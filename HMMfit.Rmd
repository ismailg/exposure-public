---
title: "HMM fitting to data of participants returns in the Exposure experiment"
author: "Ismail Guennouni"
date: "`r Sys.Date()`"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, include =F)
```

```{r}
library(tidyverse)
library(afex)
library(PairedData)
library(multcompView)
library(lsmeans)
library(depmixS4)
library(flextable)
library(grid)
library(gridExtra)
library(forcats)
library(ggsignif)
library(magick)
library(doParallel)
library(factoextra)


```

## Fitting HMM model to participants data

Here we fit an HMM model to data generated by participants in both RTGs (pre and post manipulation) for both conditions. We specify that the transition between latent states depends on the investment received. In order to distinguish transitons by condition and Phase, we add a contrast variabel that has three levels (Pre-manipulation, post-control and post exposure). We compare models with different number of states and choose the one with the lowest BIC. 

```{r}
load("data/d_finished.RData")

# select columns of interest and also solve issue with the participant with two RS_scores by averaging them. 
data_HMM <- d_finished %>%
  dplyr::select(playerId, roundType, investment, returns, roundNum, gameNum.f, condition.f, RS_score, LPFS_score, investorState.f) %>% 
  filter(roundType == "trust", !is.na(roundNum), gameNum.f %in% c("pre", "post")) %>% 
  dplyr::select(-roundType) %>%
  mutate(roundNum = as.numeric(as.character(roundNum))) %>%
  mutate(inv_pct = investment/20, ret_pct_0 = ifelse(investment == 0, 0, returns/(3*investment))) %>%
  group_by(playerId, investment, returns, roundNum, gameNum.f, condition.f, LPFS_score, investorState.f, inv_pct, ret_pct_0) %>%
  summarize(RS_score = mean(RS_score, na.rm = TRUE)) %>%
  ungroup()


# Data for both pre and post games
data_HMM_all <- data_HMM %>% 
  arrange(playerId, gameNum.f, roundNum) %>%
  group_by(playerId,gameNum.f) %>% 
  dplyr::mutate(next_investment = lead(investment, default=0),
                full_ctrst = factor(ifelse(gameNum.f=="pre", 0,ifelse(condition.f=="Control",1,2)))) %>%
  ungroup() %>% 
  unique()

# FOCUS ON POST GAMES ONLY 
data_HMM_post <- data_HMM %>% 
  filter(gameNum.f == "post") %>% 
  group_by(playerId) %>% 
  dplyr::mutate(next_investment = lead(investment, default=0)) %>%
  ungroup() %>%
  unique()


```



<!-- Here we extend the depmixS4 package functionality for analyzing data using hidden Markov models (HMMs). It involves defining new response classes and their associated methods. -->
```{r}

# Define a response class representing Gaussian distributions with discrete support
setClass("discgaus", contains="response", slots=c(breaks="numeric"))

# Define a generic function for creating instances of the discgaus class
setGeneric("discgaus", function(y, pstart = NULL, fixed = NULL, ...) standardGeneric("discgaus"))

# Define a method for creating instances of the discgaus class
setMethod("discgaus", 
          signature(y="ANY"), 
          function(y, pstart=NULL, fixed=NULL, breaks = c(-Inf, seq(0, 19) + .5, Inf), ...) {
            # Convert y to a matrix
            y <- matrix(y, length(y))
            # Create x matrix
            x <- matrix(1)
            # Initialize parameters list
            parameters <- list()
            # Number of parameters
            npar <- 2
            # Check if fixed parameters are provided, else initialize as FALSE
            if(is.null(fixed)) fixed <- as.logical(rep(0, npar))
            # Check if initial parameters are provided, else initialize default values
            if(!is.null(pstart)) {
              if(length(pstart) != npar) stop("length of 'pstart' must be ", npar)
              parameters$mu <- pstart[1]
              parameters$sigma <- pstart[2]
            } else {
              parameters <- list(mu = 10, sigma = 3)
            }
            # Create a new object of class discgaus
            mod <- new("discgaus", parameters=parameters, fixed=fixed, x=x, y=y, npar=npar, breaks=breaks)
            mod
          }
)

# Define method for displaying parameters of discgaus class
setMethod("show", "discgaus",
          function(object) {
            cat("Gaussian with discrete support\n")
            cat("Parameters: \n")
            cat("mu: ", object@parameters$mu, "\n")
            cat("sigma: ", object@parameters$sigma, "\n")
          }
)

# Define method for computing density of discgaus class
setMethod("dens", "discgaus",
          function(object, log=FALSE) {
            p <- pnorm(object@breaks[-1], mean = object@parameters$mu, sd = object@parameters$sigma) - 
                 pnorm(object@breaks[-length(object@breaks)], mean = object@parameters$mu, sd = object@parameters$sigma)
            if(log) return(log(p[as.numeric(cut(object@y, breaks=object@breaks))])) 
            else return(p[as.numeric(cut(object@y, breaks=object@breaks))])
          }
)

# Define method for setting parameters of discgaus class
setMethod("setpars", "discgaus",
          function(object, values, which="pars", ...) {
            npar <- npar(object)
            if(length(values) != npar) stop("length of 'values' must be", npar)
            nms <- names(object@parameters)
            switch(which,
                   "pars"= {
                     object@parameters$mu <- values[1]
                     object@parameters$sigma <- values[2]
                   },
                   "fixed" = {
                     object@fixed <- as.logical(values)
                   }
            )
            names(object@parameters) <- nms
            return(object)
          }
)

# Define method for getting parameters of discgaus class
setMethod("getpars", "discgaus",
          function(object, which="pars", ...) {
            switch(which,
                   "pars" = {
                     parameters <- numeric()
                     parameters <- unlist(object@parameters)
                     pars <- parameters
                   },
                   "fixed" = {
                     pars <- object@fixed
                   }
            )
            return(pars)
          }
)

# Define method for fitting discgaus class
setMethod("fit", "discgaus",
          function(object, w) {
            if(missing(w)) w <- NULL
            if(!is.null(w)) {
              negLL <- function(pars) {
                object <- setpars(object, c(pars[1], exp(pars[2])))
                -sum(w*log(dens(object)))
              }
            } else {
              negLL <- function(pars) {
                object <- setpars(object, c(pars[1], exp(pars[2])))
                -sum(log(dens(object)))
              }
            }
            pars <- optim(c(object@parameters$mu, log(object@parameters$sigma)), fn=negLL)$par
            object <- setpars(object, c(pars[1], exp(pars[2])))
            object
          }
)

# Define a response class representing truncated Gaussian distributions with discrete support
setClass("truncdiscgaus", contains="discgaus", slots=c(min="numeric", max="numeric"))

# Define method for computing density of truncdiscgaus class
setMethod("dens", "truncdiscgaus",
          function(object, log=FALSE) {
            breaks <- c(object@min, object@breaks[object@breaks > object@min & object@breaks < object@max], object@max)
            prec <- pnorm(object@max, mean = object@parameters$mu, sd = object@parameters$sigma) - 
                    pnorm(object@min, mean = object@parameters$mu, sd = object@parameters$sigma)
            if(is.na(prec) || prec < 1e-12) {
              p <- rep(1/(length(breaks)-1), length(object@y))
              if(log) return(log(p)) else return(p)
            } else {
              p <- pnorm(breaks[-1], mean = object@parameters$mu, sd = object@parameters$sigma) - 
                   pnorm(breaks[-length(breaks)], mean = object@parameters$mu, sd = object@parameters$sigma)
              p <- p/sum(p)
              if(log) return(log(p[as.numeric(cut(object@y, breaks=object@breaks))])) 
              else return(p[as.numeric(cut(object@y, breaks=object@breaks))])
            }
          }
)

# Define a generic function for creating instances of the truncdiscgaus class
setGeneric("truncdiscgaus", function(y, pstart = NULL, fixed = NULL, ...) standardGeneric("truncdiscgaus"))

# Define a method for creating instances of the truncdiscgaus class
setMethod("truncdiscgaus", 
          signature(y="ANY"), 
          function(y, pstart=NULL, fixed=NULL, breaks = c(-Inf, seq(0, 19) + .5, Inf), min=-0.5, max=20.5, ...) {
            y <- matrix(y, length(y))
            x <- matrix(1)
            parameters <- list()
            npar <- 2
            if(is.null(fixed)) fixed <- as.logical(rep(0, npar))
            if(!is.null(pstart)) {
              if(length(pstart) != npar) stop("length of 'pstart' must be ", npar)
              parameters$mu <- pstart[1]
              parameters$sigma <- pstart[2]
            }
            mod <- new("truncdiscgaus", parameters=parameters, fixed=fixed, x=x, y=y, npar=npar, breaks=breaks, min=min, max=max)
            mod
          }
)

# Define a response class representing Gaussian distributions with variable discrete support
setClass("vtdgaus", contains="response", slots=c(yield="numeric"))

# Define a generic function for creating instances of the vtdgaus class
setGeneric("vtdgaus", function(y, pstart = NULL, fixed = NULL, ...) standardGeneric("vtdgaus"))

# Define a method for creating instances of the vtdgaus class
setMethod("vtdgaus", 
          signature(y="ANY"), 
          function(y, yield, pstart=NULL, fixed=NULL, ...) {
            y <- matrix(y, length(y))
            x <- matrix(1)
            parameters <- list()
            npar <- 2
            if(is.null(fixed)) fixed <- as.logical(rep(0, npar))
            if(!is.null(pstart)) {
              if(length(pstart) != npar) stop("length of 'pstart' must be ", npar)
              parameters$mu <- pstart[1]
              parameters$sigma <- pstart[2]
            } else {
              parameters <- list(mu=.5, sigma=1)
            }
            mod <- new("vtdgaus", parameters=parameters, fixed=fixed, x=x, y=y, npar=npar, yield=yield)
            mod
          }
)

# Define method for displaying parameters of vtdgaus class
setMethod("show", "vtdgaus",
          function(object) {
            cat("Gaussian with variable discrete support for percentage responses\n")
            cat("Parameters: \n")
            cat("mu: ", object@parameters$mu, "\n")
            cat("sigma: ", object@parameters$sigma, "\n")
          }
)

# Define method for computing density of vtdgaus class
setMethod("dens", "vtdgaus",
          function(object, log=FALSE) {
            prec <- pnorm(1 + .5*(1/60), mean = object@parameters$mu, sd = object@parameters$sigma) - 
                    pnorm(0 - .5*(1/60), mean = object@parameters$mu, sd = object@parameters$sigma)
            if(prec < 1e-12) {
              p <- 1/(object@yield + 1)
            } else {
              p <- pnorm(object@y + .5*(1/object@yield), mean = object@parameters$mu, sd = object@parameters$sigma) - 
                   pnorm(object@y - .5*(1/object@yield), mean = object@parameters$mu, sd = object@parameters$sigma)
              norm <- pnorm(1 + .5*(1/object@yield), mean = object@parameters$mu, sd = object@parameters$sigma) - 
                      pnorm(0 - .5*(1/object@yield), mean = object@parameters$mu, sd = object@parameters$sigma)
              p <- p/norm
            }
            p[object@yield == 0] <- 1
            if(log) return(log(p)) else return(p)
          }
)

# Define method for setting parameters of vtdgaus class
setMethod("setpars", "vtdgaus",
          function(object, values, which="pars", ...) {
            npar <- npar(object)
            if(length(values) != npar) stop("length of 'values' must be", npar)
            nms <- names(object@parameters)
            switch(which,
                   "pars"= {
                     object@parameters$mu <- values[1]
                     object@parameters$sigma <- values[2]
                   },
                   "fixed" = {
                     object@fixed <- as.logical(values)
                   }
            )
            names(object@parameters) <- nms
            return(object)
          }
)

# Define method for getting parameters of vtdgaus class
setMethod("getpars", "vtdgaus",
          function(object, which="pars", ...) {
            switch(which,
                   "pars" = {
                     parameters <- numeric()
                     parameters <- unlist(object@parameters)
                     pars <- parameters
                   },
                   "fixed" = {
                     pars <- object@fixed
                   }
            )
            return(pars)
          }
)

# Define method for fitting vtdgaus class
setMethod("fit", "vtdgaus",
          function(object, w) {
            if(missing(w)) w <- NULL
            if(!is.null(w)) {
              negLL <- function(pars) {
                object <- setpars(object, c(pars[1], exp(pars[2])))
                -sum(w*log(dens(object)))
              }
            } else {
              negLL <- function(pars) {
                object <- setpars(object, c(pars[1], exp(pars[2])))
                -sum(log(dens(object)))
              }
            }
            pars <- optim(c(object@parameters$mu, log(object@parameters$sigma)), fn=negLL)$par
            object <- setpars(object, c(pars[1], exp(pars[2])))
            object
          }
)

# Function for reordering states in an HMM based on labels
label_switch <- function(mod, labels) {
  if(!is(mod, "depmix") || !is(mod, "depmix.fitted")) stop("this function is for depmix models")
  n_states <- mod@nstates
  if(length(labels) != n_states || length(unique(labels)) != n_states || !(all(labels) %in% 1:n_states)) {
    stop("labels needs to be a vector of unique integers between 1 and", n_states)
  }
  inv_labels <- sapply(1:n_states, function(x) which(labels == x))
  tmp <- mod
  # Relabel prior
  ppars <- getpars(mod@prior)
  fpars <- getpars(mod@prior, which="fixed")
  out_pars <- as.numeric(t(matrix(ppars, nrow=length(ppars)/n_states, byrow=TRUE)[, inv_labels]))
  out_fixed <- as.logical(t(matrix(fpars, nrow=length(fpars)/n_states, byrow=TRUE)[, inv_labels]))
  if(!tmp@prior@family$link == "identity") tmp@prior@family$base <- labels[tmp@prior@family$base]
  # Relabel transition
  for(i in 1:n_states) {
    ppars <- getpars(mod@transition[[inv_labels[i]]])
    fpars <- getpars(mod@transition[[inv_labels[i]]], which="fixed")
    out_pars <- c(out_pars, as.numeric(t(matrix(ppars, nrow=length(ppars)/n_states, byrow=TRUE)[, inv_labels])))
    out_fixed <- c(out_fixed, as.logical(t(matrix(fpars, nrow=length(fpars)/n_states, byrow=TRUE)[, inv_labels])))
    tmp@transition[[i]] <- mod@transition[[inv_labels[i]]]
    if(!tmp@transition[[i]]@family$link == "identity") tmp@transition[[i]]@family$base <- labels[tmp@transition[[i]]@family$base]
  }
  # Relabel response
  for(i in 1:n_states) {
    out_pars <- c(out_pars, unlist(lapply(mod@response[[inv_labels[i]]], getpars)))
    out_fixed <- c(out_fixed, unlist(lapply(mod@response[[inv_labels[i]]], getpars, which="fixed")))
  }
  tmp <- setpars(tmp, out_fixed, which="fixed")
  tmp <- setpars(tmp, out_pars)
  if(is(tmp, "depmix.fitted")) tmp@posterior <- viterbi(tmp)
  return(tmp)
}

# Function for ordering states in a truncated discretised Gaussian model
order_mod_truncdiscgaus <- function(mod) {
  ns <- nstates(mod)
  sum <- rep(0.0, ns)
  for(i in 1:ns) {
    # Calculate expected return in each state
    tpars <- getpars(mod@response[[i]][[1]])
    dmod <- truncdiscgaus(seq(0, 20), pstart=tpars, min=-0.5, max=20.5)
    sum[i] <- sum(seq(0, 20) * dens(dmod))
  }
  cat("Expected values for states: ", sum, "\n")
  # Reorder the states
  mod <- label_switch(mod, rank(sum, ties.method="first"))
  return(mod)
}

# Function for ordering states in a variable response truncated discretised Gaussian model
order_mod_vtdgaus <- function(mod) {
  ns <- nstates(mod)
  sum <- rep(0.0, ns)
  for(i in 1:ns) {
    # Calculate expected return in each state
    tpars <- getpars(mod@response[[i]][[1]])
    dmod <- vtdgaus(seq(0, 1, length=61), pstart=tpars, yield=rep(60, 61))
    sum[i] <- sum(seq(0, 1, length=61) * dens(dmod))
  }
  # Reorder the states
  mod <- label_switch(mod, rank(sum, ties.method="first"))
  return(mod)
}


```




# Fitting HMM to ALL Participants data (Pre and Post)


```{r}
# 
# #| label: setup-parallel-3
# 
# # Set up the parallel backend
# num_cores <- 8
# #create the cluster
# my.cluster <- parallel::makeCluster(
#   num_cores,
#   type = "FORK"
#   )
# 
# #register it to be used by %dopar%
# doParallel::registerDoParallel(cl = my.cluster)
```

```{r}
#| label: fit-HMM-trustee-models
#| cache: true

# # Depmix simple Models
# priordat_all <- data_HMM_all |>
#   filter(roundNum==1)
# 
# tr_fdmod_all <- list()
# 
# max_ns <- 8
# 
# 
# set.seed(20240513)
# my_seeds <- sample(1000:50000, max_ns)
# 
# 
# # Fitting HMM models to data
# tr_fdmod_all <- foreach(state = 2:max_ns, .packages = c("depmixS4"), .combine = "c") %dopar% {
#   # Define depmix model with simple transition only depending on next_inv
#   print(state)
#   tr_simple <- depmix(returns ~ 1, data=data_HMM_all, nstates=state, transition=~ next_investment*full_ctrst, prior=~ investment, initdata=priordat_all, family=multinomial("mlogit"), ntimes=rep(15,206*2))
# 
#   mus <- (1:state)*(1/(state+1))
#   sigmas <- rep(1/(state+1), state)
#   if(state > 8) sigmas <- sigmas + .1
#   rModels_tr <- list()
#   for(s in 1:state) {
#     rModels_tr[[s]] <- list(vtdgaus(y=data_HMM_all$ret_pct_0, yield = 3*data_HMM_all$investment, pstart=c(mus[s],sigmas[s])))
#   }
# 
#   tr_dmod <- makeDepmix(response=rModels_tr, transition=tr_simple@transition, prior=tr_simple@prior, ntimes = rep(15,206*2), homogeneous=FALSE)
# 
#   tmp1 <- fit(tr_dmod, emcontrol=em.control(random.start = FALSE))
#   set.seed(my_seeds[state])
#   tmp2 <- multistart(tr_dmod, nstart=20)
#   if(!is.na(logLik(tmp2)) && logLik(tmp2) > logLik(tmp1)) {tmp1 <- tmp2}
#   tmp1
# }
# 
# # Stop the parallel backend
# stopImplicitCluster()
# 
# 
# save(tr_fdmod_all, file="data/tr_fdmod_all.RData", compression_level = 9)

```

```{r}
#|  label: HMM-trustee-model-comparison
#|  include: false

load("data/tr_fdmod_all.RData")

df_bics_all <- data.frame(nstate = 2:max_ns,
                          logLik = unlist(lapply(tr_fdmod_all, logLik)),
                          num_params= unlist(lapply(tr_fdmod_all, function(x) attr(logLik(x), which="df"))),
                          AIC = unlist(lapply(tr_fdmod_all, AIC)),
                          BIC = unlist(lapply(tr_fdmod_all, BIC)))
df_bics_all

# Here we choose BIC as best m
nstate_tr <- which.min(df_bics_all[,5]) + 1
nstate_tr

best_mod_all <- order_mod_vtdgaus(tr_fdmod_all[[nstate_tr-1]])
summary(best_mod_all)
```

```{r}
#| label: tbl-BICs-tr
#| warning: false
#| echo: false
#| tbl-cap: Model comparison of HMMs of trustee actions with different numbers of latent states.

df_bics_all %>%
  mutate_if(is.numeric, format, digits=4, nsmall = 0, big.mark = ",") %>%
knitr::kable(booktabs = TRUE,
  col.names = c("#states", "log(lik)", "# pars", "AIC", "BIC"))
```


<!-- Function to get transiton probabilities from fitted HMM models -->
```{r}
get_trans_probs <- function(fmod, numCovIn, numCovTr) {
  # --- Parameters & Setup ---
  ns <- nstates(fmod) # Number of states in the HMM
  investment_values <- seq(0, 20, length = 100)
  # Create a data frame to store the transition probabilities.
  # Each row represents a combination of "from" state, "to" state, and "investment" value.
  trans_prob_all <- expand.grid(
    from = paste0("from State ", 1:ns),
    to = paste0("State ", 1:ns),
    investment = investment_values
  )
  trans_prob_all$prob_pre <- 0
  trans_prob_all$prob_ctrl <- 0
  trans_prob_all$prob_expo <- 0
  
  # --- Calculate Transition Probabilities ---
  for (from in 1:ns) { 
    start_idx <- ns * numCovIn + 1 + (from - 1) * numCovTr * ns
    end_idx <- start_idx + numCovTr * ns - 1
    pars <- matrix(getpars(fmod)[start_idx:end_idx], ncol = numCovTr)
    print(pars)
    
    # Initialize matrices to store transition probabilities before normalization
    y0 <- matrix(0, nrow = length(investment_values), ncol = ns) # Pre-intervention group
    y1 <- matrix(0, nrow = length(investment_values), ncol = ns) # Control group
    y2 <- matrix(0, nrow = length(investment_values), ncol = ns) # Exposed group
    
    for (to in 1:ns) {
      y0[, to] <- exp(pars[to, 1] + pars[to, 2] * investment_values)
      y2[, to] <- exp(pars[to, 1] + pars[to, 2] * investment_values + pars[to, 3] + pars[to, 5] * investment_values) # Exposed: Intercept + investment + group effect + interaction
      y1[, to] <- exp(pars[to, 1] + pars[to, 2] * investment_values + pars[to, 4] + pars[to, 6] * investment_values) # Control: Intercept + investment + group effect + interaction
    }
    
    # Normalize transition probabilities for each group to ensure they sum to 1 across all "to" states
    y0 <- y0 / rowSums(y0)
    y1 <- y1 / rowSums(y1)
    y2 <- y2 / rowSums(y2)
    
    for (to in 1:ns) {
      idx <- trans_prob_all$from == paste0("from State ", from) & 
             trans_prob_all$to == paste0("State ", to)
      trans_prob_all$prob_pre[idx] <- y0[, to]
      trans_prob_all$prob_ctrl[idx] <- y1[, to]
      trans_prob_all$prob_expo[idx] <- y2[, to]
    }
  }
  
  saveRDS(trans_prob_all, "data/trans_prob_all.RDS")
  return(trans_prob_all)
}
```


```{r}

# Plotting the trustee HMM policy by state 
tr_policy <- list()
for(i in 1:nstates(best_mod_all)) {
  tr_policy[[i]] <- dens(vtdgaus(seq(0,1, length=61), yield=3*20, pstart=c(unlist(best_mod_all@response[[i]][[1]]@parameters))))  
}

perc_return <- seq(0,1, length=61)

respplot <- data.frame(state = rep(1:nstates(best_mod_all), each=length(perc_return)),
                            perc_return = perc_return,
                            probability = unlist(tr_policy)) |>
  mutate(state = factor(paste0("s",state))) |> 
  ggplot(                 
       aes(x = perc_return,
           y = probability,
           fill = state)) +
  geom_bar(stat = "identity",
           position = "dodge") + 
  # labs(fill='Latent trustee state') +
  xlab("Percentage return") +
  theme_minimal() + 
  theme(legend.position = "right") + ggtitle("State conditional strategies")

##################################################################################
# Plotting Prior (initial) state probabilities (new)

# Function to calculate softmax probabilities
softmax <- function(x) exp(x) / sum(exp(x))

# Get parameters from model
params <- getpars(getmodel(best_mod_all, "prior"))

# Extract intercepts and investment coefficients, and set initial investment value
intercepts <- params[1:nstate_tr]
investments <- params[(nstate_tr + 1):(2 * nstate_tr)]
# set average investment of trustee in neutral state as value to calculate initial state probabilities in linear model
investment_value <- 9

# Calculate logits and initial probabilities
logits <- intercepts + investments * investment_value
initial_probs <- softmax(logits)

# Create a data frame for plotting
priordf <- data.frame(
  state = factor(paste0("s", 1:nstate_tr)),
  prob = initial_probs
)

# Plot the initial state probabilities
priorplot <- ggplot(priordf, aes(x = state, y = prob, fill = state)) +
  geom_bar(stat = "identity", width = 0.5) +
  xlab("State") +
  ylab("Prior Probability") +
  ggtitle("Initial State Probability for average investment") +
  theme_minimal()



```




```{r,include=F}

trans_prob_all <- get_trans_probs(best_mod_all, numCovIn=2, numCovTr=6)


ctrl_prePost_plot <- ggplot(trans_prob_all,aes(x=investment)) + 
  geom_line(aes(y=prob_ctrl, colour = as.factor(to), linetype="Post-control")) + 
  geom_line(aes(y=prob_pre, colour = as.factor(to), linetype="Pre-control")) +
  facet_wrap(~from) + 
  ylim(c(0,1)) + 
  ggtitle("Transition function pre- and post-control group") + 
  labs(x = "Investment", y = "Transition probability", color='Transition to:') + 
  scale_linetype_manual(values = c("Post-control" = "solid", "Pre-control" = "dotted")) +
  theme_bw()


expo_prePost_plot  <- ggplot(trans_prob_all,aes(x=investment)) + 
  geom_line(aes(y=prob_expo, colour = as.factor(to), linetype="Post-exposure")) + 
  geom_line(aes(y=prob_pre, colour = as.factor(to), linetype="Pre-exposure")) +
  facet_wrap(~from) + 
  ylim(c(0,1)) + 
  ggtitle("Transition function pre- and post-exposure manipulation") + 
  labs(x = "Investment", y = "Transition probability", color='Transition to:', linetype = "Line Type") + 
  scale_linetype_manual(values = c("Post-exposure" = "solid", "Pre-exposure" = "dotted")) +
  theme_bw()

expo_prePost_plot 
ctrl_prePost_plot
```


```{r}
##############################################################################

#| label: fig-trustee-policy-plot
#| echo: false
#| fig.cap: HMM model of the trustees 
#| fig.align: center
#| fig.width: 12
#| fig.height: 6

# transplot <- plot_transitions(best_mod_all,numCovIn=2,numCovTr=2) + labs(x = "Investment", y = "Probability", color='Transition to') + theme_minimal() + theme(legend.position = "bottom")


gridExtra::grid.arrange(respplot, priorplot, expo_prePost_plot, ncol=3, layout_matrix=cbind(c(1,2),c(3,3),c(3,3)))
```


<!-- Get Trustee posterior states from model and add to data table -->

```{r, include = FALSE}
set.seed(20221010)
# mention we are using local decoding (refer to the book). 
predTrStatesAll <- posterior(best_mod_all, type="local")

#############
data_HMM_all$postTrState <-  factor(predTrStatesAll, levels= c(1,2,3,4,5),labels=c("State 1","State 2","State 3","State 4","State 5"))
############
```

```{r}

#| label: fig-trustee-posterior-plot
#| echo: false
#| fig.cap: POsterior state of the trustee in eahc round by Condition and Phase
#| fig.align: center
#| fig.width: 8
#| fig.height: 12
postHMM <- ggplot(data_HMM_all) +
  geom_bar(aes(x = roundNum, group = postTrState, fill = postTrState),  position = position_stack(reverse = TRUE)) + 
  # facet_wrap(~factor(condition.f, levels = rev(levels(as.factor(condition.f))))) +  
  facet_wrap(~condition.f*gameNum.f)+
  labs(x = "Round", fill='Posterior trustee state') +
  theme_bw() +
  theme(legend.position = "bottom")

postHMM
```



<!-- Cluster joint latent states: -->

```{r}
# Load necessary libraries
library(factoextra)
library(hexbin)


# Assuming data_HMM_post is your dataframe

# Rename the levels of investorState and postTrState
data_HMM_all <- data_HMM_all %>%
  mutate(investorState = recode(investorState.f, 
                                "unhappy" = "1", 
                                "neutral" = "2", 
                                "happy" = "3"),
         postTrState = gsub("State ", "", postTrState))


# Define the desired order of joint states
desired_order <- c(
  "1-1", "1-2", "1-3", "1-4", "1-5",
  "2-1", "2-2", "2-3", "2-4", "2-5",
  "3-1", "3-2", "3-3", "3-4", "3-5"
)

# Ensure Joint_State and Next_Joint_State are factors with the specified order
data_HMM_all <- data_HMM_all %>%
  mutate(Joint_State = factor(paste(investorState, postTrState, sep = "-"), 
                              levels = desired_order, ordered = TRUE)) 


# Plot the frequency of each Joint_State
# Define a color palette based on the desired order
color_palette <- colorRampPalette(c("red","orange", "green", "cyan", "blue"))(length(desired_order))
state_pair_to_color <- setNames(color_palette, desired_order)

# Plot the frequency of each Joint_State with the assigned colors
ggplot(data_HMM_all, aes(x = Joint_State)) +
  geom_bar(aes(fill = Joint_State)) +
  scale_fill_manual(values = state_pair_to_color) +
  labs(title = "Frequency of Joint States",
       x = "Joint State",
       y = "Frequency") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

#Plot joint states distribution by phase and condition 
ggplot(data_HMM_all, aes(x = Joint_State, fill = gameNum.f)) +
  geom_bar(position = position_dodge(width = 0.9)) +
  scale_fill_manual(values = c("lightblue", "blue"), # Example colors for different conditions
                    name = "Condition") +
  labs(title = "Frequency of Joint States by Condition",
       x = "Joint State",
       y = "Frequency") +
  facet_wrap(~condition.f)+
  theme(axis.text.x = element_text(angle = 90, hjust = 1))


# Create next joint state for transition analysis
data_HMM_all <- data_HMM_all %>%
  arrange(playerId, gameNum.f, roundNum) %>%
  group_by(playerId, gameNum.f) %>%
  mutate(Next_Joint_State = lead(Joint_State, order_by = roundNum)) %>%
  ungroup() %>%
  mutate(Next_Joint_State = factor(Next_Joint_State, levels = desired_order, ordered = TRUE))

# Write to CSV if needed (for reference or debugging)
write.csv(data_HMM_all, "data/data_HMM_all.csv")

# Calculate transition counts
transition_counts <- data_HMM_all %>%
  filter(!is.na(Next_Joint_State)) %>%
  count(Joint_State, Next_Joint_State)

# Convert counts to probabilities and reshape to wide format
transition_matrix <- transition_counts %>%
  group_by(Joint_State) %>%
  mutate(transition_prob = n / sum(n)) %>%
  ungroup() %>%
  dplyr::select(Joint_State, Next_Joint_State, transition_prob) %>%
  pivot_wider(names_from = Next_Joint_State, values_from = transition_prob, values_fill = list(transition_prob = 0))

# Ensure the column order in transition_matrix
transition_matrix <- transition_matrix %>%
  dplyr::select(Joint_State, all_of(desired_order))


# Visualize the transition matrix
transition_matrix_long <- transition_matrix %>%
  pivot_longer(cols = -Joint_State, names_to = "Next_Joint_State", values_to = "probability")

ggplot(transition_matrix_long, aes(x = Next_Joint_State , y = Joint_State, fill = probability)) +
  geom_tile() +
  scale_fill_gradient2(low = "white", high = "blue", mid = "lightblue", midpoint = 0.5, limit = c(0, 1), space = "Lab", name="Transition Probability") +
  theme_minimal() +
  labs(title = "Transition Matrix of Joint States", x = "Current Joint State", y = "Next Joint State") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))


```
```{r}
frequency_table <- data_HMM_all %>%
  count(Joint_State, condition.f, gameNum.f) %>%
  spread(gameNum.f, n, fill = 0) %>% 
  mutate(Difference = `post` - `pre`)

# Plot the differences
ggplot(frequency_table, aes(x = Joint_State, y = Difference, fill = condition.f)) +
  geom_bar(stat = "identity", position = position_dodge(width = 0.9)) +
  scale_fill_manual(values = c("lightblue", "blue"), # Example colors for different conditions
                    name = "Condition") +
  labs(title = "Difference in Frequency of Joint States by Condition (post - pre)",
       x = "Joint State",
       y = "Difference in Frequency") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```


<!-- Clustering of whole time series using K-means  -->
```{r}

# Reshape the data
df_wide <- data_HMM_all %>%
  dplyr::select(playerId, gameNum.f,investorState, postTrState) %>%
  mutate(across(c(investorState, postTrState), as.numeric)) %>%
  group_by(playerId, gameNum.f) %>%
  mutate(id = row_number()) %>%
  pivot_wider(names_from = id, values_from = c(investorState, postTrState)) %>%
  ungroup()

# Separate playerId and gameNum.f columns for later use
playerIds <- df_wide$playerId
gameNums <- df_wide$gameNum.f

# Convert the rest of the data frame to a matrix
data_matrix <- df_wide %>% dplyr::select(-playerId, -gameNum.f) %>% as.matrix()

# Determine the optimal number of clusters using the elbow method
wss <- vector("numeric", length = 10)

for (k in 1:10) {
  set.seed(123)  # For reproducibility
  kmeans_result <- kmeans(data_matrix, centers = k, nstart = 25)
  wss[k] <- kmeans_result$tot.withinss
}

# Plot the elbow plot
plot(1:10, wss, type = "b", pch = 19, frame = FALSE,
     xlab = "Number of Clusters K",
     ylab = "Total Within-Clusters Sum of Squares",
     main = "Elbow Plot for Determining Optimal K")

```

<!-- # Perform k-means clustering with the optimal number of clusters -->
```{r}

set.seed(123)
final_kmeans <- kmeans(data_matrix, centers = 3, nstart = 25)

# Add cluster assignments to the original data
df_wide$cluster <- factor(final_kmeans$cluster)

# Combine playerId and gameNum.f with cluster assignments
df_wide_with_id <- df_wide %>% 
  mutate(playerId = playerIds, gameNum.f = gameNums)

# Join the cluster assignments back to the original data
df_clustered <- data_HMM_all %>% 
  left_join(df_wide_with_id %>% dplyr::select(playerId, gameNum.f, cluster), 
            by = c("playerId", "gameNum.f"))


df_clustered %>%
  group_by(cluster, Joint_State) %>%
  summarise(count = n(), .groups = 'drop') %>%
  group_by(cluster) %>%
  mutate(proportion = count / sum(count)) %>%
  ggplot(aes(x = factor(cluster), y = proportion, fill = factor(Joint_State))) +
  geom_bar(stat = "identity", position = "stack") +
  scale_fill_manual(values = state_pair_to_color) +
  theme_minimal() +
  labs(title = "Proportion of Joint States by Cluster",
       x = "Cluster",
       y = "Proportion",
       fill = "Joint State") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))


df_clustered <- df_clustered %>%
  mutate(cluster_mood = case_when(
    cluster == 2 ~ "Joint Unhappy",
    cluster == 1 ~ "Joint Happy",
    cluster == 3 ~ "Joint Neutral",
    TRUE ~ "Other"  # This catches any other values, if they exist
  ) %>% factor(levels = c("Joint Unhappy", "Joint Neutral", "Joint Happy"))) 

# Save the results to a CSV file (optional)
write.csv(df_clustered, "clustered_data.csv", row.names = FALSE)

```


```{r}
# Calculate the mean path of joint states for each cluster over time
df_mean_path <- df_clustered %>%
  group_by(cluster_mood, roundNum) %>%
  summarize(meanInvestorState = mean(as.numeric(investorState), na.rm = TRUE),
            meanPostTrState = mean(as.numeric(postTrState), na.rm = TRUE)) %>%
  ungroup()

# Combine both states in a single plot using facets
df_mean_path_long <- df_mean_path %>%
  pivot_longer(cols = c(meanInvestorState, meanPostTrState), 
               names_to = "StateType", 
               values_to = "MeanState")

 # Define custom colors for each cluster
cluster_colors <- c("Joint Unhappy" = "red", "Joint Neutral" = "darkgreen", "Joint Happy" = "blue")

ggplot(df_mean_path_long, aes(x = roundNum, y = MeanState, color = cluster_mood)) +
  geom_line(size = 1.5) +
  geom_point(size = 2) +
  scale_color_manual(values = cluster_colors) +
  facet_wrap(~ StateType, scales = "free_y") +
  labs(title = "Mean Path of States by Cluster Over Time",
       x = "Time",
       y = "Mean State",
       color = "Cluster") +
  theme_minimal()

```


```{r}
cluster_means <- df_clustered %>%
  group_by(cluster_mood, roundNum) %>%
  summarise(across(c(investment, ret_pct_0), mean))

ggplot(cluster_means, aes(x = roundNum, y = investment, color = factor(cluster_mood))) +
  geom_line() +
  scale_color_manual(values = cluster_colors) +
  labs(x = "Round Number", y = "Average investment by cluster", color = "Cluster")

ggplot(cluster_means, aes(x = roundNum, y = ret_pct_0, color = factor(cluster_mood))) +
  geom_line() +
  scale_color_manual(values = cluster_colors) +
  labs(x = "Round Number", y = "Average % return by cluster", color = "Cluster")

# Load the patchwork library
library(patchwork)

# Assuming your cluster_means dataframe and cluster_colors vector are already defined
# First plot for investment
p1 <- ggplot(cluster_means, aes(x = roundNum, y = investment, color = factor(cluster_mood))) +
  geom_line() +
  scale_color_manual(values = cluster_colors) +
  labs(x = "Round Number", y = "Average investment by cluster", color = "Cluster") +
  theme_minimal()

# Second plot for % return
p2 <- ggplot(cluster_means, aes(x = roundNum, y = ret_pct_0, color = factor(cluster_mood))) +
  geom_line() +
  scale_color_manual(values = cluster_colors) +
  labs(x = "Round Number", y = "Average % return by cluster", color = "Cluster") +
  theme_minimal()

# Combine the two plots
combined_plot <- p1 / p2

# Print the combined plot
print(combined_plot)

```
```{r}

# Calculate cumulative rewards and investments for each game
cumulative_summary <- df_clustered %>%
  group_by(playerId, cluster_mood, gameNum.f) %>%
  summarise(
    cum_investor_reward = sum(returns - investment, na.rm = TRUE),
    cum_trustee_reward = sum(3*investment - returns, na.rm = TRUE),
    .groups = 'drop'
  )  %>%
  group_by(cluster_mood) %>%
  summarise(
    avg_investor_cum = mean(cum_investor_reward),
    avg_trustee_cum = mean(cum_trustee_reward)
  ) %>%
  ungroup()

# Print summary
print(cumulative_summary)

```

<!-- Correlate the Cluster with initial state of the trustee:  -->

```{r}
library(dplyr)
library(nnet)  # for multinomial logistic regression
library(broom)  # for tidy output
library(ggplot2)

# First, let's filter for the initial round and select relevant variables
df_initial <- df_clustered %>%
  filter(roundNum == 1) %>%
  dplyr::select(playerId,gameNum.f, condition.f, cluster_mood, investment, postTrState)

# Create a dataframe with the pre and post cluster moods for each player and condition
pre_post_data <- df_initial %>%
  dplyr::select(playerId, gameNum.f, condition.f, cluster_mood) %>%
  spread(key = gameNum.f, value = cluster_mood) %>%
  filter(!is.na(pre) & !is.na(post))

# Calculate the distribution of people between clusters for pre and post
distribution_pre <- pre_post_data %>%
  group_by(condition.f, pre) %>%
  summarise(count = n()) %>%
  mutate(time = "pre") %>%
  rename(cluster_mood = pre)

distribution_post <- pre_post_data %>%
  group_by(condition.f, post) %>%
  summarise(count = n()) %>%
  mutate(time = "post") %>%
  rename(cluster_mood = post)

# Combine the pre and post data
combined_distribution <- bind_rows(distribution_pre, distribution_post)

# Ensure the time column is a factor with levels in the correct order
combined_distribution$time <- factor(combined_distribution$time, levels = c("pre", "post"))

# Plot the evolution between pre and post
ggplot(combined_distribution, aes(x = time, y = count, group = cluster_mood, color = cluster_mood)) +
  geom_line(aes(linetype = cluster_mood)) +
  geom_point() +
  facet_wrap(~ condition.f, scales = "fixed") +
  theme_minimal() +
  labs(title = "Evolution of Cluster Moods Pre to Post by Condition",
       x = "Time",
       y = "Count",
       color = "Cluster Mood",
       linetype = "Cluster Mood") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))


```
<!-- #Testing whether differences between pre and post cluster frequencies/proportions are statistically significant -->
```{r}
# Create a contingency table
contingency_table <- combined_distribution %>%
  filter(time == "pre") %>%
  inner_join(combined_distribution %>% filter(time == "post"), by = c("condition.f", "cluster_mood")) %>%
  dplyr::select(condition.f, cluster_mood, count.x, count.y) %>%
  pivot_wider(names_from = condition.f, values_from = c(count.x, count.y))

# Rename columns for clarity
colnames(contingency_table) <- c("cluster_mood", "Control_Pre", "Manipulation_Pre", "Control_Post", "Manipulation_Post")

# Print contingency table
print(contingency_table)


# Function to perform proportion test for each class
perform_prop_test <- function(pre_counts, post_counts, total_pre, total_post) {
  counts <- c(pre_counts, post_counts)
  totals <- c(total_pre, total_post)
  test_result <- prop.test(counts, totals)
  return(test_result)
}

# Total counts for Control and Manipulation groups
total_control_pre <- sum(contingency_table$Control_Pre)
total_control_post <- sum(contingency_table$Control_Post)
total_manipulation_pre <- sum(contingency_table$Manipulation_Pre)
total_manipulation_post <- sum(contingency_table$Manipulation_Post)

# Perform tests for Control group
control_results <- lapply(1:nrow(contingency_table), function(i) {
  perform_prop_test(contingency_table$Control_Pre[i], contingency_table$Control_Post[i], total_control_pre, total_control_post)
})

# Perform tests for Manipulation group
manipulation_results <- lapply(1:nrow(contingency_table), function(i) {
  perform_prop_test(contingency_table$Manipulation_Pre[i], contingency_table$Manipulation_Post[i], total_manipulation_pre, total_manipulation_post)
})

# Print results for Control group
cat("Control Group Proportion Tests:\n")
for (i in 1:length(control_results)) {
  cat(paste("\nCluster Mood:", contingency_table$cluster_mood[i]))
  print(control_results[[i]])
}

# Print results for Manipulation group
cat("\n\nManipulation Group Proportion Tests:\n")
for (i in 1:length(manipulation_results)) {
  cat(paste("\nCluster Mood:", contingency_table$cluster_mood[i]))
  print(manipulation_results[[i]])
}


```


```{r}
# Ensure cluster_mood is a factor
df_initial$cluster_mood <- factor(df_initial$cluster_mood)

# Fit the multinomial logistic regression model
model <- multinom(cluster_mood ~ investment + postTrState, data = df_initial)

# Summary of the model
summary(model)

# Get tidy output of the model
tidy_model <- tidy(model)
print(tidy_model)


# Visualize the effects
ggplot(df_initial, aes(x = investment, fill = cluster_mood)) +
  geom_density(alpha = 0.5) +
  facet_wrap(~postTrState) +
  labs(title = "Distribution of Initial Investment by Cluster Mood and Trustee State",
       x = "Initial Investment Percentage",
       y = "Density") +
  theme_minimal()
```


### Key takeaways:

Higher initial investments slightly decrease the likelihood of being in Joint Neutral or Joint Happy clusters compared to Joint Unhappy.
Higher trustee states, particularly 3 and above, strongly increase the odds of being in Joint Neutral or Joint Happy clusters compared to Joint Unhappy.
The effect of trustee state is more pronounced for the Joint Happy cluster than for Joint Neutral.

These results suggest that the trustee's initial state is a stronger predictor of cluster membership than the initial investment amount, with higher trustee states associated with more positive joint outcomes.

<!-- Check associations with RS -->
```{r}
#########################
# Perform ANOVA to test for significant differences in RS_score between clusters
df_aov_RS <-  df_clustered %>% dplyr::select(playerId,gameNum.f, RS_score,cluster_mood) %>% unique()

# Calculate the mean and standard error of RS_score for each cluster
mean_rs_score <- df_clustered %>%
  group_by(cluster_mood,condition.f) %>%
  summarize(mean_RS_score = mean(RS_score, na.rm = TRUE),
            se_RS_score = sd(RS_score, na.rm = TRUE) / sqrt(n()))


# Print the mean RS score for each cluster
print(mean_rs_score)


anova_result_rs <- aov(RS_score ~ cluster_mood*gameNum.f, data=df_aov_RS)

# Print the summary of the ANOVA result
summary(anova_result_rs)


# Plot the mean RS score for each cluster with error bars using geom_point and geom_errorbar
ggplot(mean_rs_score, aes(x = cluster_mood, y = mean_RS_score, color = cluster_mood)) +
  geom_point(size = 5) +
  geom_errorbar(aes(ymin = mean_RS_score - se_RS_score, ymax = mean_RS_score + se_RS_score),
                width = 0.2, size = 1.5) +
  facet_wrap(~condition.f)+
  scale_color_manual(values = cluster_colors) +
  labs(title = "Average RS Score for Each Cluster",
       x = "Cluster",
       y = "Average RS Score",
       color = "Cluster") +
  theme_minimal()

```



<!-- Check association WITH LPFS -->
```{r}
# Perform ANOVA to test for significant differences in LPFS_score between clusters
df_aov_lpfs <-  df_clustered %>% dplyr::select(playerId,LPFS_score,cluster_mood) %>% unique()

anova_result_lpfs <- aov(LPFS_score ~ cluster_mood, data = df_aov_lpfs)

# Print the summary of the ANOVA result
summary(anova_result_lpfs)

# Calculate the mean LPFS_score for each cluster
mean_lpfs_score <- df_clustered %>%
  group_by(cluster_mood) %>%
  summarize(mean_LPFS_score = mean(LPFS_score, na.rm = TRUE))

# Print the mean LPFS score for each cluster
print(mean_lpfs_score)

```
Association between RS and variability in joitn states 
```{r}

# Calculate the number of joint state changes for each player
result_vol <- df_clustered %>%
  arrange(playerId, roundNum) %>%
  group_by(playerId) %>%
  summarize(
    RS_score = first(RS_score),
    joint_state_changes = sum(Joint_State != Next_Joint_State, na.rm = TRUE)) %>%
  ungroup()

# Perform correlation analysis
correlation <- cor.test(result_vol$RS_score, result_vol$joint_state_changes)

# Print correlation results
print(correlation)

# Create a scatter plot
ggplot(result_vol, aes(x = RS_score, y = joint_state_changes)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE, color = "red") +
  labs(title = "Relationship between RS_score and Joint State Changes",
       x = "RS_score",
       y = "Number of Joint State Changes")
```


```{r}
# Load required libraries
library(dplyr)
library(ggplot2)
library(tidyr)
library(forcats)

# Assuming the data is already loaded into a dataframe called 'df'

# Categorize RS_score into high and low groups
df_categorized <- df_clustered %>%
  mutate(RS_group = case_when(
    RS_score > 15 ~ "High RS",
    RS_score <= 10 ~ "Low RS",
    TRUE ~ NA_character_
  )) %>%
  filter(!is.na(RS_group))

# Calculate the distribution of joint states for each RS group
joint_state_distribution <- df_categorized %>%
  group_by(RS_group, Joint_State) %>%
  summarise(count = n()) %>%
  group_by(RS_group) %>%
  mutate(proportion = count / sum(count))

# Visualization: Stacked bar plot
ggplot(joint_state_distribution, aes(x = RS_group, y = proportion, fill = Joint_State)) +
  geom_bar(stat = "identity") +
  labs(title = "Distribution of Joint States by Rejection Sensitivity Group",
       x = "Rejection Sensitivity Group",
       y = "Proportion",
       fill = "Joint State") +
  theme_minimal()

# Chi-square test of independence
chi_square_result <- chisq.test(table(df_categorized$RS_group, df_categorized$Joint_State))
print(chi_square_result)

# Post-hoc analysis: Standardized residuals
residuals <- chi_square_result$residuals
print("Standardized Residuals:")
print(residuals)

# Visualization: Mosaic plot
library(vcd)
mosaic(~ RS_group + Joint_State, data = df_categorized, 
       main = "Mosaic Plot of Joint States by RS Group")

# Effect size: Cramer's V
library(effectsize)
cramer_v <- cramers_v(df_categorized$RS_group, df_categorized$Joint_State)
print(paste("Cramer's V:", cramer_v))

# Optional: Analyze transitions between joint states
transitions <- df_categorized %>%
  arrange(playerId, roundNum) %>%
  group_by(playerId) %>%
  mutate(next_state = lead(Joint_State)) %>%
  filter(!is.na(next_state)) %>%
  group_by(RS_group, Joint_State, next_state) %>%
  summarise(transition_count = n()) %>%
  ungroup()

# Visualization: Transition heatmap
ggplot(transitions, aes(x = Joint_State, y = next_state, fill = transition_count)) +
  geom_tile() +
  facet_wrap(~ RS_group) +
  scale_fill_viridis_c() +
  labs(title = "Joint State Transitions by RS Group",
       x = "Current State", y = "Next State", fill = "Transition Count") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```












# Fitting HMM to Participants data in the post Phase with manipulation vs Control factor in transition function:  


```{r}

#| label: setup-parallel-4

# # Set up the parallel backend
# num_cores <- 8
# #create the cluster
# my.cluster <- parallel::makeCluster(
#   num_cores,
#   type = "FORK"
#   )
# 
# #register it to be used by %dopar%
# doParallel::registerDoParallel(cl = my.cluster)
```

```{r}
#| label: fit-HMM-trustee-models
#| cache: true

# # Depmix simple Models 
# priordat <- data_HMM_post |>
#   filter(roundNum==1)
# 
# tr_fdmod_cond <- list()
# 
# max_ns <- 8
# 
# 
# set.seed(20240513)
# my_seeds <- sample(1000:50000, max_ns)
# 
# 
# # Fitting HMM models to data 
# tr_fdmod_cond <- foreach(state = 2:max_ns, .packages = c("depmixS4"), .combine = "c") %dopar% {
#   print(state)
#   # Define depmix model with simple transition only depending on next_inv
#   tr_cond <- depmix(returns ~ 1, data=data_HMM_post, nstates=state, transition=~ next_investment*condition.f, prior=~ investment, initdata=priordat, family=multinomial("mlogit"), ntimes=rep(15,207))
#   
#   mus <- (1:state)*(1/(state+1))
#   sigmas <- rep(1/(state+1), state)
#   if(state > 8) sigmas <- sigmas + .1
#   rModels_tr <- list()
#   for(s in 1:state) {
#     rModels_tr[[s]] <- list(vtdgaus(y=data_HMM_post$ret_pct_0, yield = 3*data_HMM_post$investment, pstart=c(mus[s],sigmas[s])))
#   }
#   
#   tr_dmod <- makeDepmix(response=rModels_tr, transition=tr_cond@transition, prior=tr_cond@prior, ntimes = rep(15,207), homogeneous=FALSE)
#   
#   tmp1 <- fit(tr_dmod, emcontrol=em.control(random.start = FALSE))
#   set.seed(my_seeds[state])
#   tmp2 <- multistart(tr_dmod, nstart=20)
#   if(!is.na(logLik(tmp2)) && logLik(tmp2) > logLik(tmp1)) {tmp1 <- tmp2}
#   tmp1
# }
# 
# # Stop the parallel backend
# stopImplicitCluster()
# 
# 
# save(tr_fdmod_cond, file="data/tr_fdmod_cond.RData", compression_level = 9)

```



```{r}
#|  label: HMM-trustee-cond-comparison
#|  include: false


#############################
load("data/tr_fdmod_cond.RData")
############################


max_ns <- length(tr_fdmod_cond) +1 
df_bics_cond <- data.frame(nstate = 2:max_ns,
                          logLik = unlist(lapply(tr_fdmod_cond, logLik)),
                          unlist(lapply(tr_fdmod_cond, function(x) attr(logLik(x), which="df"))),
                          AIC = unlist(lapply(tr_fdmod_cond, AIC)),
                          BIC = unlist(lapply(tr_fdmod_cond, BIC)))
df_bics_cond

# Here we choose BIC as best m
nstate_tr <- which.min(df_bics_cond[,5]) + 1

############################
best_mod_cond <- order_mod_vtdgaus(tr_fdmod_cond[[nstate_tr-1]])
###########################
summary(best_mod_cond)
```

```{r}
#| label: tbl-BICs-tr-cond
#| warning: false
#| echo: false
#| tbl-cap: Model comparison of HMMs of trustee actions with different numbers of latent states.

df_bics_cond %>%
  mutate_if(is.numeric, format, digits=4, nsmall = 0, big.mark = ",") %>%
knitr::kable(booktabs = TRUE,
  col.names = c("#states", "log(lik)", "# par", "AIC", "BIC"))
```

```{r}
#| label: fig-trustee-policy-plot
#| echo: false
#| fig.cap: Probability mass function of the trustee's policy conditional on its latent state as an output of the best fitting XX state HMM using a truncated discretised Gaussian as a response function
#| fig.align: center
#| fig.width: 12
#| fig.height: 6


# Plotting the trustee HMM policy by state 
tr_policy <- list()
for(i in 1:nstates(best_mod_cond)) {
  tr_policy[[i]] <- dens(vtdgaus(seq(0,1, length=61), yield=3*20, pstart=c(unlist(best_mod_cond@response[[i]][[1]]@parameters))))  
}

perc_return <- seq(0,1, length=61)

respplot <- data.frame(state = rep(1:nstates(best_mod_cond), each=length(perc_return)),
                            perc_return = perc_return,
                            probability = unlist(tr_policy)) |>
  mutate(state = factor(paste0("s",state))) |> 
  ggplot(                 
       aes(x = perc_return,
           y = probability,
           fill = state)) +
  geom_bar(stat = "identity",
           position = "dodge") + 
  # labs(fill='Latent trustee state') +
  xlab("Percentage return") +
  theme_minimal() + 
  theme(legend.position = "right") + ggtitle("State conditional strategies")


# Function to calculate softmax probabilities
softmax <- function(x) exp(x) / sum(exp(x))

# Assuming best_mod_cond is your fitted model
params <- getpars(getmodel(best_mod_cond, "prior"))

# Extract intercepts and investment coefficients, and set initial investment value
intercepts <- params[1:nstate_tr]
investments <- params[(nstate_tr + 1):(2 * nstate_tr)]
investment_value <- 9

# Calculate logits and initial probabilities
logits <- intercepts + investments * investment_value
initial_probs <- softmax(logits)

# Create a data frame for plotting
priordf <- data.frame(
  state = factor(paste0("s", 1:nstate_tr)),
  prob = initial_probs
)

# Plot the initial state probabilities
priorplot <- ggplot(priordf, aes(x = state, y = prob, fill = state)) +
  geom_bar(stat = "identity", width = 0.5) +
  xlab("State") +
  ylab("Prior Probability") +
  ggtitle("Initial State Probability") +
  theme_minimal()

# Plotting Transition function between states
plot_transitions_cond <- function(fmod, numCovIn, numCovTr) {
  
  ns <- nstates(fmod)
  conditions <- c(0, 1)  # 0 for control, 1 for manipulation
  
  trans_prob <- data.frame(
    from = rep(1:ns, each=80*ns*2),
    to = rep(1:ns, each=80*2),
    inv = rep(seq(0, 20, length=80), times=ns*2),
    condition = rep(rep(conditions, each=80), times=ns),
    prob = 0
  )
  
  y <- matrix(0.0, ncol=ns, nrow=80)
  
  for (from in 1:ns) {
    pars <- matrix(getpars(fmod)[seq(ns*numCovIn + 1 + (from - 1)*numCovTr*ns, ns*numCovIn + 1 + (from - 1)*numCovTr*ns + numCovTr*ns - 1)], ncol=numCovTr)
    print(pars)
    for (cond in conditions) {
      for (to in 1:ns) {
        x <- trans_prob[trans_prob$from == from & trans_prob$to == to & trans_prob$condition == cond, "inv"]
        y[, to] <- exp(pars[to, 1] + pars[to, 2]*x + pars[to, 3]*cond + pars[to, 4]*x*cond)
      }
      y <- y / rowSums(y)
      for (to in 1:ns) {
        trans_prob$prob[trans_prob$from == from & trans_prob$to == to & trans_prob$condition == cond] <- y[, to]
      }
    }
  }
  
  trans_prob <- trans_prob %>%
    mutate(from = paste0("s", from),
           to = paste0("s", to))
  
  ggplot(trans_prob, aes(x=inv, y=prob, colour = as.factor(to), linetype = as.factor(condition))) + 
    geom_line() + 
    facet_wrap(~from) + 
    ylim(c(0, 1)) +
    scale_linetype_manual(values=c("0" = "dashed", "1" = "solid")) +
    labs(linetype = "Condition")
}
transplot <- plot_transitions_cond(best_mod_cond,numCovIn=2,numCovTr=4) + labs(x = "Investment", y = "Probability", color='Transition to') + theme_minimal() + theme(legend.position = "bottom")


gridExtra::grid.arrange(respplot, priorplot, transplot, ncol=3, layout_matrix=cbind(c(1,2),c(3,3),c(3,3)))


```


<!-------------------------       LATENT STATE POSTERIOR PLOTS BY CONDITIONS        ------------------------------>

```{r, include = FALSE}
set.seed(20221010)
# Get investor posterior states from model and add to data table

# mention we are using local decoding (refer to the book). 
predTrStates <- posterior(best_mod_cond, type="local")

#############
data_HMM_post$postTrState <-  factor(predTrStates, levels= c(1,2,3,4,5),labels=c("State 1","State 2","State 3","State 4","State 5"))
############
```

```{r}
postHMM <- ggplot(data_HMM_post %>% dplyr::filter(gameNum.f=="post")) +
  geom_bar(aes(x = roundNum, group = postTrState, fill = postTrState),  position = position_stack(reverse = TRUE)) + 
  facet_wrap(~factor(condition.f, levels = rev(levels(as.factor(condition.f))))) +  
  labs(x = "Round", fill='Posterior trustee state') +
  theme_bw() +
  theme(legend.position = "bottom")

postHMM
```

<!-------------------------       CLUSTERING PAIRS OF LATENT STATES      ------------------------------>



```{r}
# Load required libraries
library(reshape2)
library(ggplot2)
library(dplyr)

# Example structure of data_hmm_post:
# playerId | roundNum | PosttrState | investorState
# 1        | 1        | 2           | 1
# 1        | 2        | 3           | 2
# ...

# Create a combined state pair column
data_HMM_new <- data_HMM_post %>%
  distinct(playerId, roundNum, .keep_all = TRUE) %>%
  mutate(StatePair = paste(investorState.f, postTrState, sep = "-"))

# Define the order of state pairs from most uncooperative to most cooperative
state_order <- c("unhappy-State 1", "unhappy-State 2", "unhappy-State 3", "unhappy-State 4", "unhappy-State 5",
                 "neutral-State 1", "neutral-State 2", "neutral-State 3", "neutral-State 4", "neutral-State 5",
                 "happy-State 1", "happy-State 2", "happy-State 3", "happy-State 4", "happy-State 5")

# Convert StatePair to a factor with the defined order
data_HMM_new$StatePair <- factor(data_HMM_new$StatePair, levels = state_order, ordered = TRUE)

# Convert roundNum to a numeric type and then to factor with levels in the correct order
data_HMM_new$roundNum <- as.numeric(as.character(data_HMM_new$roundNum))
data_HMM_new$roundNum <- factor(data_HMM_new$roundNum)

# Pivot the data to have players as rows and rounds as columns
heatmap_data <- data_HMM_new %>%
  dplyr::select(playerId, roundNum, StatePair) %>%
  pivot_wider(names_from = roundNum, values_from = StatePair)

# Convert the data to long format for ggplot2
heatmap_data_long <- heatmap_data %>%
  pivot_longer(cols = -playerId, names_to = "roundNum", values_to = "StatePair")

# Ensure roundNum, playerId, and StatePair are treated as characters and then as factors
heatmap_data_long$roundNum <- as.character(heatmap_data_long$roundNum)
heatmap_data_long$playerId <- as.character(heatmap_data_long$playerId)
heatmap_data_long$StatePair <- as.character(heatmap_data_long$StatePair)

heatmap_data_long$roundNum <- as.factor(heatmap_data_long$roundNum)
heatmap_data_long$playerId <- as.factor(heatmap_data_long$playerId)
heatmap_data_long$StatePair <- as.factor(heatmap_data_long$StatePair)

#Get unique state pairs and assign a color to each
unique_state_pairs <- unique(heatmap_data_long$StatePair)
color_palette <- scales::hue_pal()(length(unique_state_pairs))
state_pair_to_color <- setNames(color_palette, unique_state_pairs)

# Assign colors: cold for uncooperative and warm for cooperative
color_palette <- colorRampPalette(c("blue", "cyan", "yellow", "orange", "red"))(length(state_order))
state_pair_to_color <- setNames(color_palette, state_order)

# Plot the heatmap
ggplot(heatmap_data_long, aes(x = factor(roundNum, levels = unique(roundNum)), y = playerId)) +
  geom_tile(aes(fill = factor(StatePair, levels=unique(StatePair))), color = "white") +
  scale_fill_manual(values = state_pair_to_color, 
                    breaks = unique_state_pairs,
                    labels = unique_state_pairs) +
  theme_minimal() +
  labs(title = "Sequence of Latent State Pairs (Investor-Trustee) for Each Participant",
       x = "Round",
       y = "Participant ID",
       fill = "State Pair") +
  theme(axis.text.y = element_blank(), 
        axis.ticks.y = element_blank())

# Visual of frequencies of joint states by phase and condition . 

```

 <!-- # 3D representation of joint latent space -->
 
 
```{r}

# Load required libraries
library(plotly)
library(dplyr)

# Define the order of investor states
investor_state_order <- c("unhappy", "neutral", "happy")

# Function to plot evolution of a specific player in 3D
plot_player_evolution_3d <- function(player_index) {
  player_data <- data_HMM_new %>% filter(playerId == player_index)
  
  # Ensure postTrState is converted to numeric for y-axis
  player_data <- player_data %>%
    mutate(
      TrusteeState = as.numeric(gsub("State ", "", postTrState)),
      InvestorStateNum = as.numeric(factor(investorState.f, levels = investor_state_order))
    )

  # Create 3D plot
  p <- plot_ly(player_data, x = ~InvestorStateNum, y = ~TrusteeState, z = ~roundNum, type = 'scatter3d', mode = 'lines+markers',
               marker = list(size = 5, color = ~roundNum, colorscale = 'Viridis', showscale = TRUE),
               line = list(width = 4, color = ~roundNum, colorscale = 'Viridis', showscale = FALSE)) %>%
    add_trace(
      x = ~InvestorStateNum, y = ~TrusteeState, z = ~roundNum, 
      marker = list(size = 8, symbol = I("circle")),
      text = ~paste("Round:", roundNum),
      hoverinfo = 'text'
    ) %>%
    add_trace(
      x = player_data$InvestorStateNum[1], y = player_data$TrusteeState[1], z = player_data$roundNum[1], 
      marker = list(size = 10, symbol = I("diamond"), color = "red"),
      text = "Start",
      hoverinfo = 'text'
    ) %>%
    add_trace(
      x = player_data$InvestorStateNum[nrow(player_data)], y = player_data$TrusteeState[nrow(player_data)], z = player_data$roundNum[nrow(player_data)], 
      marker = list(size = 10, symbol = I("cross"), color = "green"),
      text = "End",
      hoverinfo = 'text'
    ) %>%
    layout(
      title = paste("Evolution of State Pairs Over Time for Player", player_index),
      scene = list(
        xaxis = list(title = 'Investor State', tickvals = 1:3, ticktext = investor_state_order),
        yaxis = list(title = 'Trustee State', tickvals = 1:5),
        zaxis = list(title = 'Round')
      )
    )
  
  # Print the plot
  print(p)
}

# Example usage
plot_player_evolution_3d("YEpcoSejRCLubbkPp")
plot_player_evolution_3d("EZYk8rfDNxcuwSpEr")
plot_player_evolution_3d("6SYmH8njCALTjKyp2")



```


<!-- Cluster joint latent states: -->

```{r}
# Load necessary libraries
library(factoextra)
library(hexbin)


# Assuming data_HMM_post is your dataframe

# Rename the levels of investorState and postTrState
data_HMM_clust <- data_HMM_post %>%
  distinct(playerId, roundNum, .keep_all = TRUE) %>%
  mutate(investorState = recode(investorState.f, 
                                "unhappy" = "1", 
                                "neutral" = "2", 
                                "happy" = "3"),
         postTrState = gsub("State ", "", postTrState))


# Define the desired order of joint states
desired_order <- c(
  "1-1", "1-2", "1-3", "1-4", "1-5",
  "2-1", "2-2", "2-3", "2-4", "2-5",
  "3-1", "3-2", "3-3", "3-4", "3-5"
)

# Ensure Joint_State and Next_Joint_State are factors with the specified order
data_HMM_clust <- data_HMM_clust %>%
  mutate(Joint_State = factor(paste(investorState, postTrState, sep = "-"), 
                              levels = desired_order, ordered = TRUE)) 


# Plot the frequency of each Joint_State
# Define a color palette based on the desired order
color_palette <- colorRampPalette(c("blue", "cyan", "yellow", "orange", "red"))(length(desired_order))
state_pair_to_color <- setNames(color_palette, desired_order)

# Plot the frequency of each Joint_State with the assigned colors
ggplot(data_HMM_clust, aes(x = Joint_State)) +
  geom_bar(aes(fill = Joint_State)) +
  scale_fill_manual(values = state_pair_to_color) +
  labs(title = "Frequency of Joint States",
       x = "Joint State",
       y = "Frequency") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

ggplot(data_HMM_clust, aes(x = Joint_State, fill = condition.f)) +
  geom_bar(position = position_dodge(width = 0.9)) +
  scale_fill_manual(values = c("grey40", "grey80"), # Example colors for different conditions
                    name = "Condition") +
  labs(title = "Frequency of Joint States by Condition",
       x = "Joint State",
       y = "Frequency") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))


# Create next joint state for transition analysis
data_HMM_clust <- data_HMM_clust %>%
  arrange(playerId, roundNum) %>%
  group_by(playerId) %>%
  mutate(Next_Joint_State = lead(Joint_State, order_by = roundNum)) %>%
  ungroup() %>%
  mutate(Next_Joint_State = factor(Next_Joint_State, levels = desired_order, ordered = TRUE))

# Write to CSV if needed (for reference or debugging)
write.csv(data_HMM_clust, "data/data_HMM_clust.csv")

# Calculate transition counts
transition_counts <- data_HMM_clust %>%
  filter(!is.na(Next_Joint_State)) %>%
  count(Joint_State, Next_Joint_State)

# Convert counts to probabilities and reshape to wide format
transition_matrix <- transition_counts %>%
  group_by(Joint_State) %>%
  mutate(transition_prob = n / sum(n)) %>%
  ungroup() %>%
  select(Joint_State, Next_Joint_State, transition_prob) %>%
  pivot_wider(names_from = Next_Joint_State, values_from = transition_prob, values_fill = list(transition_prob = 0))

# Ensure the column order in transition_matrix
transition_matrix <- transition_matrix %>%
  select(Joint_State, all_of(desired_order))


# Visualize the transition matrix
transition_matrix_long <- transition_matrix %>%
  pivot_longer(cols = -Joint_State, names_to = "Next_Joint_State", values_to = "probability")

ggplot(transition_matrix_long, aes(x = Next_Joint_State , y = Joint_State, fill = probability)) +
  geom_tile() +
  scale_fill_gradient2(low = "white", high = "blue", mid = "lightblue", midpoint = 0.5, limit = c(0, 1), space = "Lab", name="Transition Probability") +
  theme_minimal() +
  labs(title = "Transition Matrix of Joint States", x = "Current Joint State", y = "Next Joint State") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))


```
```{r}
library(dplyr)
library(ggplot2)

# Function to compute the stationary distribution
stationary_distribution <- function(transition_matrix) {
  eigen_result <- eigen(t(transition_matrix))
  # Find the eigenvector associated with the eigenvalue 1
  stationary_vector <- Re(eigen_result$vectors[, which.max(Re(eigen_result$values))])
  # Normalize the vector to sum to 1
  stationary_vector <- stationary_vector / sum(stationary_vector)
  return(stationary_vector)
}

# Compute the stationary distribution
transition_matrix_numeric <- transition_matrix %>%
  dplyr::select(-Joint_State) %>%  # Remove the 'Joint_State' column
  as.matrix()

# Print the resulting transition matrix
print(transition_matrix_numeric)
stationary_dist <- stationary_distribution(transition_matrix_numeric)

print("Stationary Distribution:")
print(stationary_dist)

# Create a data frame for plotting with initial names
plot_data <- data.frame(
  State = desired_order,
  Probability = stationary_dist
)

# Plot the stationary distribution
ggplot(plot_data, aes(x = factor(State, levels = desired_order), y = Probability)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  labs(title = "Stationary Distribution", x = "State", y = "Probability") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))

```

<!-- Visual of times series of joint states by initial trustee latent state (investor always starts neutral) -->
```{r}
# # Extract the trustee state at the first trial for each player
# first_trial_Trstate <- data_HMM_clust %>%
#   filter(roundNum == 1) %>%
#   dplyr::select(playerId, firstPostTrState = postTrState)
# 
# # Merge with the main data to add the first trial state as a column
# data_HMM_clust <- data_HMM_clust %>%
#   left_join(first_trial_Trstate, by = "playerId")
# 
# # Visualize the joint states over rounds with color based on the first trial trustee state
# ggplot(data_HMM_clust, aes(x = roundNum, y = Joint_State, group=playerId, color = as.factor(firstPostTrState))) +
#   geom_line(size = 1) +
#   geom_point(size = 2) +
#   facet_wrap(~ as.factor(firstPostTrState), scales = "free_y") +
#   labs(title = "Joint States Over Rounds", x = "Round", y = "Joint State", color = "First Trial Trustee State") +
#   theme_minimal() +
#   theme(axis.text.x = element_text(angle = 90, hjust = 1))
```


<!-- Clustering of whole time series using K-means  -->
```{r}

# Reshape the data
df_wide <- data_HMM_clust %>%
  dplyr::select(playerId, investorState, postTrState) %>%
  mutate(across(c(investorState, postTrState), as.numeric)) %>%
  group_by(playerId) %>%
  mutate(id = row_number()) %>%
  pivot_wider(names_from = id, values_from = c(investorState, postTrState)) %>%
  ungroup()

# Separate playerId column for later use
playerIds <- df_wide$playerId

# Convert the rest of the data frame to a matrix
data_matrix <- df_wide %>% select(-playerId) %>% as.matrix()

# Determine the optimal number of clusters using the elbow method
wss <- vector("numeric", length = 10)

for (k in 1:10) {
  set.seed(123)  # For reproducibility
  kmeans_result <- kmeans(data_matrix, centers = k, nstart = 25)
  wss[k] <- kmeans_result$tot.withinss
}

# Plot the elbow plot
plot(1:10, wss, type = "b", pch = 19, frame = FALSE,
     xlab = "Number of Clusters K",
     ylab = "Total Within-Clusters Sum of Squares",
     main = "Elbow Plot for Determining Optimal K")

# Perform k-means clustering with the optimal number of clusters
set.seed(123)
final_kmeans <- kmeans(data_matrix, centers = 3, nstart = 25)

# Add cluster assignments to the original data
df_wide$cluster <- factor(final_kmeans$cluster)

# Combine playerId with cluster assignments
df_wide_with_id <- df_wide %>% 
  mutate(playerId = playerIds)

# Join the cluster assignments back to the original data
df_clustered <- data_HMM_clust %>% 
  left_join(df_wide_with_id %>% select(playerId, cluster), by = "playerId") %>% 
  mutate(cluster = recode(cluster, `1` = "2", `2` = "1"))  %>% # renaming clusters so that they are in increasing order of cooperation (1 least cooeprative and 3 most) 
  mutate(cluster = factor(cluster, levels = c("1", "2", "3")))


  

# Save the results to a CSV file (optional)
# write.csv(df_clustered, "clustered_data.csv", row.names = FALSE)

# Display the clustering results
print(df_clustered)

# Frenquencies of clusters 
 df_clustered %>%
  group_by(cluster, condition.f) %>%
  summarize(frequency = n()/15) %>%
  ungroup()

 
```



```{r}
# Calculate the mean path of joint states for each cluster over time
df_mean_path <- df_clustered %>%
  group_by(cluster, roundNum) %>%
  summarize(meanInvestorState = mean(as.numeric(investorState), na.rm = TRUE),
            meanPostTrState = mean(as.numeric(postTrState), na.rm = TRUE)) %>%
  ungroup()

# Combine both states in a single plot using facets
df_mean_path_long <- df_mean_path %>%
  pivot_longer(cols = c(meanInvestorState, meanPostTrState), 
               names_to = "StateType", 
               values_to = "MeanState")

 # Define custom colors for each cluster
cluster_colors <- c("1" = "red", "2" = "green", "3" = "blue")

ggplot(df_mean_path_long, aes(x = roundNum, y = MeanState, color = cluster)) +
  geom_line(size = 1.5) +
  geom_point(size = 2) +
  scale_color_manual(values = cluster_colors) +
  facet_wrap(~ StateType, scales = "free_y") +
  labs(title = "Mean Path of States by Cluster Over Time",
       x = "Time",
       y = "Mean State",
       color = "Cluster") +
  theme_minimal()

# frequencies of clusters  what is specific about these people 
# whether peop
```

```{r}
cluster_means <- df_clustered %>%
  group_by(cluster, roundNum) %>%
  summarise(across(c(investment, ret_pct_0), mean))

 # Define custom colors for each cluster
cluster_colors <- c("1" = "red", "2" = "green", "3" = "blue")

ggplot(cluster_means, aes(x = roundNum, y = investment, color = factor(cluster))) +
  geom_line() +
  scale_color_manual(values = cluster_colors) +
  labs(x = "Round Number", y = "Average investment by cluster", color = "Cluster")

ggplot(cluster_means, aes(x = roundNum, y = ret_pct_0, color = factor(cluster))) +
  geom_line() +
  scale_color_manual(values = cluster_colors) +
  labs(x = "Round Number", y = "Average % return by cluster", color = "Cluster")
```


<!-- Check association WITH LPFS -->
```{r}
# Perform ANOVA to test for significant differences in LPFS_score between clusters
anova_result_lpfs <- aov(LPFS_score ~ cluster, data = df_clustered)

# Print the summary of the ANOVA result
summary(anova_result_lpfs)

# Calculate the mean LPFS_score for each cluster
mean_lpfs_score <- df_clustered %>%
  group_by(cluster) %>%
  summarize(mean_LPFS_score = mean(LPFS_score, na.rm = TRUE))

# Print the mean LPFS score for each cluster
print(mean_lpfs_score)

```

<!-- Check associations with RS -->
```{r}
#########################
# Perform ANOVA to test for significant differences in RS_score between clusters

anova_result_rs <- aov(RS_score ~ cluster, data = df_clustered %>% dplyr::select(playerId,RS_score,cluster) %>% unique())

# Print the summary of the ANOVA result
summary(anova_result_rs)

# Calculate the mean and standard error of RS_score for each cluster
mean_rs_score <- df_clustered %>%
  group_by(cluster) %>%
  summarize(mean_RS_score = mean(RS_score, na.rm = TRUE),
            se_RS_score = sd(RS_score, na.rm = TRUE) / sqrt(n()))

# Print the mean RS score for each cluster
print(mean_rs_score)

# Define custom colors for each cluster
cluster_colors <- c("1" = "red", "2" = "green", "3" = "blue")

# Plot the mean RS score for each cluster with error bars using geom_point and geom_errorbar
ggplot(mean_rs_score, aes(x = cluster, y = mean_RS_score, color = cluster)) +
  geom_point(size = 5) +
  geom_errorbar(aes(ymin = mean_RS_score - se_RS_score, ymax = mean_RS_score + se_RS_score),
                width = 0.2, size = 1.5) +
  scale_color_manual(values = cluster_colors) +
  labs(title = "Average RS Score for Each Cluster",
       x = "Cluster",
       y = "Average RS Score",
       color = "Cluster") +
  theme_minimal()

```
<!-- Check associations with firs trustee state and first trustee return %  -->

```{r}

```



<!-- ######## OLD WORK  -->
```{r}
# Load necessary libraries
# library(DirichletReg)
# 
# 
# # Assuming merged_data is your dataframe
# 
# # Prepare the data for Dirichlet regression
# # Create a matrix of the cluster probabilities
# probability_matrix <- as.matrix(merged_data %>%
#   select(starts_with("Cluster_")))
# 
# # Add a small constant to avoid zeros, which can cause issues in Dirichlet regression
# probability_matrix <- probability_matrix + 1e-6
# probability_matrix <- DR_data(probability_matrix)
# 
# # Fit a Dirichlet regression model
# dirichlet_model <- DirichReg(probability_matrix ~ RS_score + LPFS_score, data = merged_data)
# 
# # Summary of the model
# summary(dirichlet_model)
# 
# # Predict the probabilities for each cluster
# predicted_probabilities <- predict(dirichlet_model, merged_data)
# 
# # Add predicted probabilities to the dataframe
# predicted_probabilities_df <- as.data.frame(predicted_probabilities)
# names(predicted_probabilities_df) <- paste0("Predicted_Cluster_", 1:5)
# 
# merged_data <- cbind(merged_data, predicted_probabilities_df)
# 
# # Evaluate the model by comparing actual and predicted probabilities
# # Calculate the Mean Squared Error (MSE) as an example
# mse <- function(actual, predicted) {
#   mean((actual - predicted)^2)
# }
# 
# mse_values <- sapply(1:5, function(i) {
#   actual_col <- paste0("Cluster_", i)
#   predicted_col <- paste0("Predicted_Cluster_", i)
#   mse(merged_data[[actual_col]], merged_data[[predicted_col]])
# })
# 
# print(mse_values)
# 
# # Visualize the predicted vs actual probabilities for each cluster
# predicted_actual_df <- merged_data %>%
#   select(playerId, starts_with("Cluster_"), starts_with("Predicted_Cluster_")) %>%
#   pivot_longer(cols = -playerId, names_to = "Cluster", values_to = "Probability") %>%
#   mutate(Type = ifelse(grepl("Predicted", Cluster), "Predicted", "Actual"),
#          Cluster = gsub("Predicted_", "", Cluster))
# 
# ggplot(predicted_actual_df, aes(x = Cluster, y = Probability, fill = Type)) +
#   geom_boxplot() +
#   facet_wrap(~ Cluster) +
#   theme_minimal() +
#   labs(title = "Actual vs Predicted Cluster Probabilities",
#        x = "Cluster",
#        y = "Probability",
#        fill = "Type")

```

```{r}
# Load necessary libraries
library(dplyr)
library(tidyr)



# Create a transition matrix
transition_counts <- data_HMM_clust %>%
  arrange(playerId, roundNum) %>%
  group_by(playerId) %>%
  mutate(next_cluster = lead(Cluster, order_by = roundNum)) %>%
  filter(!is.na(next_cluster)) %>%  # Remove rows with NA next_cluster
  ungroup() %>%
  count(Cluster, next_cluster) %>%
  spread(key = next_cluster, value = n, fill = 0)

# Normalize the transition counts to get probabilities
transition_matrix <- as.matrix(transition_counts[,-1])
row_sums <- rowSums(transition_matrix)
transition_matrix <- transition_matrix / row_sums

print("Transition Matrix:")
print(transition_matrix)


```

<!----------------------------- Compute stationary distribution of Clusters:  ---------------------->

```{r}
# Function to compute the stationary distribution of a transition matrix
stationary_distribution <- function(transition_matrix) {
  eigen_result <- eigen(t(transition_matrix))
  # Find the eigenvector associated with the eigenvalue 1
  stationary_vector <- Re(eigen_result$vectors[, which.max(Re(eigen_result$values))])
  # Normalize the vector to sum to 1
  stationary_vector <- stationary_vector / sum(stationary_vector)
  return(stationary_vector)
}

# Compute the stationary distribution
stationary_dist <- stationary_distribution(transition_matrix)

print("Stationary Distribution:")
print(stationary_dist)

```






<!------------------- ########## TRYING NEW CLUSTERING WITH FEATURES OF THE DYAD ################ ------------------->


```{r}
# Ensure joint states are numeric for clustering
data_HMM_clust <- data_HMM_clust %>%
  mutate(Joint_State_numeric = as.numeric(factor(Joint_State)))

# Extract features
features <- data_HMM_clust %>%
  group_by(playerId) %>%
  mutate(
    cumulative_invPayoff = cumsum(returns - investment+20),
    cumulative_trPayoff = cumsum(3*investment -returns)) %>%
  summarize(
    avg_joint_state_duration = mean(rle(Joint_State_numeric)$lengths),
    avg_investment = mean(investment),
    avg_return = mean(returns)
    # avg_invPayoff = mean(cumulative_invPayoff),
    # avg_trPayoff = mean(cumulative_trPayoff) 
  ) %>%
  ungroup()

# Prepare the feature matrix for clustering
feature_matrix <- features %>%
  dplyr::select(-playerId) %>%
  scale()

# Determine the optimal number of clusters using the elbow method
fviz_nbclust(feature_matrix, kmeans, method = "wss")


# Perform k-means clustering
k <- 3  # Choose the number of clusters based on the elbow plot
kmeans_result <- kmeans(feature_matrix, centers = k, nstart = 25)

# Add cluster assignments to the features dataframe
features$cluster <- kmeans_result$cluster

# Visualize the clusters
fviz_cluster(kmeans_result, data = feature_matrix)

pca_result <- prcomp(feature_matrix, scale. = TRUE)
print(pca_result)
summary(pca_result)


# Load required library (if not already loaded)
library(ggbiplot)

# Assuming your PCA result is in pca_result
g <- ggbiplot(pca_result, 
              obs.scale = 1, 
              var.scale = 1, 
              ellipse = TRUE,
              circle = TRUE,
              varname.size = 4
              )
g <- g + scale_color_discrete(name = '')
g <- g + theme(legend.direction = 'horizontal', 
               legend.position = 'top')
g <- g + theme_minimal()
print(g)

```
```{r}
# Interpret the clusters
cluster_summary <- features %>%
  group_by(cluster) %>%
  summarize_all(mean)

print(cluster_summary)

```




<!-- NEW APPROACH  -->

```{r}
# Load necessary libraries
library(dplyr)
library(tidyr)
library(cluster)
library(ggplot2)
library(factoextra)

# Example data frame structure (assuming you have the actual data in a similar structure)
data <- data_HMM_clust %>% dplyr::select(playerId, roundNum, investorState,postTrState)

# Number of categories in each time series
n_cat1 <- 3
n_cat2 <- 5

# Function to calculate frequency distribution
frequency_distribution <- function(series, n_cat) {
  table(factor(series, levels = 1:n_cat)) / length(series)
}

# Function to calculate transition matrix
transition_matrix <- function(series, n_cat) {
  series <- factor(series, levels = 1:n_cat)
  trans_mat <- matrix(0, nrow = n_cat, ncol = n_cat)
  for (i in 1:(length(series) - 1)) {
    trans_mat[as.numeric(series[i]), as.numeric(series[i + 1])] <- trans_mat[as.numeric(series[i]), as.numeric(series[i + 1])] + 1
  }
  trans_mat <- trans_mat / rowSums(trans_mat)
  trans_mat[is.nan(trans_mat)] <- 0  # Replace NaN with 0
  return(trans_mat)
}

# Function to calculate co-occurrence matrix
co_occurrence_matrix <- function(series1, series2, n_cat1, n_cat2) {
  series1 <- factor(series1, levels = 1:n_cat1)
  series2 <- factor(series2, levels = 1:n_cat2)
  co_mat <- matrix(0, nrow = n_cat1, ncol = n_cat2)
  for (i in 1:length(series1)) {
    co_mat[as.numeric(series1[i]), as.numeric(series2[i])] <- co_mat[as.numeric(series1[i]), as.numeric(series2[i])] + 1
  }
  co_mat <- co_mat / sum(co_mat)
  print(co_mat)
  return(co_mat)
}

# Extract unique player IDs
player_ids <- unique(data$playerId)

# Initialize an empty list to store feature vectors
feature_list <- list()

# Loop over each playerId to extract features for each dyad
for (player_id in player_ids) {
  dyad_data <- data %>% filter(playerId == player_id)
  
  time_series1 <- dyad_data$investorState 
  time_series2 <- dyad_data$postTrState
  
  # Calculate frequency distributions
  freq_dist1 <- frequency_distribution(time_series1, n_cat1)
  freq_dist2 <- frequency_distribution(time_series2, n_cat2)
  
  # Calculate transition matrices
  trans_matrix1 <- as.vector(transition_matrix(time_series1, n_cat1))
  trans_matrix2 <- as.vector(transition_matrix(time_series2, n_cat2))
  
  # Calculate co-occurrence matrix
  co_matrix <- as.vector(co_occurrence_matrix(time_series1, time_series2, n_cat1, n_cat2))
  
  # Construct the feature vector for the current dyad
  features <- c(freq_dist1, freq_dist2, trans_matrix1, trans_matrix2, co_matrix)
  
  # Append the feature vector to the list
  feature_list[[as.character(player_id)]] <- features
}

# Convert the list of feature vectors into a dataframe
features_df <- do.call(rbind, feature_list)

# Perform PCA for dimensionality reduction
pca_result <- prcomp(features_df, scale. = TRUE)
pca_data <- data.frame(pca_result$x)

# Clustering using K-means (adjust the number of clusters as needed)
set.seed(123)  # For reproducibility
kmeans_result <- kmeans(pca_data, centers = 2)

# Add cluster labels to the PCA data
pca_data$cluster <- as.factor(kmeans_result$cluster)

# Visualize the clusters
ggplot(pca_data, aes(x = PC1, y = PC2, color = cluster)) +
  geom_point(size = 3) +
  ggtitle('Clustering of Dyadic Categorical Time Series') +
  xlab('Principal Component 1') +
  ylab('Principal Component 2') +
  theme_minimal()

# Print the clustering results
kmeans_result

```






