---
title: "When Forgiveness Backfires: Rejection Sensitivity and Cooperative Behavior Following Exposure to Adaptive Forgiving Agents"
author:
  "Ismail Guennouni^1,2,3,4^*, Georgia Koppe^1,2,3^$^\\dagger$, Christoph Korn^4^$^\\dagger$"
abstract: |
bibliography: "bib/exposure.bib"
csl: apa.csl
output:
  bookdown::pdf_document2:
    keep_tex: true
    toc: false
header-includes:
  - \usepackage{lscape}
editor_options: 
  markdown: 
    wrap: 72
---

\small

^1^ *Department of Psychiatry and Psychotherapy, Central Institute of
Mental Health, Medical Faculty Mannheim, Heidelberg University,
Mannheim, Germany*

^2^ *Interdisciplinary Center for Scientific Computing, Faculty of
Mathematics and Computer Science, Heidelberg University, Heidelberg,
Germany*

^3^ *Hector Institute for AI in Psychiatry, Central Institute of Mental
Health, Medical Faculty Mannheim, Heidelberg University, Mannheim
Germany*

^4^ *Department of General Psychiatry, Section Social Neuroscience,
Heidelberg University, Germany*

$^\dagger$ *Joint last author*

^\*^ *Corresponding author. Address: Central institute of Mental Health,
J5, Mannheim, Germany. Email:
[ismail.guennouni\@zi-mannheim.de](mailto:ismail.guennouni@zi-mannheim.de){.email}*

\pagebreak

**Abstract:**

Can exposure to forgiving behavior improve cooperative outcomes, and
does Rejection Sensitivity (RS) moderate this effect? This randomized
controlled experiment explores these questions using a novel approach
with Hidden Markov Model (HMM)-based artificial agents in repeated trust
games (RTGs). Participants (N = 206), pre-screened for high or low RS,
interacted with either consistently behaving or more forgiving
co-players, which were in reality HMM agents. Unexpectedly, exposure to
forgiving agents led to reduced cooperation in subsequent interactions.
Control group participants maintained consistent behavior. RS levels
influenced perceptions of the agent's cooperativeness but did not
significantly affect behavioral outcomes, revealing a
perception-behavior dissociation. These findings challenge assumptions
about fostering cooperation through simple exposure to positive
interactions and highlight the importance of accounting for negative
contrast effects when designing such interventions. They also
demonstrate the potential of HMM-based artificial agents for studying
interactive social dynamics, offering a methodological advancement for
future research. Our results suggest the need for nuanced interventions
that gradually shape expectations and behaviors to foster cooperative
outcomes, particularly addressing the discrepancy between perceptions
and behavior in individuals with high rejection sensitivity.

\vspace{1cm}

**Keywords** : Interpersonal functioning; Rejection Sensitivity;
Forgiveness Intervention; Trust-based Cooperation; Hidden Markov Models

\vspace{1cm}

**General Scientific Summary:**

This study reveals that exposing individuals to forgiving behavior in
economic games can unexpectedly decrease their subsequent cooperation.
Interestingly, while people with high rejection sensitivity more
accurately perceived their partners' cooperativeness, this didn't
translate into more cooperative behavior. These findings challenge
assumptions about fostering cooperation and highlight the need for more
nuanced interventions to promote reciprocity, especially for individuals
prone to expecting rejection.

\pagebreak

```{r setupCoax, include=FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE, echo = FALSE, include=FALSE) 
knitr::opts_chunk$set(out.width = "\\textwidth")
```

```{r load-packages05}
library(papaja)
library(kableExtra)
require(knitr)
#require(citr)
require(bookdown)

# using some functions dplyr, ggpubr, PairedData and sjPlot. Need to be loaded. 
library(tidyverse)
library(afex)
library(PairedData)
library(multcompView)
library(lsmeans)
library(depmixS4)
library(flextable)
library(grid)
library(gridExtra)
library(forcats)
library(ggsignif)
library(magick)


```

```{r analysis-preferences, include = FALSE}
# Seed for random number generation
set.seed(42)
options(tinytex.verbose = TRUE)
```

```{r emmOptions}
emm_options(pbkrtest.limit = 6210)
emm_options(lmerTest.limit = 6210)

```

# Introduction

Trust is fundamental to human social interactions, facilitating seamless
relations at both interpersonal and intergroup levels. The study of
psychopathology has linked deficits in trust-based constructs to the
development of mental health disorders [@fonagy_mentalizing_2017].
Individuals with personality disorders (PD) often struggle to form and
maintain social connections, a difficulty reflected in uncooperative
behaviors – a marker for the severity of PD symptoms
[@herpertz_social-cognitive_2014; @mulder_relationship_1999].

One explanation for such social challenges lies in early caregiver
experiences. Attachment theory [@bowlby_attachment_1978] suggests that
the quality of these relationships shapes our capacity for secure
attachments and trust. Individuals with higher levels of insecure
attachment may recall negative trust-related experiences more easily,
report fewer positive trust experiences, and use less constructive
coping strategies when trust is broken [@mikulincer_attachment_1998].
These insecure attachment patterns are often associated with heightened
rejection sensitivity (RS), a tendency to anxiously expect, readily
perceive, and intensely react to rejection [@downey_implications_1996;
@downey_early_1997]. RS has been linked to the development of various
mental health conditions, including depression, anxiety, personality
disorders, and self-harm [@gao_associations_2017]. Individuals high in
RS show attentional biases towards social threat cues, which may
contribute to difficulties in social interactions
[@berenson_rejection_2009]. A recent meta-analysis revealed prosocial
behavior and interpersonal trust as two key processes of interpersonal
functioning that are markedly impaired in PDs and which are likely to
contribute to interpersonal dysfunction in this population
[@hepp_prosociality_2022]. The interaction of RS and trust-based
constructs has been explored, particularly in Borderline Personality
Disorder (BPD). @miano_rejection_2013 and @richetin_emotional_2018 found
that RS mediated the relationship between BPD features and lower trust
appraisal. @abramov_influence_2022-1 found that higher baseline feelings
of rejection in individuals with BPD predict slower trust formation and
less pronounced declines in trust following trust violations during the
trust game. However, the interaction between *reciprocity* and RS hasn't
been studied as extensively, leaving a gap in our understanding of how
these constructs might interplay. Could an ingrained sensitivity to
rejection contribute to reduced pro-social behavior such as a failure to
show reciprocity as a result of perceived rejection by the interaction
partner?

Given that RS may be a manifestation of maladaptive attachment styles,
it's crucial to explore whether exposure to consistently forgiving
interaction partners could help reshape these interpersonal expectations
and behaviors. If RS indeed influences reciprocity in repeated
interactions, could such exposure serve as a corrective experience,
potentially improving interpersonal outcomes? This approach aligns with
attachment theory, which suggests that new, positive relational
experiences can modify internal working models of relationships
[@bowlby_secure_1988]. Research in the fields of behavioral economics
and psychology has also explored how positive social interactions
influence cooperation and pro-social behavior. The use of the repeated
trust game (RTG), a well-established experimental approach, has allowed
for the analysis of the development of trust through ongoing
interactions [@joyce_trust_1995]. In this paradigm, cycles of mutual
trust, where each party's trust is reciprocated with trustworthiness,
have the effect of enhancing cooperative behaviors even among
individuals who are initially inclined to be distrustful
[@king-casas_getting_2005]. @fowler_cooperative_2010 studied behavior in
social networks interacting in a public goods game and found that
cooperative behavior tends to cluster, suggesting that exposure to
cooperative peers can lead to more cooperative behavior. Similarly,
research on social learning theory [@bandura_social_1977] has long
demonstrated that individuals learn and model the behavior of those
around them, indicating that if someone is consistently exposed to
cooperative and positive individuals, they're likely to emulate this
behavior. These insights highlight that engaging with compassionate and
forgiving others can be an effective method for mitigating deeply
ingrained mistrust and potentially fostering trustworthy behavior.

In this study, we use a randomized controlled online experiment to test
whether exposing participants with varying RS levels to forgiving and
more cooperative co-players results in more trustworthy behavior and a
repair of potential breakdowns in RTG cooperation. To simulate realistic
social interaction while maintaining a high degree of experimental
control, we take a novel paradigmatic approach: We use generative models
of how humans play the RTG to design an agent that plays the role of the
investor, based on Hidden Markov Models (HMMs) fitted to real players'
data. A key aspect of these agents is that their actions depend on a
latent "trust state" which reacts dynamically to the trustees' returns,
simulating real-life trust-building scenarios. An advantage of having
such a generative model of behavior is the possibility of controlling
different aspects of the agent's strategy such as its general policy,
the propensity to cooperate actively, or the propensity to trust again
after breakdowns of cooperation. To further mimic real-world
interactions and examine participants' responses to one-off breakdowns
of cooperation, we incorporate occasional pre-programmed low investments
by the agent.

We pre-screened participants for high or low RS using a validated
questionnaire, then assigned them exclusively to the trustee role in a
series of trust games. After playing a 15-round RTG with a human-like
HMM investor, they were randomly assigned to either a Control or
Manipulation condition. In the Manipulation condition, participants were
exposed over three RTGs to HMM investors designed with a limited
propensity for retaliation, potentially mitigating ingrained mistrust.
In the Control condition, participants played three RTGs against the
same human-like HMM. After this exposure phase, all participants played
another 15-round RTG with a human-like HMM investor, similar to the one
in the pre-exposure phase. We expect those exhibiting high RS to be more
responsive to the pre-programmed change in the agent's cooperativeness
and retaliation propensity. We also hypothesize that those in the
Manipulation condition would behave more cooperatively and have a lower
propensity to retaliate to the co-player's defection after the exposure
phase, with those in the higher RS group showing a bigger effect.

# Methods

```{r loadData}

load("data/d_finished.RData")

# Step 1: Identify the expo_opponent for each playerId where gameNumber == "11" (exposure game) & isLastRound == TRUE (to select a particular)
expo_opponent_df <- d_finished %>%
  filter(gameNumber == "11", isLastRound == TRUE) %>%
  dplyr::select(id, expo_opponent = game_opponent) %>%
  distinct() # Ensure uniqueness in case of duplicates

# Step 2: Join this information back to the original dataset
d_finished <- d_finished %>%
  left_join(expo_opponent_df, by = "id") %>%
  mutate(condition.f = factor(expo_opponent, levels= c("AI_HMM","AI_HMM_nice"),
                              labels=c("Control","Manipulation"))) %>%
  dplyr::select(-expo_opponent) # remove the expo_opponent column if it's no longer needed


# Step 3:  create binary : high or low RS
d_finished <- d_finished %>%
  mutate(high_RS = factor(ifelse(RS_score > 15, 1, 0), 
                                    levels = c(0, 1), 
                                    labels = c("low RS", "high RS"))) 


# Summarize to count the number of participants for each Condition within each high_RS level
temp <- d_finished %>% dplyr::select(id, condition.f, high_RS) %>% 
                      unique() %>%
                      group_by(high_RS, condition.f) %>%
                      summarize(participant_count = n(), .groups = 'drop')

# View the summarized counts
print(temp)

###################### Extract latent Investor State in each round ####################

# Select the desired columns
d_selected <- d_finished %>%
  dplyr::select(roundNum, gameNumber, playerId, starts_with("State_"))

# Reshape the data
d_reshaped <- d_selected %>%
  pivot_longer(cols = starts_with("State_"), 
               names_to = "State_name", 
               values_to = "investorState") %>%
  mutate(roundNum = as.numeric(str_extract(State_name, "(?<=r)\\d+")),
         gameNumber = as.numeric(str_extract(State_name, "(?<=game_)\\d+"))) %>%
  dplyr::select(playerId, gameNumber, roundNum, investorState) %>%
  arrange(playerId, gameNumber, roundNum) %>%
  filter(!is.na(investorState)) %>% unique()

# Join the reshaped data back to the original dataset
d_finished <- d_finished %>%
  dplyr::select(-investorState) %>% 
  left_join(d_reshaped, by = c("playerId", "gameNumber", "roundNum"))
```

## Participants

To have participants with large differences in RS, a total of 1195
participants were pre-screened on the Prolific Academic platform
(prolific.co) using the Rejection Sensitivity Questionnaire (RSQ) to
finally select two similarly sized groups: One with high RS (RSQ score
\> 15, N=103) and the other with low RS (RSQ score \< 10, N=103)
totalling 206 participants (56% female). These were then invited through
prolific to take part in the main experiment. The required sample size
was determined using an *a priori* power analysis to have an 80%
probability to detect a small effect size (Cohen’s f = 0.10) for a
within-between interaction with a 5% type I error rate in a repeated
measures ANOVA. The sample size calculation assumed 2 groups, 2
measurement per group and was performed using the G\*Power software
[@faul_statistical_2009]. The mean age of participants was 34.6 years,
with an 11.9 years standard deviation. The majority of participants
identified ethnically as White ($80$%). The online cohort registered 30
unique countries of birth with the most frequent being the U.K ($33$%)
followed by Poland ($10$%) and Portugal ($10$%). Participants were paid
a fixed fee of £6 plus a bonus payment dependent on their performance
that averaged £0.5. Data was collected over multiple sessions between
December 2023 and February 2024.

## Design and Procedure

The experiment had a 2 (Condition: Manipulation or Control) by 2 (RS :
High or Low) by 2 (Phase: Trust-Game Pre Manipulation, Trust-Game Post
Manipulation) design, with repeated measures on the Phase factor (Figure
\@ref(fig:HMMPanels).A). Participants within each pre-screened RS group
were randomly assigned to one of the two levels of the Condition factor,
resulting in 101 participants in the Manipulation condition and 105 in
the Control condition. The games were designed and implemented online
using Empirica v1 [@almaatouq_empirica_2021]. The planned experiment
received approval from the University of Heidelberg's Medical Faculty
ethics commission (ID:S-708/2023) and the experiment was performed in
accordance with the ethics board guidelines and regulations. All
participants provided informed consent prior to their participation.

## Tasks and Measures

```{r, include=FALSE}
Anti_social <-  c(0.1025436430408, 0.1221931236853, 0.1345215238995,
0.1368182252617, 0.1285592471751, 0.1116014322677, 0.0895041220882,
0.0663166721334, 0.0453950277118, 0.0287077419587, 0.0167723588011,
0.0090530028158, 0.0045143317507, 0.0020796744990, 0.0008851094702,
0.0003480141146, 0.0001264134789, 0.0000424213859, 0.0000131513231,
0.0000037665630, 0.0000009965755)

Neutral <- c(0.003393529, 0.006930874, 0.013053553, 0.022671228,
0.036310144, 0.053627606, 0.073039389, 0.091734929, 0.106248217,
0.113479701, 0.111769796, 0.101517390, 0.085028780, 0.065675083,
0.046778251, 0.030725245, 0.018610323, 0.010394861, 0.005354126,
0.002543094, 0.001113881)

Pro_social <- c(0.003162697, 0.001057162, 0.001410197, 0.001881016,
0.002508877, 0.003346113, 0.004462480, 0.005950950, 0.007935434,
0.010581067, 0.014107909, 0.018809194, 0.025075644, 0.033427845,
0.044559370, 0.059394206, 0.079163228, 0.105506029, 0.140606514,
0.187373417, 0.249680651)

investment <- seq(0:20) -1

response_probs <- as.data.frame(cbind(investment,Anti_social,Neutral,Pro_social)) %>% 
  rename("low-trust" = "Anti_social", "medium-trust"="Neutral", "high-trust" = "Pro_social") %>%
  pivot_longer(cols=c("low-trust","medium-trust","high-trust"),
                    names_to='Investor_state',
                    values_to='probability') %>% 
   mutate(across(Investor_state, factor, levels=c("low-trust","medium-trust","high-trust")))
```

```{r, include=F}

plotinvHMM <- ggplot(response_probs,                            
       aes(x = investment,
           y = probability,
           fill = Investor_state)) +
  geom_bar(stat = "identity",
           position = "dodge") + 
  labs(fill='Latent investor state', x = "Investment", y= "Probability") + 
  theme_bw() + 
  theme(legend.position = "bottom",  legend.text = element_text(size = 12),  legend.title = element_text(size = 14))
  
plotinvHMM
```

```{r, include=FALSE}

# Parameters for HMM human-like Transition Function
unhappy_pars <- rbind(c(0,0), c(-3.366027, 0.40910797 ), c(-3.572619,0.08137274)) 
neutral_pars <- rbind(c(0,0), c(3.3142637, 0.3763408), c(0.9169736, 0.4502838))
happy_pars   <- rbind(c(0,0), c(0.7134085, 0.02101626), c(2.2215478 ,0.16162964))

pars_inv <- list(unhappy_pars, neutral_pars, happy_pars)


# Parameters for HMM nice Transition Function
unhappy_pars_nice <- rbind(c(-10,0), c(-3.366027, 0.40910797 ), c(-3.572619,0.08137274)) 
neutral_pars_nice <- rbind(c(0,0), c(3.3142637, 0.3763408), c(0.9169736, 0.4502838))
happy_pars_nice   <- rbind(c(0,0), c(0.7134085, 0.02101626), c(2.2215478 ,0.16162964))

pars_inv_nice <- list(unhappy_pars_nice, neutral_pars_nice, happy_pars_nice)



plot_HMM_transitions <- function(ns, pars_mat) {

  trans_prob <- data.frame(
    from = rep(1:ns, each=100*ns),
    to = rep(1:ns, each=100),
    ret = seq(-20,60,length=100),
    probs = 0
  )
  
  
  y <- matrix(0.0,ncol=ns, nrow=100)
  
  for(from in 1:ns) {
  pars <- matrix(pars_mat[[from]], ncol=2)
  # print(pars)
  
    for(to in 1:ns) {
        x <- trans_prob[trans_prob$from == from & trans_prob$to == to,"ret"]
        y[,to] <- exp(pars[to,1] + pars[to,2]*x)
    }
    y <- y/rowSums(y)

    
    for(to in 1:ns) {
      trans_prob$probs[trans_prob$from == from & trans_prob$to == to] <- y[,to]
    }
  }
  
  df <- as.data.frame(trans_prob) %>% 
    mutate(from = recode(from, "1" = "low-trust", "2" = "medium-trust", "3" = "high-trust"),
           to = recode(to, "1" = "low-trust", "2" = "medium-trust", "3" = "high-trust") ) %>% 
    mutate(across(from, factor, levels=c("low-trust","medium-trust","high-trust"))) %>% 
    mutate(across(to, factor, levels=c("low-trust","medium-trust","high-trust")))
                                    
  
    # Create a separate data frame with the background colors
  bg_colors <- data.frame(
    from = factor(c("low-trust", "medium-trust", "high-trust"), levels=c("low-trust","medium-trust","high-trust"))
  )
  
  # plotting code...
  ggplot() +
    geom_rect(data = bg_colors, aes(xmin = -Inf, xmax = Inf, ymin = -Inf, ymax = Inf, fill = from), alpha = 0.1) +
    geom_line(data = df, aes(x = ret, y = probs, colour = as.factor(to))) +
    facet_wrap(~from, labeller = labeller(from = function(x) paste("From", x, "state on trial t"))) +
    ylim(c(0,1)) +
    scale_fill_manual(values = c("low-trust" = "red", "medium-trust" = "green", "high-trust" = "blue"),
                    name = "From state") +  # Changed legend title for 'fill' here
    scale_color_manual(values = c("low-trust" = "red", "medium-trust" = "green", "high-trust" = "blue"),
                       labels = c("low-trust", "medium-trust", "high-trust"),
                       name = "State transitioned to") +
    labs(x = "Investor's net return on trial t", y = "Transition probability to \nState on trial t+1", color = 'State transitioned to') +
    theme_bw() +
    theme(legend.position = "bottom",
          legend.text = element_text(size = 12),
          legend.key.size = unit(1, 'lines'),
          legend.spacing.x = unit(0.1, 'in'),
          legend.title = element_text(size = 14),
          legend.margin = margin(t = 0.2, b = 0, unit = 'cm'),
          plot.margin = margin(t = 0, r = 0, b = 0, l = 0, unit = "cm"),
          strip.text = element_text(size = 10),
          legend.box = "vertical" # Arrange legends vertically
    ) +
    guides(fill = guide_legend(order = 1, title.position = "left", title.hjust = 0.3),
           color = guide_legend(order = 2, title.position = "left", title.hjust = 0.3))
}

```

```{r, include=F}

plotInvTran <- plot_HMM_transitions(3, pars_inv) 
print(plotInvTran)

plotInvTranNice <- plot_HMM_transitions(3, pars_inv_nice) 
print(plotInvTranNice)


```

### Repeated Trust Game and HMM Investor

Participants played a 15-round RTG [@joyce_trust_1995] in the trustee
role against a computer-programmed investor. On each round the investor
is endowed with 20 units and decides how much of that endowment to
invest. This investment is tripled and the trustee then decides how to
split this tripled amount between them and the investor. If the trustee
returns more than one third of the amount, the investor makes a gain.
Each player was represented with an icon with the participant always on
the left of the screen and the co-player on the right. The participants
were able to choose the icon that represents them at the start of the
experiment. The icon representing the co-player changed at the start of
each new game, to simulate a new interaction partner. Participants were
not told they were facing computerised co-players. We chose to simulate
the behavior of a human interaction partner through allowing for a delay
whilst pairing with new opponents as the start of each game as well as
programming the agents to respond during each round after a varying time
lapse (randomly chosen between 5 and 10 seconds).

The computerised investor consisted of a hidden Markov model (HMM)
trained on an independent existing behavioral RTG data set of human
investors. This data-driven approach thus sought to learn an investor
strategy that mimics human-like interactions. The data set used for
training consists of 388 ten round games with the same player (full
details can be found in the Supplementary Information). On this data
set, the HMM was inferred with three latent states that could be
interpreted as reflecting a “low-trust”, a “medium-trust”, and a
“high-trust” state. A separate output distribution, that maps each HMM
state onto possible investments from 0 to 20 separately, is learned
(Figure \@ref(fig:HMMPanels).B). In analogy to the latent states, these
distributions can be interpreted as reflecting “low-trust”,
“medium-trust”, or “high-trust” dispositions. Finally, the HMM is
specified by transition probabilities that describe the transition
between states. The probability of these transitions was modelled as a
function of their net return (i.e return - investment) in the previous
round (see Figure \@ref(fig:HMMPanels).C)). The initial state for the
HMM investor in each instance of the game was set to the “mid-trust”
state. Details on how the HMM state conditional probabilities and
transition functions are specified can be found in the supplement.

In order to instigate a potential breakdown of trust, thereby allowing
us to probe efforts to repair it, the computerised agent was programmed
to provide a low investment on round 12 (pre-manipulation) and round 13
(post-manipulation). On all other rounds, the investor’s actions were
determined by randomly drawing an investment from the state-conditional
distribution, with the state over rounds determined by randomly drawing
the next state from the state-transition distribution as determined from
the net return on the previous round (disregarding the net return
immediately after the pre-programmed low investment rounds).

## Manipulation

In all phases of the RTG other than the ‘Exposure phase’ (Figure
\@ref(fig:HMMPanels).A), participants interacted with this human-like
HMM. In the ‘Manipulation’ Condition of the exposure phase, however, the
parameters of this HMM were adjusted to design a ‘forgiving’ and
ultimately more cooperative agent. To achieve this, we changed the state
transition probabilities of the HMM such that it becomes impossible for
it to remain in a low trust state, effectively setting the transition
probability for remaining in a “low-trust” state to 0. The resulting
transition function is shown in Figure \@ref(fig:HMMPanels).D. The
policies conditional on the latent states and the transition function in
the other latent states remain unchanged.

## Procedure

At the start of the experiment, participants provided informed consent
and were instructed the study would consist of three phases in which
they would face a different other player. Participants were told their
goal was to maximise the number of points in all phases. They were not
told the number of rounds of each phase. Participants were randomly
assigned to either a Control or Manipulation condition. The timeline of
the experiment is shown in Figure \@ref(fig:HMMPanels).A. Phase one
("pre") consisted of a 15 round RTG in which participants took the role
of trustee, facing the same investor over all 15 rounds. On each round,
after being informed about the amount sent by the investor participants
decided how much of the tripled investment to return to the investor,
before continuing to the next round. Phase 2 ("exposure") consisted of
three 7-round RTGs. Participants in the Manipulation condition faced the
forgiving HMM investor and rated the agent on the same attributes as in
the pre-manipulation phase. Those in the Control condition faced the
same human-like HMM agent as in the "pre" phase and rated each co-player
on the same attributes. To keep the experience similar to the "pre"
phase, the agent in the Control condition was also designed to send a
very low investment in round 5 of each of the three games. In the
post-manipulation phase ("post"), participants in both conditions faced
the same human-like HMM as in "pre" phase.

At the beginning of each game in all three phases, participants were
told they would face a new player and had to wait to be paired with an
available co-player. This simulated the waiting time in real social
interaction tasks. After completing each RTG in each phase, participants
rated how cooperative and forgiving they perceived the co-player to be,
and whether they would like to play with them again (all on a scale from
1 to 10 with 10 being the most positive rating). After completing the
three game phases, participants then completed the Levels of Personality
Functioning Scale Brief-Form (LPFS-BF) questionnaire
[@weekers_level_2019]. This is a self-report measure designed to assess
core elements of personality functioning as defined in the Alternative
Model for Personality Disorders in the DSM-5
[@american_psychiatric_association_diagnostic_2013], and provides a
dimensional assessment of personality functioning, which complements the
categorical approach of RS. Finally, participants were asked whether
they thought the other players were human or computer agents, to probe
how well the agent can mimic human behavior, then debriefed and thanked
for their participation.

````{=tex}
\begin{landscape}
```{r HMMPanels, fig.cap= "\\small{A: A timeline of the experiment for both conditions. The RTG is played in dyads, with participants always assigned the role of the trustee and the HMM agent that of the investor. The investor is endowed with 20 units at the start of each round. They need to decide how much of that endowment they want to invest with the trustee. The investment is then multiplied by a factor of 3 and sent to the trustee who needs to decide how much of the multiplied investment they want to send back to the investor. The difference between conditions is the type of agents participants are exposed to in the exposure phase. Panels B - D: We construct the artificial investor agent by fitting a three-state hidden Markov model to data of human investors engaged in the 10 round RTG. From the fitted HMM, we get the distribution of investments by the human-like agent, conditional on its latent state as shown in Panel B. The fitted HMM also yields the transition probability of the agent to a state on trial t+1 as a function of the net return (difference between the investment sent and the amount received in return) on trial t as shown in Panel C. Each plot in Panel C represents a different starting latent state on trial t, and each line represents the probability of transitioning to a particular state in trial t+1. Panel D shows the transition probabilities of the forgiving HMM agent in the low trust state. Unlike the human-like HMM, the forgiving HMM always transitions out of the low-trust state, and is more likely to end up in a high-trust state, as a proxy for coaxing behavior. Transitions in the medium and high trust states were identical for both agents.}",include=T, out.width='1\\linewidth', out.height='1\\textheight', fig.align='center'}


library(magick)

# Read in the images
image1 <- image_read("figures/timeline.png")
image2 <- image_read("figures/HMMinvPolicy2.png")
image3 <- image_read("figures/HMMinvTrans2.png")
image4 <- image_read("figures/HMM_switch.png") 



# Determine the target width for all images, for example, the width of the widest image
target_width <- max(image_info(image1)$width, image_info(image2)$width, 
                    image_info(image3)$width, image_info(image4)$width)

target_height <- max(image_info(image1)$height, image_info(image2)$height, 
                    image_info(image3)$height, image_info(image4)$height)


# Scale images to have the same width
image1 <- image_scale(image1, paste0(target_width, "x", target_height))
image2 <- image_scale(image2, paste0(target_width, "x", target_height))
image3 <- image_scale(image3, paste0(target_width, "x", target_height))
image4 <- image_scale(image4, paste0(target_width, "x", target_height))

# Annotate each image with a label
image1 <- image_annotate(image1, text = "A", location = "+0+10", size = 90, color = "black", gravity = "northwest")
image2 <- image_annotate(image2, text = "B", location = "+0+10", size = 90, color = "black", gravity = "northwest")
image3 <- image_annotate(image3, text = "C", location = "-0+10", size = 90, color = "black", gravity = "northwest")
image4 <- image_annotate(image4, text = "D", location = "+0+10", size = 90, color = "black", gravity = "northwest")

# Assuming a 300 DPI resolution for good print quality
dpi <- 300

# Spacing of 0.1 inches converted to pixels
spacing <- 0.05 * dpi

# Calculating the width and height for each image
width_per_image <- ((12 - 0.1) / 2) * dpi
height_per_image <- ((7.4 - 0.1) / 2) * dpi
# The geometry string for each image, including spacing (assuming no borders)
geometry_string <- paste0(width_per_image, 'x', height_per_image, '+', spacing, '+', spacing)

# Now create the montage with the specified geometry
combined_image <- image_montage(
  c(image1, image2, image3, image4), 
  tile = "2x2",
  geometry = geometry_string
)


# Display the combined image
plot(combined_image)
```
\end{landscape}
````

## Statistical Analysis

To test whether participants behaved differently in the RTG after the
manipulation compared to the Control group, we model the percentage
return (percentage of tripled investment returned to investor) using a
linear mixed-effects model with Phase (RTG game pre vs.
post-manipulation), Condition (manipulation vs. Control), Investment,
and RS (High vs Low RS group) as well as their interactions as fixed
effects, and player-wise random intercepts and slopes for Phase. The
full specification of the statistical model can be found in the
supplement. To test whether participants behaved differently between
conditions in the Exposure phase, we fit a linear mixed effects model to
participants returns only in the exposure phase, with Condition
(manipulation vs. Control), Investment, and RS (High vs Low RS group) as
well as their interactions as fixed effects, and player-wise random
intercepts. Finally, to test whether the HMM agent's behavior differed
between Phases, Conditions and RS groups, we estimate a linear
mixed-effects model of investments sent by the computerised HMM agent
with Condition, Phase and RS and their interaction as fixed effects, and
a similar random effects structure to the returns model.

The model was estimated using the `afex` package [@singmann_afex_2022]
in R. More complex models with additional random effects could not be
estimated reliably, and as such the estimated model can be considered to
include the optimal random effects structure
[@matuschek_balancing_2017]. A similar process was used to establish the
random effects structures of linear mixed-effects models used to analyse
the HMM agent investments as well as the participants' ratings of the
co-players. There is no agreed upon way to calculate effect sizes for
mixed effects models. Instead, we will report on testing differences in
marginal means. For the $F$-tests, we used the Kenward-Roger
approximation to the degrees of freedom, as implemented in the R package
"afex". We Z-transform the Investment variable (subtract the overall
investment mean and divide by overall standard deviation) as centering
is beneficial to interpreting the main effects more easily in the
presence of interactions. To probe significant interactions, we
conducted planned contrasts using the `emmeans` package in R. Given that
we were testing multiple pre-planned comparisons, we applied the "Sidak"
correction to control for familywise error rate while maintaining
reasonable statistical power. This approach allowed us to investigate
specific hypotheses about the differential effects of our manipulation
across phases and RS groups, while protecting against inflated Type I
error rates.

```{r datRatings}

#######################    Pre-processing player ratings 

# Pivot longer ratings on each attribute 
df_coop <- d_finished %>% dplyr::select(playerId,condition.f,contains("cooperative"),high_RS) %>%  
  pivot_longer(cols=contains("cooperative"), names_to = c("game"), names_pattern ="rating_cooperative_(.*)", values_to = "rating_coop") %>% distinct()

df_forgiv <- d_finished %>% dplyr::select(playerId,condition.f,contains("forgiving"),high_RS) %>%
  pivot_longer(cols=contains("forgiving"), names_to = c("game"), names_pattern ="rating_forgiving_(.*)", values_to = "rating_forgiving") %>% distinct()

df_playAgain <- d_finished %>% dplyr::select(playerId,condition.f,contains("again"),high_RS) %>%  
  pivot_longer(cols=contains("again"), names_to = c("game"), names_pattern ="rating_playAgain_(.*)", values_to = "rating_playAgain") %>% distinct()

#merge all data frames together
datRatings <- list(df_coop, df_forgiv,df_playAgain) %>% 
              reduce(full_join, by=c('playerId','game','condition.f','high_RS')) %>%
              mutate(gameNum.f = factor(game,labels = c("pre", "expo1", "expo2", "expo3","post"),
                                      levels=c("1", "11", "12", "13", "2")))

# Group means for each rating 
mu <- datRatings %>% group_by(gameNum.f, condition.f) %>% summarise(mean_coop = mean(rating_coop),
                                                  mean_forgiv = mean(rating_forgiving),
                                                  mean_playAgain = mean(rating_playAgain)
                                                  )
mu


```

```{r}

df_long_ratings <- datRatings %>%
  pivot_longer(
    cols = starts_with("rating_"), 
    names_to = "rating_type", 
    values_to = "rating_value"
  ) %>%
  dplyr::select(playerId, condition.f, gameNum.f, rating_type, rating_value, high_RS)


# First, calculate the mean and SEM for each group
summary_df <- df_long_ratings %>%
  group_by(gameNum.f, condition.f, rating_type, high_RS) %>%
  summarise(
    mean = mean(rating_value, na.rm = TRUE),
    sem = sd(rating_value, na.rm = TRUE)/sqrt(n())
  ) %>%
  ungroup()


```

<!-- ## Linear mixed effects Model for returns  -->

```{r avgRetDf}
# Filter only trust rounds and create % returns and investments 

avg_ret_df <- d_finished %>%
  dplyr::select(playerId,roundType,investment,returns,roundNum,gameNum.f,condition.f, phase.f, high_RS, LPFS_score, RS_score, investorState.f) %>% 
  filter(roundType=="trust",!is.na(roundNum)) %>% 
  mutate(roundNum = as.numeric(as.character(roundNum))) %>%
  mutate(inv_scaled = as.vector(scale(investment))) %>% 
  mutate(inv_pct = investment/20, ret_pct_0 = ifelse(investment==0,0,returns/(3*investment)),ret_pct_na = ifelse(investment==0,NA,returns/(3*investment))) 

# Number of people left for analysis. (there are 51 rounds in each game)
#num_participants <- nrow(avg_ret_df)/51
num_participants <- length(unique(avg_ret_df$playerId))

num_participants 

```

```{r}
# Number of participants in manipulation condition
temp_manip <- avg_ret_df %>% filter(condition.f =="Manipulation")

length(unique(temp_manip$playerId))

# Number of participants with high RS

temp_RS <- avg_ret_df %>% filter(high_RS =="high RS")
length(unique(temp_RS$playerId))

```

```{r}
# average investment for first 10 rounds pre manipulation
avg_pct <- avg_ret_df %>% filter(roundNum < 11 , gameNum.f == "pre") %>% summarise(avg_inv = mean(inv_pct), avg_ret = mean(ret_pct_na, na.rm=TRUE))
avg_pct
```

<!-- Linear mixed effects model for all returns  -->

# Behavioral Results

## Analysis of Participant Returns

```{r modAllReturns, include=FALSE, cache=TRUE}
##############  Filter only pre and post games
prepost_df <- avg_ret_df %>% filter(gameNum.f %in% c("pre","post"))
##############
mod_returns_pct_RS <- mixed( ret_pct_na ~ phase.f*condition.f*inv_scaled*high_RS + (1 + phase.f| playerId), prepost_df, REML= TRUE, method="KR")

summary(mod_returns_pct_RS)

```

```{r}
saveRDS(summary(mod_returns_pct_RS), "data/mod_returns_pct_RS.RDS")
```

```{r}
contrasts(prepost_df$phase.f)
contrasts(prepost_df$condition.f)
contrasts(prepost_df$high_RS)
contrasts(prepost_df$investorState.f)
```

```{r prepostByCond, cache=TRUE}
prepost_bycond <- pairs(emmeans::emmeans(mod_returns_pct_RS, c("phase.f"), by = "condition.f", pbkrtest.limit = 6300))
prepost_bycond
```

```{r modemmeans, cache=TRUE, include=F}
library(emmeans)

# Compute EMMs for the interaction of interest
emms <- emmeans(mod_returns_pct_RS, ~ phase.f * condition.f | high_RS, pbkrtest.limit = 6300, adjust="tukey")

contrasts <- contrast(emms, "pairwise", by = c("condition.f", "high_RS"))
summary(contrasts)

results_df <- as.data.frame(summary(contrasts))
```

<!-- EFFECT SIZES -->

```{r}
# Load the necessary packages

library(sjstats)
effectsize::eta_squared(mod_returns_pct_RS)
```

On average, investments and returns, as shown in Figure
\@ref(fig:gamesPlot), fell within the documented range of 40-60% of the
endowment for investments and 35-50% of the total yield for returns, as
reported in previous studies [@charness_investment_2008;
@fiedler_social_2011].

```{r gamesPlot, include=T, echo=FALSE, fig.cap="Averages and standard errors of the trustee's return as a percentage of the multiplied investment received (y-axis) by Condition, Phase, and game round (x-axis) averaged across RS groups. The blue line shows the returns in the Pre phase and the green line those in the Post phase. The left Panel shows returns in the Control condition and the right one those in the Manipulation condition. The dotted lines identify the rounds where the pre-programmed one-off low investment occurs. We note lower average returns post vs pre in the Manipulation condition, whilst returns in the Control condition are similar between the two phases.",fig.align="center", fig.width=6, fig.height = 4}

# Create a data frame for the vertical lines
vline_data <- data.frame(
  xintercept = c(12, 13),
  Defection_round = factor(c("Pre-manipulation", "Post-manipulation"), levels = c("Pre-manipulation", "Post-manipulation"))
)


# Plot
ggplot(avg_ret_df %>% filter(gameNum.f %in% c("pre","post")), aes(x=as.factor(roundNum), y=ret_pct_na, group=gameNum.f, color = gameNum.f, fill=gameNum.f)) +
  stat_summary(fun = mean, geom = "line") +
  stat_summary(fun.data = mean_se, geom = "ribbon", aes(ymin=..ymin.., ymax=..ymax..),
               alpha = 0.3, linetype = 0) +
  geom_vline(data = vline_data, aes(xintercept = xintercept, linetype = Defection_round), color = "black", linewidth = 0.6) +
  scale_linetype_manual(values = c("Pre-manipulation" = "dotted", "Post-manipulation" = "dashed"),name = "Defection round") +
  labs(x = "Round",
       y = "Percentage Return",
       color = "Trust Game Phase") +
  theme_bw() +
  theme(legend.position = "bottom",
        legend.box = "vertical", # This will stack the legends vertically
        legend.key = element_blank(),
        legend.margin = margin(t = 0.2, b = 0.2, unit = "pt"),
        legend.box.margin = margin(t = 0, b = 0, unit = "pt"),
        legend.title = element_text(size = 12),
        legend.text = element_text(size = 10)) +
  scale_color_manual(values = c("darkblue", "darkgreen"),
                     labels = c("Pre-manipulation", "Post-manipulation")) +
  scale_fill_manual(values = c("darkblue", "darkgreen"),
                    guide = "none") + # Hide the fill legend
  guides(color = guide_legend(override.aes = list(fill = NA)))+  # Remove fill for color legend keys
  guides(color = guide_legend(title = "Participant Returns Proportions", override.aes = list(fill = NA)),
         linetype = guide_legend(title = "Defection round")) +
  facet_wrap(~condition.f)


```

Mixed-effects analysis on the percentage returns shows a significant
main effect of Phase (Pre vs. Post RTG game),
`r papaja::apa_print(mod_returns_pct_RS)$full_result$phase_f`, with
higher percentage returns in the Pre RTG compared to the Post.
Importantly, we also find an interaction between Condition and Phase
(RTG pre- vs. post-manipulation),
`r papaja::apa_print(mod_returns_pct_RS)$full_result$phase_f_condition_f`.
As shown in Figure \@ref(fig:boxPlots), post-hoc tests confirm that,
contrary to our expectations, there was a decrease in the percentage
returned only in the Manipulation condition, pre - post,
`r papaja::apa_print(prepost_bycond)$full_result$Manipulation_Pre_post`,
but no change in the Control condition. We find no interaction between
Phase, Condition and RS, suggesting that there was no difference between
RS groups for this interaction.

There was also a significant main effect of Investment,
`r gsub("(\\d{1,3}),(\\d{3})", "\\1\\2", papaja::apa_print(mod_returns_pct_RS)$full_result$inv_scaled)`,
such that higher investments were associated with higher percentage
returns indicating positive reciprocity. An Investment by Condition
interaction,
`r gsub("(\\d{1,3}),(\\d{3})", "\\1\\2", papaja::apa_print(mod_returns_pct_RS)$full_result$condition_f_inv_scaled)`,
reflected that returns were more affected by investments in the Control
condition. We also find a three way interaction between Phase,
Investment and RS,
`r gsub("(\\d{1,3}),(\\d{3})", "\\1\\2", papaja::apa_print(mod_returns_pct_RS)$full_result$phase_f_inv_scaled_high_RS)`,
showing that the differentiated effect of the investment on the
proportion returned by RS group is itself moderated by the Phase (pre-
vs post manipulation). Finally, we find a four-way interaction between
Condition, Phase, Investment and RS
`r gsub("(\\d{1,3}),(\\d{3})", "\\1\\2", papaja::apa_print(mod_returns_pct_RS)$full_result$phase_f_condition_f_inv_scaled_high_RS)`.

<!-- # USING LMER TO LEVERAGE CAPABILITIES WITH EMTRENDS -->

```{r}
library(lmerTest)
library(emmeans)

# Refitting the model directly
direct_model <- lmer(ret_pct_na ~ phase.f * condition.f * inv_scaled * high_RS + (1 + phase.f | playerId), data = prepost_df, REML = TRUE)



emm_res <- emmeans(direct_model, specs = ~ phase.f * condition.f * high_RS * inv_scaled)
trends <- emtrends(direct_model, specs = ~ phase.f * condition.f * high_RS, var = "inv_scaled")

# Print results
summary(emm_res)
summary(trends)

```

```{r}
library(emmeans)


# First, get the estimated marginal means
emm <- emmeans(mod_returns_pct_RS, ~ inv_scaled | phase.f * condition.f * high_RS)

# Then, get the slopes (effects of investment) for each combination
slopes <- emtrends(mod_returns_pct_RS, ~ phase.f * condition.f * high_RS, var = "inv_scaled")
slopes

# Define the contrasts
corrected_contrasts <- list(
  "Diff in inv effect (Post - Pre, Manip, Low RS)" = c(0, 0, -1, 1, 0, 0, 0, 0),
  "Diff in inv effect (Post - Pre, Manip, High RS)" = c(0, 0, 0, 0, 0, 0, -1, 1),
  "Diff in (Post - Pre) between High and Low RS" = c(0, 0, 1, -1, 0, 0, -1, 1)
)

# Test the contrasts with multiple comparison correction
results_4w <- contrast(slopes, method = corrected_contrasts, adjust = "sidak")

# View the results
summary(results_4w)

```

To examine this four-way interaction, we conducted a contrast analysis
of how the effect of investment on returns changed from pre- to
post-manipulation for different RS groups in both conditions. Starting
with the Manipulation condition, for participants with low RS, the
effect of investment on returns increased significantly from pre- to
post-manipulation,
`r papaja::apa_print(results_4w)$full_result$DiffininveffectPost_PreManipLowRS`.
This suggests that after the manipulation, low RS participants became
more responsive to their co-player's investments, returning
proportionally more as investments increased. In contrast, for
participants with high RS, the effect of investment on returns decreased
significantly from pre- to post-manipulation,
`r papaja::apa_print(results_4w)$full_result$DiffininveffectPost_PreManipHighRS`.
This indicates that high RS participants became less responsive to their
co-player's investments after the manipulation, with smaller increases
in returns as investments increased. The difference in these pre-post
changes between high and low RS groups was significant,
`r papaja::apa_print(results_4w)$full_result$DiffinPost_PrebetweenHighandLowRS`.
This result suggests that the manipulation had significantly different
effects on how low and high RS participants responded to their
co-player's investments.

In the Control condition, we observed no significant changes in how
participants responded to their co-player's investments between the pre
and post phases, regardless of their RS level.

```{r}
# Define the contrasts for both conditions
contrasts_ctrl <- list(
  # Control condition contrasts
  "Diff in inv effect (Post - Pre, Control, Low RS)" = c(-1, 1, 0, 0, 0, 0, 0, 0),
  "Diff in inv effect (Post - Pre, Control, High RS)" = c(0, 0, 0, 0, -1, 1, 0, 0),
  "Diff in (Post - Pre) between High and Low RS in Control" = c(1, -1, 0, 0, -1, 1, 0, 0)
)

# Test the contrasts with multiple comparison correction
results_ctrl <- contrast(slopes, method = contrasts_ctrl, adjust = "sidak")

# View the results
print(summary(results_ctrl))
```

```{r fourwayInteractionPlot, include=F, fig.cap ="Visualising the four way interaction between Phase, RS group, Condition and Investment. The plot shows the effect of the investment on participant returns for each condition, phase and RS group. The interesting effect is in the Manipulation Condition: " }


library(ggplot2)

# 
# ggplot(prepost_df, aes(x = inv_scaled, y = ret_pct_na, color = phase.f)) +
#   # geom_point(alpha = 0.6) + # Adjust point transparency with alpha
#   geom_smooth(method = "lm", se = FALSE) + # Add linear regression lines without confidence intervals
#   labs(title = "Effect of inv_scaled on Outcome by Condition",
#        x = "inv_scaled", y = "Outcome") +
#   theme_minimal() +
#   facet_wrap(~high_RS)

# 'inv_scaled' is the continuous predictor, and 'outcome' is your dependent variable.
ggplot(prepost_df, aes(x = inv_scaled, y = ret_pct_na, color = phase.f)) +
  # geom_point(alpha = 0.6) + # Adjust point transparency with alpha
  geom_smooth(method = "lm", se = FALSE) + # Add linear regression lines without confidence intervals
  labs(x = "Investment Z-values", y = "Return proportion", color = "Experiment Phase") +
  theme_minimal() +
  facet_wrap(~condition.f*high_RS)+
  theme(legend.position = "bottom")
  

```

```{r invMod, cache=TRUE}

mod_invs_RS <- mixed( investment ~ phase.f*condition.f*high_RS + (1 + phase.f| playerId), prepost_df, REML= TRUE, method="KR")

summary(mod_invs_RS)
```

```{r}
saveRDS(summary(mod_invs_RS), "data/mod_invs_RS.RDS")
```

```{r violPlotsDef, cache=TRUE}
library(afex)
library(ggplot2)
library(ggsignif)

# Generate the plot with points and error bars
ret_all <- afex_plot(mod_returns_pct_RS, x = "condition.f", trace = "phase.f", dodge = 0.8, error = "within",
                     mapping = c("linetype", "shape", "fill"),
                     factor_levels = list(condition.f = c("Control", "Manipulation")),
                     legend_title = "Phase",
                     emmeans_arg = list(p.adjust.method = "tukey"))

# Extract the data used in afex_plot
plot_data <- ret_all$data

# Generate the plot
ret_all <- ggplot(plot_data, aes(x = condition.f, y = y, color = phase.f, group = phase.f)) +
  geom_point(position = position_dodge(width = 0.8)) +
  geom_errorbar(aes(ymin = y - SE, ymax = y + SE), width = 0.2, position = position_dodge(width = 0.8)) +
  theme_bw() +
  labs(y = "% Returns", x = "Condition", color = "Trust Game Phase") +
  theme(plot.title = element_text(size = 16), legend.position = "bottom") +
  geom_signif(
              annotations = "***", 
              xmin = 1.8, xmax = 2.2,
              y_position = 0.47, 
              tip_length = 0.03, 
              textsize = 3, 
              color = "black")


######################################################################################################

# Generate the plot with points and error bars
inv_all <- afex_plot(mod_invs_RS, x = "condition.f", trace = "phase.f", dodge = 0.8, error = "within",
                     mapping = c("linetype", "shape", "fill"),
                     factor_levels = list(condition.f = c("Control", "Manipulation")),
                     legend_title = "Phase")

# Extract the data used in afex_plot
plot_data <- inv_all$data

# Generate the plot
inv_all <- ggplot(plot_data, aes(x = condition.f, y = y, color = phase.f, group = phase.f)) +
  geom_point(position = position_dodge(width = 0.8)) +
  geom_errorbar(aes(ymin = y - SE, ymax = y + SE), width = 0.2, position = position_dodge(width = 0.8)) +
  theme_bw() +
  labs(y = "HMM Investment", x = "Condition", color = "Trust Game Phase") +
  theme(plot.title = element_text(size = 16), legend.position = "bottom")+
  ylim(9, 11) 


```

```{r boxPlots, include=T,fig.cap="Marginal means and distributions of either investments or percentage returns across participants by Phase and Condition. The top panel shows that participants in the Intervention condition returned lower proportions of the multiplied investment received in the second game compared to the first game over all ronds, whilst those in the Control condition sent back similar returns. The bottom panel shows no difference on aggregate of how the HMM invested across Phases and Conditions. RS did not affect returns and investments by Phase and Condition.",fig.align="center", fig.width=6, fig.height = 8}



library(patchwork)

ret_all/inv_all +  plot_layout(guides = 'collect') & theme(legend.position = "bottom")


```

<!-- Focusing on post defection only:  -->

### Post Defection Trials

```{r postDefMod, cache=TRUE}
post_def_data <- avg_ret_df %>% filter(roundType=="trust",!is.na(gameNum.f),(roundNum >= 12 & gameNum.f =="pre")| (roundNum >= 13 & gameNum.f =="post"))

mod_retPostDef_RS <- mixed( ret_pct_na ~ phase.f*condition.f*inv_scaled + (1 + phase.f| playerId), post_def_data , REML= TRUE, method="KR")

summary(mod_retPostDef_RS)
```

```{r PairsPostDef}
phasePairs <- pairs(emmeans::emmeans(mod_retPostDef_RS, c("phase.f"), pbkrtest.limit = 1449))
phasePairs
```

Did participants learn to be more forgiving and cooperative after
witnessing the pre-programmed defection by the HMM investor? To explore
this question, we restrict the analysis to the trials following the
pre-programmed defection by the HMM agent in both the "pre" (trials 12
to 15) and the "post" phases (trials 13 to 15). We fit the same mixed
effects model as for all the trials with the exception of the RS
variable. This is because RS did not show main effects in the previous
model, and also due to the necessity of running a simpler model to
accommodate the low number of trials. We find a significant main effect
of Phase `r papaja::apa_print(mod_retPostDef_RS)$full_result$phase_f`
with returns lower in the second game post defection trials compared to
the first. We also find a main effect of Investment
`r gsub("(\\d{1,3}),(\\d{3})", "\\1\\2", papaja::apa_print(mod_retPostDef_RS)$full_result$inv_scaled)`
where participants continued to return higher proportions when receiving
higher investments. Finally, we still find an Investment by Condition
interaction
`r gsub("(\\d{1,3}),(\\d{3})", "\\1\\2", papaja::apa_print(mod_returns_pct_RS)$full_result$condition_f_inv_scaled)`
showing a lower effects of investment on the Manipulation condition
compared to the Control condition in post-defection trials. However, the
absence of a Condition by Phase effect indicates there was no difference
between conditions on participants' reaction to a one-off low investment
by the co-player.

<!-- Checking whether Investor behavior has changed dramatically between pre and post: -->

### HMM Investor in Pre and Post Phases

<!-- Linear mixed effects model for investments -->

Was the HMM's strategy similar between pre and post phases in the
control condition? Was participants' behavior post exposure
differentiated enough to induce a different reaction from the HMM? To
answer these questions, we test for differences in the HMM agent's
investment by Phase, Condition and RS using a linear mixed-effects model
as described in the methods section. As seen in Figure
\@ref(fig:boxPlots), we find no main or interaction effects, indicating
the HMM's behavior was on aggregate similar across levels of Phase,
Condition and RS. This consistency in the investor's behavior is a
desirable feature of the HMM agent when the participants behavior is
largely simialr between phases. More importantly, it indicates that the
lower returns of participants in the post phase of the manipulation
condition were not differentiated enough to make the HMM react by
transitioning to lower latent trust states. It is also noteworthy that
the HMM agent was relatively successful in imitating human behavior in
this paradigm: When asked during debrief whether they thought the
investors they faced were human or not, $41$% of participants thought
they were either facing a human or were not sure of the nature of the
co-player. When asked to justify their choice, many answers reflected
participants projecting human traits such as "spitefulness" or "greed"
onto the artificial co-player's behavior.

### Exposure Phase Trials

```{r}
ggplot(avg_ret_df %>% filter(gameNum.f %in% c("expo1","expo2","expo3")), aes(x=as.factor(roundNum), y=ret_pct_na, group=gameNum.f, color = gameNum.f, fill=gameNum.f)) +
  stat_summary(fun = mean, geom = "line") +
  stat_summary(fun.data = mean_se, geom = "ribbon", aes(ymin=..ymin.., ymax=..ymax..),
               alpha = 0.3, linetype = 0) +
  # geom_vline(data = vline_data, aes(xintercept = xintercept, linetype = Defection_round), color = "black", linewidth = 0.6) +
  # scale_linetype_manual(values = c("Pre-manipulation" = "dotted", "Post-manipulation" = "dashed"),name = "Defection round") +
  labs(x = "Round",
       y = "Percentage Return",
       color = "Trust Game Phase") +
  theme_bw() +
  guides(color = guide_legend(override.aes = list(fill = NA)))+  # Remove fill for color legend keys
  guides(color = guide_legend(title = "Participant Returns Proportions", override.aes = list(fill = NA)),
         linetype = guide_legend(title = "Defection round")) +
  facet_wrap(~condition.f)
```

```{r}

expo_df <- avg_ret_df %>% filter(gameNum.f %in% c("expo1","expo2","expo3"))

mod_returns_expo <- mixed( ret_pct_na ~ condition.f*inv_scaled*high_RS + (1 | playerId), expo_df, REML= TRUE, method="KR")
mod_inv_summary <- summary(mod_returns_expo)
mod_inv_summary

em_ret_cond <- emmeans::emmeans(mod_returns_expo , c("condition.f"))
pairs(em_ret_cond)

# Calculate the slopes (coefficients) of inv_scaled for each condition
inv_slopes <- emtrends(mod_returns_expo, ~ condition.f, var = "inv_scaled")

# To see pairwise comparisons of the slopes
print(inv_slopes)
pairs(inv_slopes)

##### Three way interaction
inv_slopes3 <- emtrends(mod_returns_expo, ~ condition.f * high_RS, var = "inv_scaled")
summary(inv_slopes3)

pairwise_comparisons3 <- pairs(inv_slopes3, by = "high_RS")
summary(pairwise_comparisons3)


######### HMM investment in EXPO PHASE 
mod_invs_expo <- mixed(investment ~ condition.f*high_RS + (1 | playerId), expo_df %>% filter(roundNum >= 5), REML= TRUE, method="KR")
summary(mod_invs_expo)

emcheck_inv <- pairs(emmeans::emmeans(mod_invs_expo, c("condition.f"), pbkrtest.limit = 6300))
emcheck_inv
```

So far we focused on analysing behavior for the pre and post phases.
Here, we look at returns and investments in the exposure phase. The
linear mixed effects model of participants' returns in the exposure
phase does not show a main effect of Condition on returns. There was a
main effect of Investment,
`r papaja::apa_print(mod_returns_expo)$full_result$inv_scaled`, with
participants positively reciprocating higher investments, an interaction
effect between Condition and Investment
`r gsub("(\\d{1,3}),(\\d{3})", "\\1\\2",papaja::apa_print(mod_returns_expo)$full_result$condition_f_inv_scaled)`,
showing a stronger positive reciprocity in the Control condition, and
finally a three way interaction between the RS group, Condition and
Investment
`r gsub("(\\d{1,3}),(\\d{3})", "\\1\\2",papaja::apa_print(mod_returns_expo)$full_result$condition_f_inv_scaled_high_RS)`,
showing that this stronger positive reciprocity to investment in the
Control condition is higher for participants with high RS. The linear
mixed effects model of the HMM investments shows a main effect of
Condition `r papaja::apa_print(mod_invs_expo)$full_result$condition_f`,
suggesting higher overall investments for the forgiving HMM compared to
the human-like HMM, but no difference in investments when facing low and
high RS groups.

In summary, despite the forgiving HMM sending overall higher investments
in the exposure phase, participants returned similar proportions of the
multiplied investments as those facing the human-like HMM. The positive
reciprocity of returns to investments was higher in the Control
condition with this relationship stronger for the high RS group.

### Questionnaire Scores and Performance

```{r}

temp2 <- d_finished %>% dplyr::filter(gameNum.f %in% c("pre", "post")) %>%
  dplyr::select(id, payoffTrust1, payoffTrust2, condition.f, RS_score, LPFS_score) %>%
  mutate(perf = payoffTrust1 + payoffTrust2) %>% 
  unique()
cor.test(temp2$LPFS_score, temp2$perf, method = "spearman")
cor.test(temp2$RS_score, temp2$perf, method = "spearman")

cor_result <- cor.test(temp2$RS_score, temp2$LPFS_score, method = "spearman")
# Format the result using papaja
apa_result <- papaja::apa_print(cor_result)

print(apa_result)
# Extract the correlation coefficient and p-value
spearman_rho <- apa_result$estimate

```

Whilst we found a significant correlation between participant's Levels
of Personality Functioning Score (LPFS) and the Rejection Sensitivity
Questionnaire score (RSQ), Spearman's `r spearman_rho`, $p < 0.001$,
there was no correlation between these questionnaire scores and
participant's return or overall task performance.

<!---------------------- Modelling of co-player ratings -------------------------------------->

```{r afexModCoop, cache=TRUE}

mod_rating_coop <- mixed( rating_coop ~ gameNum.f*condition.f*high_RS + (1 | playerId), datRatings, REML= TRUE, method="KR")

summary(mod_rating_coop)

```

```{r emmCoop, cache=TRUE}
# Contrast 1: Pre vs. Post
contrast1 <- c(-1, 0, 0, 0, 1)  

# Contrast 2: Pre vs. (Expo1, Expo2, Expo3) 
contrast2 <- c(-3, 1, 1, 1, 0) 

# Contrast 3: Post vs. (Expo1, Expo2, Expo3) 
contrast3 <- c(0, -1, -1, -1, 3) 

# Combine contrasts into a matrix
contrast_matrix <- rbind(contrast1, contrast2, contrast3)
colnames(contrast_matrix) <- levels(datRatings$gameNum.f) 


# Apply contrasts to the model using 'emmeans'
emm_coop <- emmeans(mod_rating_coop, ~ gameNum.f | condition.f)

# Custom comparisons: use 'contrast' directly
comp1_coop <- contrast(emm_coop, list("Pre vs Post" = contrast_matrix[1,]), by = "condition.f")
comp2_coop <- contrast(emm_coop, list("Pre vs Expo" = contrast_matrix[2,]), by = "condition.f")
comp3_coop <- contrast(emm_coop, list("Post vs Expo" = contrast_matrix[3,]), by = "condition.f")


comp1_coop

comp2_coop

comp3_coop

```

```{r}
# Compute the estimated marginal means (EMMs) for the interaction
emm_coop_interaction <- emmeans(mod_rating_coop, ~ gameNum.f | condition.f * high_RS)

comp1_coop_interaction <- contrast(emm_coop_interaction, list("Pre vs Post" = contrast_matrix[1,]))
comp2_coop_interaction <- contrast(emm_coop_interaction, list("Pre vs Expo" = contrast_matrix[2,]))
# comp3_coop_interaction <- contrast(emm_coop_interaction, list("Post vs Expo" = contrast_matrix[3,]))

# Output the results
print("Pre vs Post")
comp1_coop_interaction
print("Pre vs Expo")
test(comp2_coop_interaction, adjust="bonferroni")
test(comp2_coop_interaction)

# test_comp3_coop_interaction
```

```{r afexModForg}

mod_rating_forg <- mixed( rating_forgiving ~ gameNum.f*condition.f*high_RS + (1 | playerId), datRatings, REML= TRUE, method="KR")

#summary(mod_rating_forg)

```

```{r emmForg}

# Apply contrasts to the model using 'emmeans'
emm_forg <- emmeans(mod_rating_forg, ~ gameNum.f | condition.f)

# Custom comparisons: use 'contrast' directly
comp1_forg <- contrast(emm_forg, list("Pre vs Post" = contrast_matrix[1,]), by = "condition.f")
comp2_forg <- contrast(emm_forg, list("Pre vs Expo" = contrast_matrix[2,]), by = "condition.f")
comp3_forg <- contrast(emm_forg, list("Post vs Expo" = contrast_matrix[3,]), by = "condition.f")


comp1_forg

comp2_forg

comp3_forg

```

```{r}
# Compute the estimated marginal means (EMMs) for the interaction
emm_forg_interaction <- emmeans(mod_rating_forg, ~ gameNum.f | condition.f * high_RS)

comp1_forg_interaction <- contrast(emm_forg_interaction, list("Pre vs Post" = contrast_matrix[1,]))
comp2_forg_interaction <- contrast(emm_forg_interaction, list("Pre vs Expo" = contrast_matrix[2,]))
# comp3_forg_interaction <- contrast(emm_forg_interaction, list("Post vs Expo" = contrast_matrix[3,]))

# Output the results
print("Pre vs Post")
comp1_forg_interaction
print("Pre vs Expo")
comp2_forg_interaction

# test_comp3_forg_interaction
```

```{r afexModAgain}

mod_rating_again <- mixed( rating_playAgain ~ gameNum.f*condition.f*high_RS + (1 | playerId), datRatings, REML= TRUE, method="KR")

#summary(mod_rating_again)

```

```{r emmAgain}

# Apply contrasts to the model using 'emmeans'
emm_again <- emmeans(mod_rating_again, ~ gameNum.f | condition.f)

# Custom comparisons: use 'contrast' directly
comp1_again <- contrast(emm_again, list("Pre vs Post" = contrast_matrix[1,]), by = "condition.f")
comp2_again <- contrast(emm_again, list("Pre vs Expo" = contrast_matrix[2,]), by = "condition.f")
comp3_again <- contrast(emm_again, list("Post vs Expo" = contrast_matrix[3,]), by = "condition.f")


comp1_again

comp2_again

comp3_again

```

```{r}
# Compute the estimated marginal means (EMMs) for the interaction
emm_again_interaction <- emmeans(mod_rating_again, ~ gameNum.f | condition.f * high_RS)

comp1_again_interaction <- contrast(emm_again_interaction, list("Pre vs Post" = contrast_matrix[1,]))
comp2_again_interaction <- contrast(emm_again_interaction, list("Pre vs Expo" = contrast_matrix[2,]))
# comp3_again_interaction <- contrast(emm_again_interaction, list("Post vs Expo" = contrast_matrix[3,]))

# Output the results
print("Pre vs Post")
comp1_again_interaction
print("Pre vs Expo")
comp2_again_interaction

# test_comp3_again_interaction
```

## Player Ratings

Figure \@ref(fig:plotRatings) shows participants' ratings of each player
they faced by condition and RS group. We will focus on two contrasts to
analyse the ratings by Condition and RS group. The first is between the
rating in the first phase ("pre") when participants phase the human-like
HMM, and the average rating during the exposure phase (average of
"expo1", "expo2" and "expo3") where they either face the forgiving HMM
(Manipulation condition) or the human-like HMM again (Control
condition). The second contrast is between the "pre" and "post" phases
of the experiment where in both conditions participants face the same
human-like HMM.

### Comparing Pre and Exposure Ratings

For those with high RS, participants in the Manipulation condition rated
the investors they faced in the exposure phase (the forgiving HMM) as
more Cooperative
`r papaja::apa_print(comp2_coop_interaction)$full_result$Manipulation_HighRS_PrevsExpo`.
There was no difference in ratings on forgiveness and whether they would
like to face the co-players again. Those in the Control condition rated
the investors faced in the exposure group (same HMM) as less cooperative
`r papaja::apa_print(comp2_coop_interaction)$full_result$Control_HighRS_PrevsExpo`,
less forgiving
`r papaja::apa_print(comp2_forg_interaction)$full_result$Control_HighRS_PrevsExpo`,
and were less keen on facing them again
`r papaja::apa_print(comp2_again_interaction)$full_result$Control_HighRS_PrevsExpo`.

For those with low RS, there was no difference in any of the ratings
between the "pre" and "exposure" phases for the Manipulation condition.
For the Control condition, participants indicated less willingness to
face the exposure co-player compared to the "pre" player,
`r papaja::apa_print(comp2_again_interaction)$full_result$Control_LowRS_PrevsExpo`
but also did not differ on cooperation and forgiveness ratings. In
summary, those with low RS had a mostly undifferentiated perception of
players between the pre and exposure phases, even when the co-player was
in fact designed to be more forgiving. In contrast, we see that exposing
participants with high RS to a more cooperative and more forgiving agent
has compensated for the decrease in ratings that would have occurred if
faced with a co-player with the exact same strategy.

```{r plotRatings,include=T, echo=FALSE, fig.pos='H', fig.cap="Averages and standard errors of the participants ratings of the opponent (y-axis) by each game and condition for each phase (x-axis). Pre and post are the 15 round RTGs before and after the exposure phase respectively. The games titled expo 1 to 3 are the three 7 round games during the exposure phase. The blue line represents participants' perception of co-player cooperation, the red line indicates perceived co-player forgiveness, and the green line shows the participants' willingness to play again with the same co-player. Cooperation, forgiveness, and willingness to play again ratings remained relatively stable for the low RS group except post-manipulation, where they were lower. In the high RS group, the ratings more accurately reflected the agent's actual cooperativeness and forgiveness in the Manipulation condition, but decreased over time in the Control group. Ratings were also markedly lower in the post-manipulation game for this group.",fig.align="center", fig.width=6, fig.height = 6}


ggplot(summary_df, aes(x = gameNum.f, y = mean, group = interaction(rating_type, condition.f), color = rating_type)) +
  geom_errorbar(aes(ymin = mean - sem, ymax = mean + sem), width = .1, position = position_dodge(width = 0.25)) +
  geom_line(linetype = "dashed", position = position_dodge(width = 0.25)) +
  geom_point(position = position_dodge(width = 0.25), size = 3) +
  facet_wrap(~high_RS*condition.f, scales = "free_x") +
  labs(x = "Phase", y = "Mean Rating", color = "Rating Type") +
  scale_color_manual(values = c("rating_coop" = "lightblue", "rating_forgiving" = "#FF6961", "rating_playAgain" = "#77DD77"),
                     labels = c("Cooperative", "Forgiving", "Play again")) +
  theme_bw() +
  theme(legend.position = "bottom")


```

```{r}
# temporarily paste code from Figure 2 to compare styles: 
# Plot
ggplot(avg_ret_df %>% filter(gameNum.f %in% c("pre","post")), aes(x=as.factor(roundNum), y=ret_pct_na, group=gameNum.f, color = gameNum.f, fill=gameNum.f)) +
  stat_summary(fun = mean, geom = "line") +
  stat_summary(fun.data = mean_se, geom = "ribbon", aes(ymin=..ymin.., ymax=..ymax..),
               alpha = 0.3, linetype = 0) +
  geom_vline(data = vline_data, aes(xintercept = xintercept, linetype = Defection_round), color = "black", linewidth = 0.6) +
  scale_linetype_manual(values = c("Pre-manipulation" = "dotted", "Post-manipulation" = "dashed"),name = "Defection round") +
  labs(x = "Round",
       y = "Percentage Return",
       color = "Trust Game Phase") +
  theme_bw() +
  theme(legend.position = "bottom",
        legend.box = "vertical", # This will stack the legends vertically
        legend.key = element_blank(),
        legend.margin = margin(t = 0.2, b = 0.2, unit = "pt"),
        legend.box.margin = margin(t = 0, b = 0, unit = "pt"),
        legend.title = element_text(size = 12),
        legend.text = element_text(size = 10)) +
  scale_color_manual(values = c("darkblue", "darkgreen"),
                     labels = c("Pre-manipulation", "Post-manipulation")) +
  scale_fill_manual(values = c("darkblue", "darkgreen"),
                    guide = "none") + # Hide the fill legend
  guides(color = guide_legend(override.aes = list(fill = NA)))+  # Remove fill for color legend keys
  guides(color = guide_legend(title = "Participant Returns Proportions", override.aes = list(fill = NA)),
         linetype = guide_legend(title = "Defection round")) +
  facet_wrap(~condition.f)


```

```{r}
library(ggplot2)

ggplot(summary_df, aes(x = gameNum.f, y = mean, group = interaction(rating_type, condition.f))) +
  geom_errorbar(aes(ymin = mean - sem, ymax = mean + sem, color = condition.f), 
                width = .1, position = position_dodge(width = 0.25)) +
  geom_line(aes(color = condition.f), linetype = "dashed", position = position_dodge(width = 0.25)) +
  geom_point(aes(color = condition.f), position = position_dodge(width = 0.25), size = 3) +
  facet_grid(high_RS ~ rating_type, scales = "free_x") +
  scale_color_manual(values = c("Control" = "blue", "Manipulation" = "red")) +
  labs(x = "Phase", y = "Mean Rating", color = "Condition") +
  theme_minimal() +
  theme(legend.position = "bottom")


```

### Comparing Pre and Post Ratings

<!-- Comparing post-exposure to exposure ratings, participants in the Manipulation condition rated the investors they faced in the exposure phase as less cooperative,  -->

<!-- `r papaja::apa_print(comp3_coop)$full_result$Manipulation_PostvsExpo`, less forgiving `r papaja::apa_print(comp3_forg)$full_result$Manipulation_PostvsExpo`, and were less willing to face them again `r papaja::apa_print(comp3_again)$full_result$Manipulation_PostvsExpo`. Ratings for those in the Control group did not differ on how cooperative, forgiving the investors were, and on willingness to face them again.  -->

Participants high on RS in the Manipulation condition rated the
co-players in the "post" phase similarly on cooperation, lower on
forgiveness
`r papaja::apa_print(comp1_forg_interaction)$full_result$Manipulation_HighRS_PrevsPost`,
and lower on willingness to face them again
`r papaja::apa_print(comp1_again_interaction)$full_result$Manipulation_HighRS_PrevsPost`.
Those in the Control condition rated the investors post the exposure
phase lower on all three attributes (Cooperation:
`r papaja::apa_print(comp1_coop_interaction)$full_result$Control_HighRS_PrevsPost`,
Forgiveness:
`r papaja::apa_print(comp1_forg_interaction)$full_result$Control_HighRS_PrevsPost`,
Play again:
`r papaja::apa_print(comp1_again_interaction)$full_result$Control_HighRS_PrevsPost`).

For participants low on RS, those in the Manipulation condition rated
the co-players in the "post" phase lower on all three attributes
(Cooperation:`r papaja::apa_print(comp1_coop_interaction)$full_result$Manipulation_LowRS_PrevsPost`,
Forgiveness:
`r papaja::apa_print(comp1_forg_interaction)$full_result$Manipulation_LowRS_PrevsPost`,
Play again:
`r papaja::apa_print(comp1_again_interaction)$full_result$Manipulation_LowRS_PrevsPost`).
Those in the Control condition did not differ in their ratings of the
"pre" and "post" phase players.

In summary, we again see that those with low RS accurately perceive the
co-player as similar on all attributes throughout the phases in the
Control condition. In contrast, the high RS group shows a negative bias
towards the co-players after the "pre" phase in the Control condition
even though the player continues to use the same strategy. After
exposure to the forgiving HMM, both groups rate the "post" co-player
worse than the "pre" even though they are the same.

```{r}
d_finished %>% 
  dplyr::select(id,Turing.choice) %>% 
  unique() %>% 
  group_by(Turing.choice) %>%
  summarise(Count = n()) %>%
  mutate(Percentage = (Count / sum(Count)) * 100)
```

<!-- Extracting Investor latent state from data -->

```{r extractInvStates}

library(tidyverse)

# Convert dataset from wide to long format, focusing on columns that start with "State_"
d_long <- d_finished %>%
  dplyr::select(id, condition.f, gameNum.f, gameNumber, roundNum, investorState.f) %>% 
  drop_na()
# View the resulting dataset
print(d_long)

```

```{r InvStatePlot}
library(ggplot2)
library(dplyr)

# Filter for only games 1 and 2
filtered_prepost <- d_long %>%
  filter(gameNum.f %in% c("pre", "post"))

# Define the colors for the levels of investorState

state_colors <- c("happy" = "Blue", "neutral" = "#77DD77", "unhappy" = "#FF6961")

# Create the histogram with stacked bars and specified colors
ggplot(filtered_prepost, aes(x = as.factor(roundNum), fill = investorState.f)) +
  geom_bar(aes(group = investorState.f), position = position_stack(reverse = FALSE), stat = "count") +
  scale_fill_manual(values = state_colors) +
  facet_wrap(~condition.f*gameNum.f, scales = "free_x", labeller = label_both) +
  labs(x = "Round", fill = "Investor State", title = "Histogram of Latent HMM Investor States per Game and Round") +
  theme_bw() +
  theme(legend.position = "bottom")

```

```{r}
# Filter for expo games only
filtered_expo <- d_long %>%
  filter(gameNum.f %in% c("expo1", "expo2", "expo3"))

# Create the histogram with stacked bars and specified colors
ggplot(filtered_expo, aes(x = as.factor(roundNum), fill = investorState.f)) +
  geom_bar(aes(group = investorState.f), position = position_stack(reverse = FALSE), stat = "count") +
  scale_fill_manual(values = state_colors) +
  facet_wrap(~condition.f*gameNum.f, scales = "free_x", labeller = label_both) +
  labs(x = "Round", fill = "Investor State", title = "Histogram of Latent States per Game and Round") +
  theme_bw() +
  theme(legend.position = "bottom")
```

<!------------------------ AVERAGING LATENT STATE COUNT ACROSS TRIALS ----------------------------->

```{r}
counts <- filtered_prepost %>%
  group_by(condition.f, gameNum.f, investorState.f,id) %>%
  summarise(count = n()) %>%
    summarise(count = sum(count))
  
# Calculate the average count per state per condition
total_rounds <- filtered_prepost  %>%
  group_by(condition.f, gameNum.f) %>%
  summarise(total_rounds = n()) 

state_summary  <- counts %>%
  left_join(total_rounds, by = c("condition.f", "gameNum.f")) %>% 
  mutate(state_percentage = count/total_rounds)

ggplot(state_summary , aes(x = gameNum.f, y = state_percentage, fill = investorState.f)) +
  geom_bar(stat = "identity") +
  facet_wrap(~condition.f) +
  labs(x = "Condition", y = "Proportion", fill = "Investor State") +
  theme_bw() +
  theme(legend.position = "bottom")

state_colors <- c("happy" = "Blue", "neutral" = "#77DD77", "unhappy" = "#FF6961")

# Create the histogram with stacked bars and specified colors
ggplot(state_summary , aes(x = gameNum.f, y = state_percentage, fill = investorState.f)) +
  geom_bar(aes(group = investorState.f), position = position_stack(reverse = FALSE), stat = "identity") +
  scale_fill_manual(values = state_colors) +
  facet_wrap(~condition.f*gameNum.f, scales = "free_x", labeller = label_both) +
  labs(x = "Round", fill = "Investor State", title = "Histogram of Latent States per Game and Round") +
  theme_bw() +
  theme(legend.position = "bottom")
```

# Discussion

We used a randomized controlled online experiment where participants
played a RTG with artificial agents designed to simulate human-like
trust-building scenarios. Participants were then exposed to either
forgiving or human-like HMM agents before playing another RTG. We found
that RS did not moderate participants' returns as trustees in the
repeated trust game. While previous research has shown that RS affects
*trust* formation, appraisal and repair, its impact on *reciprocity* in
repeated economic exchanges has been less explored. Our results suggest
a potential dissociation between RS's known effects on broader social
behavior and its limited influence on reciprocity in structured,
repeated interactions, challenging assumptions about the pervasive
influence of RS on social behavior and highlighting the complexity of
factors influencing reciprocity in economic exchanges.

Contrary to our hypothesis, exposure to forgiving agents did not
increase participant's reciprocity or cooperation, nor did it prompt the
artificial agent to increase their trust in participants through higher
investments. Instead, participants reduced their returns overall whilst
the returns of those in the Control group did not change between the pre
and post phase of the experiment. Why did participants reduce their
returns even though they were repeatedly exposed to more cooperative and
more forgiving artificial agents? A look at how the participants rated
their co-players might shed some light on what might be driving this
reduction in returns for those in the Manipulation condition. Those
exposed to the forgiving agent rated their opponent in the post-exposure
phase lower on all attributes even though they faced the same dynamic
human-like HMM as pre-exposure. One possible explanation for this drop
in rating is that participants exhibited a negative contrast effect.
This occurs when the evaluation of a person, object, or situation is
influenced by comparisons with recently encountered contrasting objects
or people. If we've repeatedly interacted with someone exceptionally
nice, our perception of a normal level of niceness might be skewed,
making typical behavior seem less favourable or even negative by
comparison [@kobre_negative_1972]. As the most recently faced opponents
were more forgiving and cooperative, this negative contrast effect may
have trumped any learning transfer from being repeatedly exposed to
forgiving agents [@zentall_within-trial_2005]. If this contrast effect
is indeed replicable, then an avenue for future research would be to use
it to our benefit by making the participants play agents with low
cooperation perception.

This effect appears to operate independently of RS, as both groups
exhibited it. However, RS did influence how participants perceived and
reacted to their co-players' behavior. High RS individuals demonstrated
a heightened attunement to changes in their co-players' behavior,
accurately perceiving increased cooperativeness in the forgiving agent.
Paradoxically, this same sensitivity may explain their decreased
reactivity to investment levels and declining ratings of similar
co-players over time in the Control condition. Occasional pre-programmed
defections may have amplified their perceptions of untrustworthiness,
leading to a more cautious approach and less responsiveness to
investment variations. This aligns with the heightened social awareness
and vigilance often associated with high RS [@downey_implications_1996].
This finding suggests that individuals with high RS might benefit from
interventions that focus on calibrating their perceptions of social cues
in economic exchanges. In contrast, low RS individuals were less
affected by the agent's behavioral variations, showing a more stable
baseline of social perception. This stability in perception might
reflect a lower propensity to scrutinize social cues or a more robust
internal model of social interactions that is less easily perturbed by
short-term variations in partner behavior. Their increased
responsiveness to investments post-exposure in the Manipulation
condition suggests they may have internalized the cooperative norms
experienced, carrying over this increased reciprocity to subsequent
interactions.

Despite these differences in perception and investment reactivity, the
actual cooperative behavior – as measured by returns in the trust game –
did not significantly differ between RS groups. This suggests a
potential dissociation between the cognitive-perceptual processes
involved in evaluating social partners and the behavioral output in
economic games. There are multiple potential explanations for this:
First, the ratings may reflect explicit, conscious evaluations of social
partners, while behavior in the trust game might be guided more by
implicit, automatic processes that are less differentiated between RS
groups. This interpretation aligns with dual-process theories of social
cognition [@lieberman_social_2007]. Second, the structured nature of the
trust game might provide a context where the behavioral expression of RS
is attenuated. In contrast, the more open-ended nature of providing
ratings might allow for greater expression of RS-related perceptual
biases.

These findings have important implications for interventions aimed at
promoting trust and cooperation. Simply exposing individuals to
artificially highly cooperative or forgiving partners may not suffice to
induce lasting changes in behavior, and may even lead to negative
contrast effects. Instead, interventions should focus on developing
adaptive strategies for navigating the complexities of real-world social
interactions, which often involve a mix of cooperative and
non-cooperative behaviors. Such approaches could gradually shape
expectations and behaviors over time, taking into account individual
differences in RS. For individuals with high RS, interventions might
specifically target the calibration of social perceptions in economic
exchanges, helping to bridge the gap between their heightened
sensitivity to social cues and their actual cooperative behavior. Future
research should investigate whether the observed dissociation between
perception and behavior persists in more naturalistic social
interactions or over longer periods. Additionally, exploring the
temporal dynamics of these effects and the role of explicit
communication in the cooperative process could offer valuable insights.
Interventions combining realistic cooperative scenarios with clear
communication about mutual expectations might prove more effective in
fostering enduring cooperative tendencies that are robust across various
social contexts [@balliet_reward_2011].

## Limitations

While this study offers valuable insights into trust and cooperation
dynamics in social interactions mediated by artificial agents, several
limitations warrant consideration. The artificial nature of the
interactions, while enabling high experimental control, may limit
ecological validity, particularly regarding the paradigm's ability to
trigger rejection sensitivity in participants. Additionally, the
relatively brief exposure to forgiving HMM agents during the
manipulation phase may have been insufficient to induce lasting changes
in participants' reciprocity behavior. The online format of the
experiment eliminates important social cues present in face-to-face
interactions, which might influence trust and cooperation differently.
Although the RSQ is a well-validated measure of rejection sensitivity
(RS), future studies could benefit from a multi-method approach,
potentially incorporating behavioral measures or additional self-report
scales for a more comprehensive RS assessment. Furthermore, while our
use of HMM agents to simulate human-like behavior in economic games is
innovative, some participants may have suspected they were interacting
with AI, potentially confounding the results. Despite these limitations,
our findings provide a foundation for future research. Subsequent
studies could address these constraints by incorporating face-to-face
interactions, utilizing multiple measures of RS, examining the long-term
effects of exposure to forgiving interaction partners, and developing
more convincing cover stories or explicitly comparing responses to human
and computerised partners.

## Constraints on Generality

The results may be specific to adults with high or low RS recruited from
online platforms, and may not generalize to clinical populations,
children, or older adults. Our use of a computerized Repeated Trust Game
with HMM agents, while allowing for high experimental control, may limit
generalizability to face-to-face interactions or games with different
economic structures. The brief exposure phase and pre-programmed
defections are specific to our design and may not reflect real-world
trust-building scenarios. The online context may not capture all aspects
of high-stakes or information-rich interactions. We believe the core
finding of decreased cooperation after exposure to forgiving agents
should generalize across different populations and contexts, though the
effect's strength and its interaction with RS may vary. While the
specific economic game, agent representation, and perception assessment
questions could be varied, the use of artificial agents with consistent
behavior, an exposure phase with more forgiving behavior, and assessment
of both behavior and perceptions should remain constant to preserve the
results. Future studies could systematically vary these factors to
establish the boundaries of generalizability for our findings.
Additionally, cultural differences in norms of cooperation and trust may
influence the generalizability of these findings, necessitating
cross-cultural replications to establish the universality of the
observed effects.

# Conclusion

This randomised controlled experiment enabled us to uncover unexpected
effects of exposure to forgiving behavior on subsequent cooperation,
particularly in relation to RS. These findings challenge existing
assumptions about fostering cooperative behavior and suggest the need
for more nuanced interventions. Importantly, the use of HMM-based
artificial agents in this study represents a significant methodological
advancement. By providing a balance between experimental control and
realistic, adaptive behavior, these agents allowed for a nuanced
exploration of trust dynamics that would be challenging to achieve with
human confederates or simplistic computer algorithms. This approach
opens up new possibilities for studying complex social interactions in
controlled settings, potentially bridging the gap between laboratory
experiments and real-world social dynamics.

\pagebreak

# Author contributions statement {.unnumbered}

I. Guennouni, G. Koppe and C. Korn. designed and developed the study
concept. Experiment design, testing and data collection were performed
by I. Guennouni. I. Guennouni analysed and interpreted the data under
the supervision of G. Koppe and C. Korn. All authors jointly wrote and
approved the final version of the manuscript for submission.

# Funding {.unnumbered}

This study was supported by the Federal Ministry of Science, Education,
and Culture (MWK) of the state of Baden-Württemberg within the AI Health
Innovation Cluster Initiative, the German Research Foundation (DFG)
within the Excellence Strategy EXC 2181/1 – 390900948 (STRUCTURES), and
the Hector II foundation. I. Guennouni was supported by a research
fellowship from the AI Health Innovation Cluster.

# Competing interests statement {.unnumbered}

The author(s) declared that there were no conflicts of interest with
respect to the authorship or the publication of this article.

# Acknowledgements {.unnumbered}

We are grateful to Tobias Nolte, Andreas Hula and Read Montague's team
at Virginia Tech for sharing with us the data on the RTG allowing us to
fit the HMM to investor data. We're also grateful for Samuel Dupret for
help designing the online platform used for the experiment and Maarten
Speekenbrink for his guidance on the use of HMM models.

# Additional information {.unnumbered}

## Correspondence {.unnumbered}

All correspondence and requests for materials should be addressed to I.
Guennouni.

## Transparency and data availability {.unnumbered}

Preregistration: The hypotheses and methods were not preregistered.The
analysis plan was not preregistered. Materials: All study materials are
publicly available (<https://github.com/ismailg/exposure-public>). Data:
All primary data are publicly available
(<https://github.com/ismailg/exposure-public>). Analysis scripts: All
analysis scripts are publicly available
(<https://github.com/ismailg/exposure-public>).

# References
