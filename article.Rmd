---
title: "When Forgiveness Backfires: Rejection Sensitivity and Cooperative Behavior Following Exposure to Adaptive Forgiving Agents"

author:
  "Ismail Guennouni^1^*, Georgia Koppe^2^, Christoph Korn^3^"

abstract: |
  Can exposure to forgiving behavior improve cooperative outcomes, and does Rejection Sensitivity (RS) moderate this effect?  This randomized controlled experiment explores these questions using a novel approach with Hidden Markov Model (HMM)-based artificial agents in repeated trust games (RTGs). Participants (N = 206), pre-screened for high or low RS, interacted with either consistently behaving or more forgiving co-players, which were in reality HMM agents. Unexpectedly, exposure to forgiving agents led to reduced cooperation in subsequent interactions. Control group participants maintained consistent behavior. RS levels influenced perceptions of the agent's cooperativeness but did not significantly affect behavioral outcomes, revealing a perception-behavior dissociation. These findings challenge assumptions about fostering cooperation through simple exposure to positive interactions and highlight the importance of accounting for negative contrast effects when designing such interventions. They also demonstrate the potential of HMM-based artificial agents for studying interactive social dynamics, offering a methodological advancement for future research. Our results suggest the need for nuanced interventions that gradually shape expectations and behaviors to foster cooperative outcomes, particularly for individuals with high rejection sensitivity.

bibliography: "bib/exposure.bib"
biblio-style: spphys
output:
  bookdown::pdf_document2:
    keep_tex: true
    toc: false
header-includes:
  - \usepackage{lscape}
---
\small
^1^ *Central Institute of Mental Health, Medical Faculty Mannheim/Heidelberg University, Germany*

^2^ *Faculty of Mathematics and Computer Science, Heidelberg University, Germany*

^3^ *Department of General Psychiatry, Section Social Neuroscience, Heidelberg University, Germany*

^\*^ *Corresponding author. Address: Central institute of Mental Health, J5, Mannheim, Germany. Email: ismail.guennouni@zi-mannheim.de* <br>

\vspace{1cm}


**Keywords** : Social Trust; Forgiveness Intervention; Rejection Sensitivity; Interpersonal Dynamics; Hidden Markov Models

\vspace{1cm}

**Highlights:** 

- Exposure to forgiving artificial agents unexpectedly led to reduced cooperation in subsequent interactions, challenging assumptions about fostering trust through positive experiences

- Rejection sensitivity influenced perceptions of artificial agents' cooperativeness but not behavioral outcomes, revealing a dissociation between perception and behavior

- Novel Hidden Markov Model-based artificial agents provide adaptive, human-like behavior in trust games, allowing for precise control of "cooperative" and "forgiving" strategies while maintaining experimental control of co-player strategies


\pagebreak


```{r setupCoax, include=FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE, echo = FALSE, include=FALSE) 
knitr::opts_chunk$set(out.width = "\\textwidth")
```


```{r load-packages05}
library(papaja)
library(kableExtra)
require(knitr)
#require(citr)
require(bookdown)

# using some functions dplyr, ggpubr, PairedData and sjPlot. Need to be loaded. 
library(tidyverse)
library(afex)
library(PairedData)
library(multcompView)
library(lsmeans)
library(depmixS4)
library(flextable)
library(grid)
library(gridExtra)
library(forcats)
library(ggsignif)
library(magick)


```

```{r analysis-preferences, include = FALSE}
# Seed for random number generation
set.seed(42)
options(tinytex.verbose = TRUE)
```

```{r emmOptions}
emm_options(pbkrtest.limit = 6210)
emm_options(lmerTest.limit = 6210)

```

# Introduction 


Trust is fundamental to human social interactions, facilitating seamless relations at both interpersonal and intergroup levels. The study of psychopathology has linked deficits in trust-based constructs to the development of mental health disorders [@fonagy_mentalizing_2017]. Individuals with personality disorders (PD) often struggle to form and maintain social connections, a difficulty reflected in uncooperative behaviors – a marker for the severity of PD symptoms [@herpertz_social-cognitive_2014; @mulder_relationship_1999].

One explanation for such social challenges lies in early caregiver experiences. Attachment theory [@bowlby_attachment_1978] suggests that the quality of these relationships shapes our capacity for secure attachments and trust. Individuals with higher levels of insecure attachment may recall negative trust-related experiences more easily, report fewer positive trust experiences, and use less constructive coping strategies when trust is broken [@mikulincer_attachment_1998]. These insecure attachment patterns are often associated with heightened rejection sensitivity (RS), a tendency to anxiously expect, readily perceive, and intensely react to rejection [@downey_implications_1996; @downey_early_1997]. RS has been linked to the development of various mental health conditions, including depression, anxiety, personality disorders, and self-harm [@gao_associations_2017]. A recent meta-analysis revealed prosocial behavior and interpersonal trust as two key processes of interpersonal functioning that are markedly impaired in PDs and which are likely to contribute to interpersonal dysfunction in this population [@hepp_prosociality_2022]. The interaction of rejection sensitivity and trust-based constructs has been explored, particularly in Borderline Personality Disorder (BPD). @miano_rejection_2013 and @richetin_emotional_2018 found that rejection sensitivity mediated the relationship between BPD features and lower trust appraisal. @abramov_influence_2022-1 found that higher baseline feelings of rejection in individuals with BPD predict slower trust formation and less pronounced declines in trust following trust violations during the trust game. However, the interaction between trustworthiness and rejection sensitivity hasn't been studied as extensively in other personality disorders or in non-clinical populations, leaving a gap in our understanding of how these constructs might interplay. Could an ingrained sensitivity to rejection contribute to reduced pro-social behavior such as a failure to show trustworthiness?

If indeed RS contributes to interpersonal dysfunction through failure to show trustworthiness, could exposing those who exhibit it to cooperative and forgiving interaction partners lead to improved interpersonal outcomes? Research in the fields of behavioral economics and psychology has explored how positive social interactions influence cooperation and pro-social behavior. The use of the repeated trust game (RTG), a well-established experimental approach, has allowed for the analysis of the development of trust through ongoing interactions [@joyce_trust_1995]. In this paradigm, cycles of mutual trust, where each party's trust is reciprocated with trustworthiness, have the effect of enhancing cooperative behaviors even among individuals who are initially inclined to be distrustful [@king-casas_getting_2005]. @fowler_cooperative_2010 studied behavior in social networks interacting in a public goods game and found that cooperative behavior tends to cluster, suggesting that exposure to cooperative peers can lead to more cooperative behavior. Similarly, research on social learning theory [@bandura_social_1977] has long demonstrated that individuals learn and model the behavior of those around them, indicating that if someone is consistently exposed to cooperative and positive individuals, they're likely to emulate this behavior. These insights highlight that engaging with compassionate and forgiving others can be an effective method for mitigating deeply ingrained mistrust and potentially fostering trustworthy behavior.

In this study, we use a randomized controlled online experiment to test whether exposing participants with varying RS levels to forgiving and more cooperative co-players results in more trustworthy behavior and a repair of potential breakdowns in RTG cooperation. To simulate realistic social interaction while maintaining a high degree of experimental control, we take a novel paradigmatic approach: We use generative models of how humans play the RTG to design an agent that plays the role of the investor, based on Hidden Markov Models (HMMs) fitted to real players' data. A key aspect of these agents is that their actions depend on a latent "trust state" which reacts dynamically to the trustees' returns, simulating real-life trust-building scenarios. An advantage of having such a generative model of behavior is the possibility of controlling different aspects of the agent's strategy such as its general policy, the propensity to cooperate actively, or the propensity to retaliate after breakdowns of cooperation.

We pre-screened participants for high or low rejection sensitivity (RS) using a validated questionnaire, then assigned them exclusively to the trustee role in a series of trust games. After playing a 15-round RTG with a human-like HMM investor, they were randomly assigned to either a Control or Manipulation condition. In the Manipulation condition, participants were exposed over three RTGs to HMM investors designed with a limited propensity for retaliation, potentially mitigating ingrained mistrust. In the Control condition, participants played three RTGs against the same human-like HMM. After this exposure phase, all participants played another 15-round RTG with a human-like HMM investor. We expect those exhibiting high RS to be more responsive to the pre-programmed change in the agent's cooperativeness and retaliation propensity. We also hypothesize that those in the Manipulation condition would behave more cooperatively and have a lower propensity to retaliate to the co-player's defection after the exposure phase, with those in the higher RS group showing a bigger effect. 

# Methods

```{r loadData}

load("data/d_finished.RData")

# Step 1: Identify the expo_opponent for each playerId where gameNumber == "11" (exposure game) & isLastRound == TRUE (to select a particular)
expo_opponent_df <- d_finished %>%
  filter(gameNumber == "11", isLastRound == TRUE) %>%
  dplyr::select(id, expo_opponent = game_opponent) %>%
  distinct() # Ensure uniqueness in case of duplicates

# Step 2: Join this information back to the original dataset
d_finished <- d_finished %>%
  left_join(expo_opponent_df, by = "id") %>%
  mutate(condition.f = factor(expo_opponent, levels= c("AI_HMM","AI_HMM_nice"),
                              labels=c("Control","Manipulation"))) %>%
  dplyr::select(-expo_opponent) # remove the expo_opponent column if it's no longer needed


# Step 3:  create binary : high or low RS
d_finished <- d_finished %>%
  mutate(high_RS = factor(ifelse(RS_score > 15, 1, 0), 
                                    levels = c(0, 1), 
                                    labels = c("low RS", "high RS"))) 


# Summarize to count the number of participants for each Condition within each high_RS level
temp <- d_finished %>% dplyr::select(id, condition.f, high_RS) %>% 
                      unique() %>%
                      group_by(high_RS, condition.f) %>%
                      summarize(participant_count = n(), .groups = 'drop')

# View the summarized counts
print(temp)

###################### Extract latent Investor State in each round ####################

# Select the desired columns
d_selected <- d_finished %>%
  dplyr::select(roundNum, gameNumber, playerId, starts_with("State_"))

# Reshape the data
d_reshaped <- d_selected %>%
  pivot_longer(cols = starts_with("State_"), 
               names_to = "State_name", 
               values_to = "investorState") %>%
  mutate(roundNum = as.numeric(str_extract(State_name, "(?<=r)\\d+")),
         gameNumber = as.numeric(str_extract(State_name, "(?<=game_)\\d+"))) %>%
  dplyr::select(playerId, gameNumber, roundNum, investorState) %>%
  arrange(playerId, gameNumber, roundNum) %>%
  filter(!is.na(investorState)) %>% unique()

# Join the reshaped data back to the original dataset
d_finished <- d_finished %>%
  dplyr::select(-investorState) %>% 
  left_join(d_reshaped, by = c("playerId", "gameNumber", "roundNum"))
```

## Participants 

To have participants with large differences in RS, a total of 1195 participants were pre-screened on the Prolific Academic platform (prolific.co) using the Rejection Sensitivity Questionnaire (RSQ) to finally select two similarly sized groups: One with high RS (RSQ score > 15) and the other with low RS (RSQ score < 10) totalling 206 participants (56% female). These were then invited through prolific to take part in the main experiment study. The required sample size was determined using an a priori power analysis to have an 80% probability to detect a small effect size with a 5% type I error rate in a repeated measures ANOVA with between factors. The mean age of participants was 34.6 years, with an 11.9 years standard deviation. Participants were paid a fixed fee of £6 plus a bonus payment dependent on their performance that averaged £0.5. 

## Design and Procedure

The experiment had a 2 (Condition: Manipulation or Control) by 2 (RS : High or Low) by 2 (Game: Trust-Game Pre Manipulation, Trust-Game Post Manipulation) design, with repeated measures on the third factor (Figure \@ref(fig:HMMPanels).A). Participants within each pre-screened group were randomly assigned to one of the two levels of the Condition factor. The games were designed and implemented online using Empirica v1 [@almaatouq_empirica_2021]. The planned experiment received approval from the University of Heidelberg's Medical Faculty ethics commission (ID:S-708/2023) and the experiment was performed in accordance with the ethics board guidelines and regulations. All participants provided informed consent prior to their participation. 


## Tasks and Measures




```{r, include=FALSE}
Anti_social <-  c(0.1025436430408, 0.1221931236853, 0.1345215238995,
0.1368182252617, 0.1285592471751, 0.1116014322677, 0.0895041220882,
0.0663166721334, 0.0453950277118, 0.0287077419587, 0.0167723588011,
0.0090530028158, 0.0045143317507, 0.0020796744990, 0.0008851094702,
0.0003480141146, 0.0001264134789, 0.0000424213859, 0.0000131513231,
0.0000037665630, 0.0000009965755)

Neutral <- c(0.003393529, 0.006930874, 0.013053553, 0.022671228,
0.036310144, 0.053627606, 0.073039389, 0.091734929, 0.106248217,
0.113479701, 0.111769796, 0.101517390, 0.085028780, 0.065675083,
0.046778251, 0.030725245, 0.018610323, 0.010394861, 0.005354126,
0.002543094, 0.001113881)

Pro_social <- c(0.003162697, 0.001057162, 0.001410197, 0.001881016,
0.002508877, 0.003346113, 0.004462480, 0.005950950, 0.007935434,
0.010581067, 0.014107909, 0.018809194, 0.025075644, 0.033427845,
0.044559370, 0.059394206, 0.079163228, 0.105506029, 0.140606514,
0.187373417, 0.249680651)

investment <- seq(0:20) -1

response_probs <- as.data.frame(cbind(investment,Anti_social,Neutral,Pro_social)) %>% 
  rename("low-trust" = "Anti_social", "medium-trust"="Neutral", "high-trust" = "Pro_social") %>%
  pivot_longer(cols=c("low-trust","medium-trust","high-trust"),
                    names_to='Investor_state',
                    values_to='probability') %>% 
   mutate(across(Investor_state, factor, levels=c("low-trust","medium-trust","high-trust")))
```

```{r, include=F}

plotinvHMM <- ggplot(response_probs,                            
       aes(x = investment,
           y = probability,
           fill = Investor_state)) +
  geom_bar(stat = "identity",
           position = "dodge") + 
  labs(fill='Latent investor state', x = "Investment", y= "Probability") + 
  theme_bw() + 
  theme(legend.position = "bottom",  legend.text = element_text(size = 12),  legend.title = element_text(size = 14))
  
plotinvHMM
```




```{r, include=FALSE}

# Parameters for HMM human-like Transition Function
unhappy_pars <- rbind(c(0,0), c(-3.366027, 0.40910797 ), c(-3.572619,0.08137274)) 
neutral_pars <- rbind(c(0,0), c(3.3142637, 0.3763408), c(0.9169736, 0.4502838))
happy_pars   <- rbind(c(0,0), c(0.7134085, 0.02101626), c(2.2215478 ,0.16162964))

pars_inv <- list(unhappy_pars, neutral_pars, happy_pars)


# Parameters for HMM nice Transition Function
unhappy_pars_nice <- rbind(c(-10,0), c(-3.366027, 0.40910797 ), c(-3.572619,0.08137274)) 
neutral_pars_nice <- rbind(c(0,0), c(3.3142637, 0.3763408), c(0.9169736, 0.4502838))
happy_pars_nice   <- rbind(c(0,0), c(0.7134085, 0.02101626), c(2.2215478 ,0.16162964))

pars_inv_nice <- list(unhappy_pars_nice, neutral_pars_nice, happy_pars_nice)



plot_HMM_transitions <- function(ns, pars_mat) {

  trans_prob <- data.frame(
    from = rep(1:ns, each=100*ns),
    to = rep(1:ns, each=100),
    ret = seq(-20,60,length=100),
    probs = 0
  )
  
  
  y <- matrix(0.0,ncol=ns, nrow=100)
  
  for(from in 1:ns) {
  pars <- matrix(pars_mat[[from]], ncol=2)
  # print(pars)
  
    for(to in 1:ns) {
        x <- trans_prob[trans_prob$from == from & trans_prob$to == to,"ret"]
        y[,to] <- exp(pars[to,1] + pars[to,2]*x)
    }
    y <- y/rowSums(y)

    
    for(to in 1:ns) {
      trans_prob$probs[trans_prob$from == from & trans_prob$to == to] <- y[,to]
    }
  }
  
  df <- as.data.frame(trans_prob) %>% 
    mutate(from = recode(from, "1" = "low-trust", "2" = "medium-trust", "3" = "high-trust"),
           to = recode(to, "1" = "low-trust", "2" = "medium-trust", "3" = "high-trust") ) %>% 
    mutate(across(from, factor, levels=c("low-trust","medium-trust","high-trust"))) %>% 
    mutate(across(to, factor, levels=c("low-trust","medium-trust","high-trust")))
                                    
  
    # Create a separate data frame with the background colors
  bg_colors <- data.frame(
    from = factor(c("low-trust", "medium-trust", "high-trust"), levels=c("low-trust","medium-trust","high-trust"))
  )
  
  # plotting code...
  ggplot() +
    geom_rect(data = bg_colors, aes(xmin = -Inf, xmax = Inf, ymin = -Inf, ymax = Inf, fill = from), alpha = 0.1) +
    geom_line(data = df, aes(x = ret, y = probs, colour = as.factor(to))) +
    facet_wrap(~from, labeller = labeller(from = function(x) paste("From", x, "state on trial t"))) +
    ylim(c(0,1)) +
    scale_fill_manual(values = c("low-trust" = "red", "medium-trust" = "green", "high-trust" = "blue"),
                    name = "From state") +  # Changed legend title for 'fill' here
    scale_color_manual(values = c("low-trust" = "red", "medium-trust" = "green", "high-trust" = "blue"),
                       labels = c("low-trust", "medium-trust", "high-trust"),
                       name = "State transitioned to") +
    labs(x = "Investor's net return on trial t", y = "Transition probability to \nState on trial t+1", color = 'State transitioned to') +
    theme_bw() +
    theme(legend.position = "bottom",
          legend.text = element_text(size = 12),
          legend.key.size = unit(1, 'lines'),
          legend.spacing.x = unit(0.1, 'in'),
          legend.title = element_text(size = 14),
          legend.margin = margin(t = 0.2, b = 0, unit = 'cm'),
          plot.margin = margin(t = 0, r = 0, b = 0, l = 0, unit = "cm"),
          strip.text = element_text(size = 10),
          legend.box = "vertical" # Arrange legends vertically
    ) +
    guides(fill = guide_legend(order = 1, title.position = "left", title.hjust = 0.3),
           color = guide_legend(order = 2, title.position = "left", title.hjust = 0.3))
}

```


```{r, include=F}

plotInvTran <- plot_HMM_transitions(3, pars_inv) 
print(plotInvTran)

plotInvTranNice <- plot_HMM_transitions(3, pars_inv_nice) 
print(plotInvTranNice)


```





### Repeated Trust Game

Participants played a 15-round RTG [@joyce_trust_1995] in the trustee role against a computer-programmed investor. On each round the investor is endowed with 20 units and decides how much of that endowment to invest. This investment is tripled and the trustee then decides how to split this tripled amount between them and the investor. If the trustee returns more than one third of the amount, the investor makes a gain. Each player was represented with an icon with the participant always on the left of the screen and the co-player on the right. The participants were able to choose the icon that represents them at the start of the experiment. The icon representing the co-player changed at the start of each new game, to simulate a new interaction partner. Participants were not told they were facing computerised co-players. We chose to simulate the behavior of a human interaction partner through allowing for a delay whilst pairing with new opponents as the start of each game as well as programming the agents to respond during each round after a varying time lapse (randomly chosen between 5 and 10 seconds). 

The computerised investor consisted of a hidden Markov model (HMM) trained on an independent existing behavioral RTG data set of human investors. This data-driven approach thus sought to learn an investor strategy that mimics human-like interactions.  The data set used for training consists of 388 ten round games with the same player (full details can be found in the Supplementary Information). On this data set, the HMM was inferred with three latent states that could be interpreted as reflecting a “low-trust”, a “medium-trust”, and a “high-trust” state. A separate output distribution, that maps each HMM state onto possible investments from 0 to 20 separately, is learned (Figure \@ref(fig:HMMPanels).B). In analogy to the latent states, these distributions can be interpreted as reflecting “low-trust”, “medium-trust”, or “high-trust” dispositions. Finally, the HMM is specified by transition probabilities that describe the transition between states. The probability of these transitions was modelled as a function of their net return (i.e return - investment) in the previous round (see Figure \@ref(fig:HMMPanels).C)). The initial state for the HMM investor in each instance of the game was set to the “mid-trust” state. Details on how the HMM state conditional probabilities and transition functions are specified can be found in the supplement. 

In order to instigate a potential breakdown of trust, thereby allowing us to probe efforts to repair it, the computerised agent was programmed to provide a low investment on round 12 (pre-manipulation) and round 13 (post-manipulation). On all other rounds, the investor’s actions were determined by randomly drawing an investment from the state-conditional distribution, with the state over rounds determined by randomly drawing the next state from the state-transition distribution as determined from the net return on the previous round (disregarding the net return immediately after the pre-programmed low investment rounds).


## Manipulation

In all phases of the RTG other than the ‘Exposure phase’ (Figure \ref{fig:HMMPanels}.A), participants interacted with this human-like HMM. In the ‘Manipulation’ Condition of the exposure phase, however, the parameters of this HMM were adjusted to design a ‘forgiving’ and ultimately more cooperative agent. To achieve this, we changed the state transition probabilities of the HMM such that it becomes impossible for it to remain in a low trust state, effectively setting the transition probability for remaining in a “low-trust” state to 0. The resulting transition function is shown in Figure \ref{fig:HMMPanels}.D. The policies conditional on the latent states and the transition function in the other latent states remain unchanged.



\begin{landscape}
```{r HMMPanels, fig.cap= "\\small{A: A timeline of the experiment for both conditions. The RTG is played in dyads, with participants always assigned the role of the trustee and the HMM agent that of the investor. The investor is endowed with 20 units at the start of each round. They need to decide how much of that endowment they want to invest with the trustee. The investment is then multiplied by a factor of 3 and sent to the trustee who needs to decide how much of the multiplied investment they want to send back to the investor. The difference between conditions is the type of agents participants are exposed to in the exposure phase. Panels B - D: We construct the artificial investor agent by fitting a three-state hidden Markov model to data of human investors engaged in the 10 round RTG against human trustees. From the fitted HMM, we get the distribution of investments by the human-like agent, conditional on its latent state as shown in Panel B. The fitted HMM also yields the transition probability of the agent to a state on trial t+1 as a function of the net return (difference between the investment sent and the amount received in return) on trial t as shown in Panel C. Each plot in Panel C represents a different starting latent state on trial t, and each line represents the probability of transitioning to a particular state in trial t+1. Panel D shows the transition probabilities of the forgiving HMM agent in the low trust state. Unlike the human-like HMM, the forgiving HMM always transitions out of the low-trust state, and is more likely to end up in a high-trust state, as a proxy for coaxing behavior. Transitions in the medium and high trust states were identical for both agents.}",include=T, out.width='1\\linewidth', out.height='1\\textheight', fig.align='center'}


library(magick)

# Read in the images
image1 <- image_read("figures/timeline.png")
image2 <- image_read("figures/HMMinvPolicy2.png")
image3 <- image_read("figures/HMMinvTrans2.png")
image4 <- image_read("figures/HMM_switch.png") 



# Determine the target width for all images, for example, the width of the widest image
target_width <- max(image_info(image1)$width, image_info(image2)$width, 
                    image_info(image3)$width, image_info(image4)$width)

target_height <- max(image_info(image1)$height, image_info(image2)$height, 
                    image_info(image3)$height, image_info(image4)$height)


# Scale images to have the same width
image1 <- image_scale(image1, paste0(target_width, "x", target_height))
image2 <- image_scale(image2, paste0(target_width, "x", target_height))
image3 <- image_scale(image3, paste0(target_width, "x", target_height))
image4 <- image_scale(image4, paste0(target_width, "x", target_height))

# Annotate each image with a label
image1 <- image_annotate(image1, text = "A", location = "+0+10", size = 90, color = "black", gravity = "northwest")
image2 <- image_annotate(image2, text = "B", location = "+0+10", size = 90, color = "black", gravity = "northwest")
image3 <- image_annotate(image3, text = "C", location = "-0+10", size = 90, color = "black", gravity = "northwest")
image4 <- image_annotate(image4, text = "D", location = "+0+10", size = 90, color = "black", gravity = "northwest")

# Assuming a 300 DPI resolution for good print quality
dpi <- 300

# Spacing of 0.1 inches converted to pixels
spacing <- 0.05 * dpi

# Calculating the width and height for each image
width_per_image <- ((12 - 0.1) / 2) * dpi
height_per_image <- ((7.4 - 0.1) / 2) * dpi
# The geometry string for each image, including spacing (assuming no borders)
geometry_string <- paste0(width_per_image, 'x', height_per_image, '+', spacing, '+', spacing)

# Now create the montage with the specified geometry
combined_image <- image_montage(
  c(image1, image2, image3, image4), 
  tile = "2x2",
  geometry = geometry_string
)


# Display the combined image
plot(combined_image)
```
\end{landscape}


## Procedure

At the start of the experiment, participants provided informed consent and were instructed the study would consist of three phases in which they would face a different other player. Participants were told their goal was to maximise the number of points in all phases. They were not told the number of rounds of each phase. Participants were randomly assigned to either a Control or Manipulation condition. The timeline of the experiment is shown in Figure \@ref(fig:HMMPanels).A.  Phase one ("pre") consisted of a 15 round RTG in which participants took the role of trustee, facing the same investor over all 15 rounds. On each round, after being informed about the amount sent by the investor participants decided how much of the tripled investment to return to the investor, before continuing to the next round. Phase 2 ("exposure") consisted of three 7-round RTGs. Participants in the Manipulation condition faced the forgiving HMM investor and rated the agent on the same attributes as in the pre-manipulation phase.  Those in the Control condition faced the same human-like HMM agent as in the "pre" phase and rated each co-player on the same attributes. To keep the experience similar to the "pre" phase, the agent in the Control condition was also designed to send a very low investment in round 5 of each of the three games. In the post-manipulation phase ("post"), participants in both conditions faced the same human-like HMM as in "pre" phase. 

At the beginning of each game in all three phases, participants were told they would face a new player and had to wait to be paired with an available co-player. This simulated the waiting time in real social interaction tasks. After completing each RTG in each phase, participants rated how cooperative and forgiving they perceived the co-playerr to be, and whether they would like to play with them again (all on a scale from 1 to 10 with 10 being the most positive rating). After completing the three game phases, participants then completed the Levels of Personality Functioning Scale Brief-Form (LPFS-BF) questionnaire [@weekers_level_2019]. This is a self-report measure designed to assess core elements of personality functioning as defined in the Alternative Model for Personality Disorders in the DSM-5 [@american_psychiatric_association_diagnostic_2013], and provides a dimensional assessment of personality functioning, which complements the categorical approach of RS. Finally, participants were asked whether they thought the other players were human or computer agents, then debriefed and thanked for their participation.

## Statistical Analysis

To explore whether participants behaved differently in the RTG after the manipulation compared to the Control group, we model the percentage return (percentage of tripled investment returned to investor) using a linear mixed-effects model with Phase (RTG game pre vs. post-manipulation), Condition (manipulation vs. Control), Investment, and RS (High vs Low RS group) as well as their interactions as fixed effects, and player-wise random intercepts and slopes for Phase. The full specification of the statistical model can be found in the supplement. To test whether participants behaved differently between conditions in the Exposure phase, we fit a linear mixed effects model to participants returns only in the exposure phase, with Condition (manipulation vs. Control), Investment, and RS (High vs Low RS group) as well as their interactions as fixed effects, and player-wise random intercepts. Finally, to test whether the HMM agent's behavior differed between Phases, Conditions and RS groups, we estimate a linear mixed-effects model of investments sent by the computerised HMM agent with Condition, Phase and RS and their interaction as fixed effects, and a similar random effects structure to the returns model.


The model was estimated using the `afex` package [@singmann_afex_2022] in R. More complex models with additional random effects could not be estimated reliably, and as such the estimated model can be considered to include the optimal random effects structure [@matuschek_balancing_2017]. A similar process was used to establish the random effects structures of linear mixed-effects models used to analyse the HMM agent investments as well as the participants' ratings of the co-players. There is no agreed upon way to calculate effect sizes for mixed effects models. Instead, we will report on testing differences in marginal means. For the $F$-tests, we used the Kenward-Roger approximation to the degrees of freedom, as implemented in the R package "afex". We Z-transform the Investment variable (subtract the overall investment mean and divide by overall standard deviation) as centering is beneficial to interpreting the main effects more easily in the presence of interactions.



```{r datRatings}

#######################    Pre-processing player ratings 

# Pivot longer ratings on each attribute 
df_coop <- d_finished %>% dplyr::select(playerId,condition.f,contains("cooperative"),high_RS) %>%  
  pivot_longer(cols=contains("cooperative"), names_to = c("game"), names_pattern ="rating_cooperative_(.*)", values_to = "rating_coop") %>% distinct()

df_forgiv <- d_finished %>% dplyr::select(playerId,condition.f,contains("forgiving"),high_RS) %>%
  pivot_longer(cols=contains("forgiving"), names_to = c("game"), names_pattern ="rating_forgiving_(.*)", values_to = "rating_forgiving") %>% distinct()

df_playAgain <- d_finished %>% dplyr::select(playerId,condition.f,contains("again"),high_RS) %>%  
  pivot_longer(cols=contains("again"), names_to = c("game"), names_pattern ="rating_playAgain_(.*)", values_to = "rating_playAgain") %>% distinct()

#merge all data frames together
datRatings <- list(df_coop, df_forgiv,df_playAgain) %>% 
              reduce(full_join, by=c('playerId','game','condition.f','high_RS')) %>%
              mutate(gameNum.f = factor(game,labels = c("pre", "expo1", "expo2", "expo3","post"),
                                      levels=c("1", "11", "12", "13", "2")))

# Group means for each rating 
mu <- datRatings %>% group_by(gameNum.f, condition.f) %>% summarise(mean_coop = mean(rating_coop),
                                                  mean_forgiv = mean(rating_forgiving),
                                                  mean_playAgain = mean(rating_playAgain)
                                                  )
mu


```





```{r}

df_long_ratings <- datRatings %>%
  pivot_longer(
    cols = starts_with("rating_"), 
    names_to = "rating_type", 
    values_to = "rating_value"
  ) %>%
  dplyr::select(playerId, condition.f, gameNum.f, rating_type, rating_value, high_RS)


# First, calculate the mean and SEM for each group
summary_df <- df_long_ratings %>%
  group_by(gameNum.f, condition.f, rating_type, high_RS) %>%
  summarise(
    mean = mean(rating_value, na.rm = TRUE),
    sem = sd(rating_value, na.rm = TRUE)/sqrt(n())
  ) %>%
  ungroup()


```



<!-- ## Linear mixed effects Model for returns  -->


```{r avgRetDf}
# Filter only trust rounds and create % returns and investments 

avg_ret_df <- d_finished %>%
  dplyr::select(playerId,roundType,investment,returns,roundNum,gameNum.f,condition.f, phase.f, high_RS, LPFS_score, RS_score, investorState.f) %>% 
  filter(roundType=="trust",!is.na(roundNum)) %>% 
  mutate(roundNum = as.numeric(as.character(roundNum))) %>%
  mutate(inv_scaled = as.vector(scale(investment))) %>% 
  mutate(inv_pct = investment/20, ret_pct_0 = ifelse(investment==0,0,returns/(3*investment)),ret_pct_na = ifelse(investment==0,NA,returns/(3*investment))) 

# Number of people left for analysis. (there are 51 rounds in each game)
#num_participants <- nrow(avg_ret_df)/51
num_participants <- length(unique(avg_ret_df$playerId))

num_participants 

```

```{r}
# average investment for first 10 rounds pre manipulation
avg_pct <- avg_ret_df %>% filter(roundNum < 11 , gameNum.f == "pre") %>% summarise(avg_inv = mean(inv_pct), avg_ret = mean(ret_pct_na, na.rm=TRUE))
avg_pct
```





<!-- Linear mixed effects model for all returns  -->


# Behavioral Results 


## Analysis of Participant Returns 


```{r modAllReturns, include=FALSE, cache=TRUE}
##############  Filter only pre and post games
prepost_df <- avg_ret_df %>% filter(gameNum.f %in% c("pre","post"))
##############
mod_returns_pct_RS <- mixed( ret_pct_na ~ phase.f*condition.f*inv_scaled*high_RS + (1 + phase.f| playerId), prepost_df, REML= TRUE, method="KR")

summary(mod_returns_pct_RS)

```

```{r}
saveRDS(summary(mod_returns_pct_RS), "data/mod_returns_pct_RS.RDS")
```


```{r}
contrasts(prepost_df$phase.f)
contrasts(prepost_df$condition.f)
contrasts(prepost_df$high_RS)
contrasts(prepost_df$investorState.f)
```


```{r prepostByCond, cache=TRUE}
prepost_bycond <- pairs(emmeans::emmeans(mod_returns_pct_RS, c("phase.f"), by = "condition.f", pbkrtest.limit = 6300))
prepost_bycond
```



```{r modemmeans, cache=TRUE, include=F}
library(emmeans)

# Compute EMMs for the interaction of interest
emms <- emmeans(mod_returns_pct_RS, ~ phase.f * condition.f | high_RS, pbkrtest.limit = 6300, adjust="tukey")

contrasts <- contrast(emms, "pairwise", by = c("condition.f", "high_RS"))
summary(contrasts)

results_df <- as.data.frame(summary(contrasts))
```


<!-- EFFECT SIZES -->
```{r}
# Load the necessary packages

library(sjstats)
effectsize::eta_squared(mod_returns_pct_RS)
```





On average, investments and returns, as shown in Figure \ref{fig:gamesPlot}, fell within the documented range of 40-60% of the endowment for investments and 35-50% of the total yield for returns, as reported in previous studies [@charness_investment_2008; @fiedler_social_2011].

```{r gamesPlot, include=T, echo=FALSE, fig.cap="Averages and standard errors of the trustee's return as a percentage of the multiplied investment received (y-axis) by Condition, Phase, and game round (x-axis) averaged across RS groups. The blue line shows the returns in the Pre phase and the green line those in the Post phase. The left Panel shows returns in the Control condition and the right one those in the Manipulation condition. The dotted lines identify the rounds where the pre-programmed one-off low investment occurs. We note lower average returns post vs pre in the Manipulation condition, whilst returns in the Control condition are similar between the two phases.",fig.align="center", fig.width=6, fig.height = 4}

# Create a data frame for the vertical lines
vline_data <- data.frame(
  xintercept = c(12, 13),
  Defection_round = factor(c("Pre-manipulation", "Post-manipulation"), levels = c("Pre-manipulation", "Post-manipulation"))
)


# Plot
ggplot(avg_ret_df %>% filter(gameNum.f %in% c("pre","post")), aes(x=as.factor(roundNum), y=ret_pct_na, group=gameNum.f, color = gameNum.f, fill=gameNum.f)) +
  stat_summary(fun = mean, geom = "line") +
  stat_summary(fun.data = mean_se, geom = "ribbon", aes(ymin=..ymin.., ymax=..ymax..),
               alpha = 0.3, linetype = 0) +
  geom_vline(data = vline_data, aes(xintercept = xintercept, linetype = Defection_round), color = "black", linewidth = 0.6) +
  scale_linetype_manual(values = c("Pre-manipulation" = "dotted", "Post-manipulation" = "dashed"),name = "Defection round") +
  labs(x = "Round",
       y = "Percentage Return",
       color = "Trust Game Phase") +
  theme_bw() +
  theme(legend.position = "bottom",
        legend.box = "vertical", # This will stack the legends vertically
        legend.key = element_blank(),
        legend.margin = margin(t = 0.2, b = 0.2, unit = "pt"),
        legend.box.margin = margin(t = 0, b = 0, unit = "pt"),
        legend.title = element_text(size = 12),
        legend.text = element_text(size = 10)) +
  scale_color_manual(values = c("darkblue", "darkgreen"),
                     labels = c("Pre-manipulation", "Post-manipulation")) +
  scale_fill_manual(values = c("darkblue", "darkgreen"),
                    guide = "none") + # Hide the fill legend
  guides(color = guide_legend(override.aes = list(fill = NA)))+  # Remove fill for color legend keys
  guides(color = guide_legend(title = "Participant Returns Proportions", override.aes = list(fill = NA)),
         linetype = guide_legend(title = "Defection round")) +
  facet_wrap(~condition.f)


```

Mixed-effects analysis on the percentage returns shows a significant main effect of Phase (Pre vs. Post RTG game), `r papaja::apa_print(mod_returns_pct_RS)$full_result$phase_f`, with higher percentage returns in the Pre RTG compared to the Post. Importantly, we also find an interaction between Condition and Phase (RTG pre- vs. post-manipulation), `r papaja::apa_print(mod_returns_pct_RS)$full_result$phase_f_condition_f`. As shown in Figure \ref{fig:boxPlots}, post-hoc tests confirm that, contrary to our expectations, there was a decrease in the percentage returned only in the Manipulation condition, pre - post,
`r papaja::apa_print(prepost_bycond)$full_result$Manipulation_Pre_post`, but no change in the Control condition.  We find no interaction between Phase, Condition and RS, suggesting that there was no difference between RS groups for this interaction.


There was also a significant main effect of Investment, 
`r gsub("(\\d{1,3}),(\\d{3})", "\\1\\2", papaja::apa_print(mod_returns_pct_RS)$full_result$inv_scaled)`,
such that higher investments were associated with higher percentage returns indicating positive reciprocity. An Investment by Condition interaction, 
`r gsub("(\\d{1,3}),(\\d{3})", "\\1\\2", papaja::apa_print(mod_returns_pct_RS)$full_result$condition_f_inv_scaled)`, reflected that returns were more affected by investments in the Control condition. We also find a three way interaction between Phase, Investment and RS, `r gsub("(\\d{1,3}),(\\d{3})", "\\1\\2", papaja::apa_print(mod_returns_pct_RS)$full_result$phase_f_inv_scaled_high_RS)`, showing that the differentiated effect of the investment on the proportion returned by RS group is itself moderated by the Phase (pre- vs post manipulation). Finally, we find a four-way interaction between Condition, Phase, Investment and RS `r gsub("(\\d{1,3}),(\\d{3})", "\\1\\2", papaja::apa_print(mod_returns_pct_RS)$full_result$phase_f_condition_f_inv_scaled_high_RS)`. For completeness, these effects are discussed in more detail in the supplement.


<!-- # USING LMER TO LEVERAGE CAPABILITIES WITH EMTRENDS -->

```{r}
library(lmerTest)
library(emmeans)

# Refitting the model directly
direct_model <- lmer(ret_pct_na ~ phase.f * condition.f * inv_scaled * high_RS + (1 + phase.f | playerId), data = prepost_df, REML = TRUE)



emm_res <- emmeans(direct_model, specs = ~ phase.f * condition.f * high_RS * inv_scaled)
trends <- emtrends(direct_model, specs = ~ phase.f * condition.f * high_RS, var = "inv_scaled")

# Print results
summary(emm_res)
summary(trends)

```



```{r fourwayInteractionPlot, include=F, fig.cap ="Visualising the four way interaction between Phase, RS group, Condition and Investment. The plot shows the effect of the investment on participant returns for each condition, phase and RS group. The interesting effect is in the Manipulation Condition: " }


library(ggplot2)

# 
# ggplot(prepost_df, aes(x = inv_scaled, y = ret_pct_na, color = phase.f)) +
#   # geom_point(alpha = 0.6) + # Adjust point transparency with alpha
#   geom_smooth(method = "lm", se = FALSE) + # Add linear regression lines without confidence intervals
#   labs(title = "Effect of inv_scaled on Outcome by Condition",
#        x = "inv_scaled", y = "Outcome") +
#   theme_minimal() +
#   facet_wrap(~high_RS)

# 'inv_scaled' is the continuous predictor, and 'outcome' is your dependent variable.
ggplot(prepost_df, aes(x = inv_scaled, y = ret_pct_na, color = phase.f)) +
  # geom_point(alpha = 0.6) + # Adjust point transparency with alpha
  geom_smooth(method = "lm", se = FALSE) + # Add linear regression lines without confidence intervals
  labs(x = "Investment Z-values", y = "Return proportion", color = "Experiment Phase") +
  theme_minimal() +
  facet_wrap(~condition.f*high_RS)+
  theme(legend.position = "bottom")
  

```


```{r invMod, cache=TRUE}

mod_invs_RS <- mixed( investment ~ phase.f*condition.f*high_RS + (1 + phase.f| playerId), prepost_df, REML= TRUE, method="KR")

summary(mod_invs_RS)
```

```{r}
saveRDS(summary(mod_invs_RS), "data/mod_invs_RS.RDS")
```




```{r violPlotsDef, cache=TRUE}
library(afex)
library(ggplot2)
library(ggsignif)

# Generate the plot with points and error bars
ret_all <- afex_plot(mod_returns_pct_RS, x = "condition.f", trace = "phase.f", dodge = 0.8, error = "within",
                     mapping = c("linetype", "shape", "fill"),
                     factor_levels = list(condition.f = c("Control", "Manipulation")),
                     legend_title = "Phase",
                     emmeans_arg = list(p.adjust.method = "tukey"))

# Extract the data used in afex_plot
plot_data <- ret_all$data

# Generate the plot
ret_all <- ggplot(plot_data, aes(x = condition.f, y = y, color = phase.f, group = phase.f)) +
  geom_point(position = position_dodge(width = 0.8)) +
  geom_errorbar(aes(ymin = y - SE, ymax = y + SE), width = 0.2, position = position_dodge(width = 0.8)) +
  theme_bw() +
  labs(y = "% Returns", x = "Condition", color = "Trust Game Phase") +
  theme(plot.title = element_text(size = 16), legend.position = "bottom") +
  geom_signif(
              annotations = "***", 
              xmin = 1.8, xmax = 2.2,
              y_position = 0.47, 
              tip_length = 0.03, 
              textsize = 3, 
              color = "black")


######################################################################################################

# Generate the plot with points and error bars
inv_all <- afex_plot(mod_invs_RS, x = "condition.f", trace = "phase.f", dodge = 0.8, error = "within",
                     mapping = c("linetype", "shape", "fill"),
                     factor_levels = list(condition.f = c("Control", "Manipulation")),
                     legend_title = "Phase")

# Extract the data used in afex_plot
plot_data <- inv_all$data

# Generate the plot
inv_all <- ggplot(plot_data, aes(x = condition.f, y = y, color = phase.f, group = phase.f)) +
  geom_point(position = position_dodge(width = 0.8)) +
  geom_errorbar(aes(ymin = y - SE, ymax = y + SE), width = 0.2, position = position_dodge(width = 0.8)) +
  theme_bw() +
  labs(y = "HMM Investment", x = "Condition", color = "Trust Game Phase") +
  theme(plot.title = element_text(size = 16), legend.position = "bottom")+
  ylim(9, 11) 


```



```{r boxPlots, include=T,fig.cap="Marginal means and distributions of either investments or percentage returns across participants by Phase and Condition. The top panel shows that participants in the Intervention condition returned lower proportions of the multiplied investment received in the second game compared to the first game over all ronds, whilst those in the Control condition sent back similar returns. The bottom panel shows no difference on aggregate of how the HMM invested across Phases and Conditions.",fig.align="center", fig.width=6, fig.height = 8}



library(patchwork)

ret_all/inv_all +  plot_layout(guides = 'collect') & theme(legend.position = "bottom")


```



<!-- Focusing on post defection only:  -->
### Post Defection Trials 




```{r postDefMod, cache=TRUE}
post_def_data <- avg_ret_df %>% filter(roundType=="trust",!is.na(gameNum.f),(roundNum >= 12 & gameNum.f =="pre")| (roundNum >= 13 & gameNum.f =="post"))

mod_retPostDef_RS <- mixed( ret_pct_na ~ phase.f*condition.f*inv_scaled + (1 + phase.f| playerId), post_def_data , REML= TRUE, method="KR")

summary(mod_retPostDef_RS)
```

```{r PairsPostDef}
phasePairs <- pairs(emmeans::emmeans(mod_retPostDef_RS, c("phase.f"), pbkrtest.limit = 1449))
phasePairs
```

Did participants learn to be more forgiving and cooperative after witnessing the pre-programmed defection by the HMM investor? To explore this question, we restrict the analysis to the trials following the pre-programmed defection by the HMM agent in both the "pre" (trials 12 to 15) and the "post" phases (trials 13 to 15).  We fit the same mixed effects model as for all the trials with the exception of the RS variable. This is because RS did not show main or interaction effects in the main model, and also due to the necessity of running a simpler model to accommodate the low number of trials. We find a significant main effect of Phase `r papaja::apa_print(mod_retPostDef_RS)$full_result$phase_f` with returns lower in the second game post defection trials compared to the first. We also find a main effect of Investment 
`r gsub("(\\d{1,3}),(\\d{3})", "\\1\\2", papaja::apa_print(mod_retPostDef_RS)$full_result$inv_scaled)` 
where participants continued to return higher proportions when receiving higher investments. 
Finally, we still find an Investment by Condition interaction 
`r gsub("(\\d{1,3}),(\\d{3})", "\\1\\2", papaja::apa_print(mod_returns_pct_RS)$full_result$condition_f_inv_scaled)` showing a lower effects of investment on the Manipulation condition compared to the Control condition in post-defection trials. However, the absence of a Condition by Phase effect indicates there was no difference between conditions on participants' reaction to a one-off defection by the co-player.

<!-- Checking whether Investor behavior has changed dramatically between pre and post: -->

### HMM Investor in Pre and Post Phases
<!-- Linear mixed effects model for investments -->
Was the HMM's strategy similar between pre and post phases in the control condition? Was participants' behavior post exposure differentiated enough to induce a different reaction from the HMM? To answer these questions, we test for differences in the HMM agent's investment by Phase, Condition and RS using a linear mixed-effects model as described in the methods section. As seen in Figure \@ref(fig:boxPlots), we find no main or interaction effects, indicating the HMM's behavior was on aggregate similar across levels of Phase, Condition and RS. This consistency in the investor's behavior is a desirable feature of the HMM agent when the participants behavior is largely simialr between phases. More importantly, it indicates that the lower returns of participants in the post phase of the manipulation condition were not differentiated enough to make the HMM react by transitioning to lower latent trust states. It is also noteworthy that the HMM agent was relatively successful in imitating human behavior in this paradigm: When asked during debrief whether they thought the investors they faced were human or not, $41$% of participants thought they were either facing a human or were not sure of the nature of the co-player. When asked to justify their choice, many answers reflected participants projecting human traits such as "spitefulness" or "greed" onto the artificial co-player's behavior. 


### Exposure Phase Trials 


```{r}
ggplot(avg_ret_df %>% filter(gameNum.f %in% c("expo1","expo2","expo3")), aes(x=as.factor(roundNum), y=ret_pct_na, group=gameNum.f, color = gameNum.f, fill=gameNum.f)) +
  stat_summary(fun = mean, geom = "line") +
  stat_summary(fun.data = mean_se, geom = "ribbon", aes(ymin=..ymin.., ymax=..ymax..),
               alpha = 0.3, linetype = 0) +
  # geom_vline(data = vline_data, aes(xintercept = xintercept, linetype = Defection_round), color = "black", linewidth = 0.6) +
  # scale_linetype_manual(values = c("Pre-manipulation" = "dotted", "Post-manipulation" = "dashed"),name = "Defection round") +
  labs(x = "Round",
       y = "Percentage Return",
       color = "Trust Game Phase") +
  theme_bw() +
  guides(color = guide_legend(override.aes = list(fill = NA)))+  # Remove fill for color legend keys
  guides(color = guide_legend(title = "Participant Returns Proportions", override.aes = list(fill = NA)),
         linetype = guide_legend(title = "Defection round")) +
  facet_wrap(~condition.f)
```




```{r}

expo_df <- avg_ret_df %>% filter(gameNum.f %in% c("expo1","expo2","expo3"))

mod_returns_expo <- mixed( ret_pct_na ~ condition.f*inv_scaled*high_RS + (1 | playerId), expo_df, REML= TRUE, method="KR")
mod_inv_summary <- summary(mod_returns_expo)
mod_inv_summary

em_ret_cond <- emmeans::emmeans(mod_returns_expo , c("condition.f"))
pairs(em_ret_cond)

# Calculate the slopes (coefficients) of inv_scaled for each condition
inv_slopes <- emtrends(mod_returns_expo, ~ condition.f, var = "inv_scaled")

# To see pairwise comparisons of the slopes
print(inv_slopes)
pairs(inv_slopes)

##### Three way interaction
inv_slopes3 <- emtrends(mod_returns_expo, ~ condition.f * high_RS, var = "inv_scaled")
summary(inv_slopes3)

pairwise_comparisons3 <- pairs(inv_slopes3, by = "high_RS")
summary(pairwise_comparisons3)


######### HMM investment in EXPO PHASE 
mod_invs_expo <- mixed(investment ~ condition.f*high_RS + (1 | playerId), expo_df %>% filter(roundNum >= 5), REML= TRUE, method="KR")
summary(mod_invs_expo)

emcheck_inv <- pairs(emmeans::emmeans(mod_invs_expo, c("condition.f"), pbkrtest.limit = 6300))
emcheck_inv
```
So far we focused on analysing behavior for the pre and post phases. Here, we look at returns and investments in the exposure phase. The linear mixed effects model of participants' returns in the exposure phase does not show a main effect of Condition on returns. There was a main effect of Investment, `r papaja::apa_print(mod_returns_expo)$full_result$inv_scaled`, with participants positively reciprocating higher investments, an interaction effect between Condition and Investment `r gsub("(\\d{1,3}),(\\d{3})", "\\1\\2",papaja::apa_print(mod_returns_expo)$full_result$condition_f_inv_scaled)`, showing a stronger positive reciprocity in the Control condition, and finally a three way interaction between the RS group, Condition and Investment `r gsub("(\\d{1,3}),(\\d{3})", "\\1\\2",papaja::apa_print(mod_returns_expo)$full_result$condition_f_inv_scaled_high_RS)`, showing that this stronger positive reciprocity to investment in the Control condition is higher for participants with high RS. The linear mixed effects model of the HMM investments shows a main effect of Condition `r papaja::apa_print(mod_invs_expo)$full_result$condition_f`, suggesting higher overall investments for the forgiving HMM  compared to the human-like HMM, but no difference in investments when facing low and high RS groups.  

In summary, despite the forgiving HMM sending overall higher investments in the exposure phase, participants returned similar proportions of the multiplied investments as those facing the human-like HMM. The positive reciprocity of returns to investments was higher in the Control condition with this relationship stronger for the high RS group. 


### Questionnaire Scores and Performance

```{r}

temp2 <- d_finished %>% dplyr::filter(gameNum.f %in% c("pre", "post")) %>%
  dplyr::select(id, payoffTrust1, payoffTrust2, condition.f, RS_score, LPFS_score) %>%
  mutate(perf = payoffTrust1 + payoffTrust2) %>% 
  unique()
cor.test(temp2$LPFS_score, temp2$perf, method = "spearman")
cor.test(temp2$RS_score, temp2$perf, method = "spearman")

cor_result <- cor.test(temp2$RS_score, temp2$LPFS_score, method = "spearman")
# Format the result using papaja
apa_result <- papaja::apa_print(cor_result)

print(apa_result)
# Extract the correlation coefficient and p-value
spearman_rho <- apa_result$estimate

```


Whilst we found a significant correlation between participant's Levels of Personality Functioning Score (LPFS) and the Rejection Sensitivity  Questionnaire score (RSQ), Spearman's `r spearman_rho`, $p < 0.001$, there was no correlation between these questionnaire scores and participant's return or overall task performance.



<!---------------------- Modelling of co-player ratings -------------------------------------->


```{r afexModCoop, cache=TRUE}

mod_rating_coop <- mixed( rating_coop ~ gameNum.f*condition.f*high_RS + (1 | playerId), datRatings, REML= TRUE, method="KR")

summary(mod_rating_coop)

```


```{r emmCoop, cache=TRUE}
# Contrast 1: Pre vs. Post
contrast1 <- c(-1, 0, 0, 0, 1)  

# Contrast 2: Pre vs. (Expo1, Expo2, Expo3) 
contrast2 <- c(-3, 1, 1, 1, 0) 

# Contrast 3: Post vs. (Expo1, Expo2, Expo3) 
contrast3 <- c(0, -1, -1, -1, 3) 

# Combine contrasts into a matrix
contrast_matrix <- rbind(contrast1, contrast2, contrast3)
colnames(contrast_matrix) <- levels(datRatings$gameNum.f) 


# Apply contrasts to the model using 'emmeans'
emm_coop <- emmeans(mod_rating_coop, ~ gameNum.f | condition.f)

# Custom comparisons: use 'contrast' directly
comp1_coop <- contrast(emm_coop, list("Pre vs Post" = contrast_matrix[1,]), by = "condition.f")
comp2_coop <- contrast(emm_coop, list("Pre vs Expo" = contrast_matrix[2,]), by = "condition.f")
comp3_coop <- contrast(emm_coop, list("Post vs Expo" = contrast_matrix[3,]), by = "condition.f")


comp1_coop

comp2_coop

comp3_coop

```

```{r}
# Compute the estimated marginal means (EMMs) for the interaction
emm_coop_interaction <- emmeans(mod_rating_coop, ~ gameNum.f | condition.f * high_RS)

comp1_coop_interaction <- contrast(emm_coop_interaction, list("Pre vs Post" = contrast_matrix[1,]))
comp2_coop_interaction <- contrast(emm_coop_interaction, list("Pre vs Expo" = contrast_matrix[2,]))
# comp3_coop_interaction <- contrast(emm_coop_interaction, list("Post vs Expo" = contrast_matrix[3,]))

# Output the results
print("Pre vs Post")
comp1_coop_interaction
print("Pre vs Expo")
test(comp2_coop_interaction, adjust="bonferroni")
test(comp2_coop_interaction)

# test_comp3_coop_interaction
```


```{r afexModForg}

mod_rating_forg <- mixed( rating_forgiving ~ gameNum.f*condition.f*high_RS + (1 | playerId), datRatings, REML= TRUE, method="KR")

#summary(mod_rating_forg)

```

```{r emmForg}

# Apply contrasts to the model using 'emmeans'
emm_forg <- emmeans(mod_rating_forg, ~ gameNum.f | condition.f)

# Custom comparisons: use 'contrast' directly
comp1_forg <- contrast(emm_forg, list("Pre vs Post" = contrast_matrix[1,]), by = "condition.f")
comp2_forg <- contrast(emm_forg, list("Pre vs Expo" = contrast_matrix[2,]), by = "condition.f")
comp3_forg <- contrast(emm_forg, list("Post vs Expo" = contrast_matrix[3,]), by = "condition.f")


comp1_forg

comp2_forg

comp3_forg

```

```{r}
# Compute the estimated marginal means (EMMs) for the interaction
emm_forg_interaction <- emmeans(mod_rating_forg, ~ gameNum.f | condition.f * high_RS)

comp1_forg_interaction <- contrast(emm_forg_interaction, list("Pre vs Post" = contrast_matrix[1,]))
comp2_forg_interaction <- contrast(emm_forg_interaction, list("Pre vs Expo" = contrast_matrix[2,]))
# comp3_forg_interaction <- contrast(emm_forg_interaction, list("Post vs Expo" = contrast_matrix[3,]))

# Output the results
print("Pre vs Post")
comp1_forg_interaction
print("Pre vs Expo")
comp2_forg_interaction

# test_comp3_forg_interaction
```

```{r afexModAgain}

mod_rating_again <- mixed( rating_playAgain ~ gameNum.f*condition.f*high_RS + (1 | playerId), datRatings, REML= TRUE, method="KR")

#summary(mod_rating_again)

```


```{r emmAgain}

# Apply contrasts to the model using 'emmeans'
emm_again <- emmeans(mod_rating_again, ~ gameNum.f | condition.f)

# Custom comparisons: use 'contrast' directly
comp1_again <- contrast(emm_again, list("Pre vs Post" = contrast_matrix[1,]), by = "condition.f")
comp2_again <- contrast(emm_again, list("Pre vs Expo" = contrast_matrix[2,]), by = "condition.f")
comp3_again <- contrast(emm_again, list("Post vs Expo" = contrast_matrix[3,]), by = "condition.f")


comp1_again

comp2_again

comp3_again

```

```{r}
# Compute the estimated marginal means (EMMs) for the interaction
emm_again_interaction <- emmeans(mod_rating_again, ~ gameNum.f | condition.f * high_RS)

comp1_again_interaction <- contrast(emm_again_interaction, list("Pre vs Post" = contrast_matrix[1,]))
comp2_again_interaction <- contrast(emm_again_interaction, list("Pre vs Expo" = contrast_matrix[2,]))
# comp3_again_interaction <- contrast(emm_again_interaction, list("Post vs Expo" = contrast_matrix[3,]))

# Output the results
print("Pre vs Post")
comp1_again_interaction
print("Pre vs Expo")
comp2_again_interaction

# test_comp3_again_interaction
```


## Player Ratings

 

Figure \@ref(fig:plotRatings) shows participants' ratings of each player they faced by condition and RS group. We will focus on two contrasts to analyse the ratings by Condition and RS group. The first is between the rating in the first phase ("pre") when participants phase the human-like HMM, and the average rating during the exposure phase (average of "expo1", "expo2" and "expo3") where they either face the forgiving HMM (Manipulation condition) or the human-like HMM again (Control condition). The second contrast is between the "pre" and "post" phases of the experiment where in both conditions participants face the same human-like HMM.

### Comparing Pre and Exposure Ratings

For those with high RS, participants in the Manipulation condition rated the investors they faced in the exposure phase (the forgiving HMM) as more Cooperative `r papaja::apa_print(comp2_coop_interaction)$full_result$Manipulation_HighRS_PrevsExpo`. There was no difference in ratings on forgiveness and whether they would like to face the co-players again. 
Those in the Control condition rated the investors faced in the exposure group (same HMM) as less cooperative `r papaja::apa_print(comp2_coop_interaction)$full_result$Control_HighRS_PrevsExpo`, less forgiving `r papaja::apa_print(comp2_forg_interaction)$full_result$Control_HighRS_PrevsExpo`, and were less keen on facing them again `r papaja::apa_print(comp2_again_interaction)$full_result$Control_HighRS_PrevsExpo`.

For those with low RS, there was no difference in any of the ratings between the "pre" and "exposure" phases for the Manipulation condition. For the Control condition, participants indicated less willingness to face the exposure co-player compared to the "pre" player, `r papaja::apa_print(comp2_again_interaction)$full_result$Control_LowRS_PrevsExpo` but also did not differ on cooperation and forgiveness ratings. In summary, those with low RS had a mostly undifferentiated perception of players between the pre and exposure phases, even when the co-player was in fact designed to be more forgiving. In contrast, we see that exposing participants with high RS to a more cooperative and more forgiving agent has compensated for the decrease in ratings that would have occurred if faced with a co-player with the exact same strategy.

```{r plotRatings,include=T, echo=FALSE, fig.pos='H', fig.cap="Averages and standard errors of the participants ratings of the opponent (y-axis) by each game and condition for each phase (x-axis). Pre and post are the 15 round RTGs before and after the exposure phase respectively. The games titled expo 1 to 3 are the three 7 round games during the exposure phase. The blue line represents participants' perception of co-player cooperation, the red line indicates perceived co-player forgiveness, and the green line shows the participants' willingness to play again with the same co-player. Cooperation, forgiveness, and willingness to play again ratings remained relatively stable for the low RS group except post-manipulation, where they were lower. In the high RS group, the ratings more accurately reflected the agent's actual cooperativeness and forgiveness in the Manipulation condition, but decreased over time in the Control group. Ratings were also markedly lower in the post-manipulation game for this group.",fig.align="center", fig.width=6, fig.height = 6}


ggplot(summary_df, aes(x = gameNum.f, y = mean, group = interaction(rating_type, condition.f), color = rating_type)) +
  geom_errorbar(aes(ymin = mean - sem, ymax = mean + sem), width = .1, position = position_dodge(width = 0.25)) +
  geom_line(linetype = "dashed", position = position_dodge(width = 0.25)) +
  geom_point(position = position_dodge(width = 0.25), size = 3) +
  facet_wrap(~high_RS*condition.f, scales = "free_x") +
  labs(x = "Phase", y = "Mean Rating", color = "Rating Type") +
  scale_color_manual(values = c("rating_coop" = "lightblue", "rating_forgiving" = "#FF6961", "rating_playAgain" = "#77DD77"),
                     labels = c("Cooperative", "Forgiving", "Play again")) +
  theme_bw() +
  theme(legend.position = "bottom")


```

```{r}
# temporarily paste code from Figure 2 to compare styles: 
# Plot
ggplot(avg_ret_df %>% filter(gameNum.f %in% c("pre","post")), aes(x=as.factor(roundNum), y=ret_pct_na, group=gameNum.f, color = gameNum.f, fill=gameNum.f)) +
  stat_summary(fun = mean, geom = "line") +
  stat_summary(fun.data = mean_se, geom = "ribbon", aes(ymin=..ymin.., ymax=..ymax..),
               alpha = 0.3, linetype = 0) +
  geom_vline(data = vline_data, aes(xintercept = xintercept, linetype = Defection_round), color = "black", linewidth = 0.6) +
  scale_linetype_manual(values = c("Pre-manipulation" = "dotted", "Post-manipulation" = "dashed"),name = "Defection round") +
  labs(x = "Round",
       y = "Percentage Return",
       color = "Trust Game Phase") +
  theme_bw() +
  theme(legend.position = "bottom",
        legend.box = "vertical", # This will stack the legends vertically
        legend.key = element_blank(),
        legend.margin = margin(t = 0.2, b = 0.2, unit = "pt"),
        legend.box.margin = margin(t = 0, b = 0, unit = "pt"),
        legend.title = element_text(size = 12),
        legend.text = element_text(size = 10)) +
  scale_color_manual(values = c("darkblue", "darkgreen"),
                     labels = c("Pre-manipulation", "Post-manipulation")) +
  scale_fill_manual(values = c("darkblue", "darkgreen"),
                    guide = "none") + # Hide the fill legend
  guides(color = guide_legend(override.aes = list(fill = NA)))+  # Remove fill for color legend keys
  guides(color = guide_legend(title = "Participant Returns Proportions", override.aes = list(fill = NA)),
         linetype = guide_legend(title = "Defection round")) +
  facet_wrap(~condition.f)


```


```{r}
library(ggplot2)

ggplot(summary_df, aes(x = gameNum.f, y = mean, group = interaction(rating_type, condition.f))) +
  geom_errorbar(aes(ymin = mean - sem, ymax = mean + sem, color = condition.f), 
                width = .1, position = position_dodge(width = 0.25)) +
  geom_line(aes(color = condition.f), linetype = "dashed", position = position_dodge(width = 0.25)) +
  geom_point(aes(color = condition.f), position = position_dodge(width = 0.25), size = 3) +
  facet_grid(high_RS ~ rating_type, scales = "free_x") +
  scale_color_manual(values = c("Control" = "blue", "Manipulation" = "red")) +
  labs(x = "Phase", y = "Mean Rating", color = "Condition") +
  theme_minimal() +
  theme(legend.position = "bottom")


```

### Comparing Pre and Post Ratings
<!-- Comparing post-exposure to exposure ratings, participants in the Manipulation condition rated the investors they faced in the exposure phase as less cooperative,  -->
<!-- `r papaja::apa_print(comp3_coop)$full_result$Manipulation_PostvsExpo`, less forgiving `r papaja::apa_print(comp3_forg)$full_result$Manipulation_PostvsExpo`, and were less willing to face them again `r papaja::apa_print(comp3_again)$full_result$Manipulation_PostvsExpo`. Ratings for those in the Control group did not differ on how cooperative, forgiving the investors were, and on willingness to face them again.  -->

Participants high on RS in the Manipulation condition rated the co-players in the "post" phase similarly on cooperation, lower on 
forgiveness `r papaja::apa_print(comp1_forg_interaction)$full_result$Manipulation_HighRS_PrevsPost`,
and lower on willingness to face them again `r papaja::apa_print(comp1_again_interaction)$full_result$Manipulation_HighRS_PrevsPost`. 
Those in the Control condition rated the investors post the exposure phase lower on all three attributes 
(Cooperation: `r papaja::apa_print(comp1_coop_interaction)$full_result$Control_HighRS_PrevsPost`, 
Forgiveness: `r papaja::apa_print(comp1_forg_interaction)$full_result$Control_HighRS_PrevsPost`, 
Play again: `r papaja::apa_print(comp1_again_interaction)$full_result$Control_HighRS_PrevsPost`). 

For participants low on RS, those in the Manipulation condition rated the co-players in the "post" phase lower on all three attributes 
(Cooperation:`r papaja::apa_print(comp1_coop_interaction)$full_result$Manipulation_LowRS_PrevsPost`, 
Forgiveness: `r papaja::apa_print(comp1_forg_interaction)$full_result$Manipulation_LowRS_PrevsPost`, 
Play again: `r papaja::apa_print(comp1_again_interaction)$full_result$Manipulation_LowRS_PrevsPost`). 
Those in the Control condition did not differ in their ratings of the "pre" and "post" phase players. 

In summary, we again see that those with low RS accurately perceive the co-player as similar on all attributes throughout the phases in the Control condition. In contrast, the high RS group shows a negative bias towards the co-players after the "pre" phase in the Control condition even though the player continues to use the same strategy. After exposure to the forgiving HMM, both groups rate the "post" co-player worse than the "pre" even though they are the same. 

```{r}
d_finished %>% 
  dplyr::select(id,Turing.choice) %>% 
  unique() %>% 
  group_by(Turing.choice) %>%
  summarise(Count = n()) %>%
  mutate(Percentage = (Count / sum(Count)) * 100)
```





<!-- Extracting Investor latent state from data -->

```{r extractInvStates}

library(tidyverse)

# Convert dataset from wide to long format, focusing on columns that start with "State_"
d_long <- d_finished %>%
  dplyr::select(id, condition.f, gameNum.f, gameNumber, roundNum, investorState.f) %>% 
  drop_na()
# View the resulting dataset
print(d_long)

```

```{r InvStatePlot}
library(ggplot2)
library(dplyr)

# Filter for only games 1 and 2
filtered_prepost <- d_long %>%
  filter(gameNum.f %in% c("pre", "post"))

# Define the colors for the levels of investorState

state_colors <- c("happy" = "Blue", "neutral" = "#77DD77", "unhappy" = "#FF6961")

# Create the histogram with stacked bars and specified colors
ggplot(filtered_prepost, aes(x = as.factor(roundNum), fill = investorState.f)) +
  geom_bar(aes(group = investorState.f), position = position_stack(reverse = FALSE), stat = "count") +
  scale_fill_manual(values = state_colors) +
  facet_wrap(~condition.f*gameNum.f, scales = "free_x", labeller = label_both) +
  labs(x = "Round", fill = "Investor State", title = "Histogram of Latent HMM Investor States per Game and Round") +
  theme_bw() +
  theme(legend.position = "bottom")

```
```{r}
# Filter for expo games only
filtered_expo <- d_long %>%
  filter(gameNum.f %in% c("expo1", "expo2", "expo3"))

# Create the histogram with stacked bars and specified colors
ggplot(filtered_expo, aes(x = as.factor(roundNum), fill = investorState.f)) +
  geom_bar(aes(group = investorState.f), position = position_stack(reverse = FALSE), stat = "count") +
  scale_fill_manual(values = state_colors) +
  facet_wrap(~condition.f*gameNum.f, scales = "free_x", labeller = label_both) +
  labs(x = "Round", fill = "Investor State", title = "Histogram of Latent States per Game and Round") +
  theme_bw() +
  theme(legend.position = "bottom")
```

<!------------------------ AVERAGING LATENT STATE COUNT ACROSS TRIALS ----------------------------->

```{r}
counts <- filtered_prepost %>%
  group_by(condition.f, gameNum.f, investorState.f,id) %>%
  summarise(count = n()) %>%
    summarise(count = sum(count))
  
# Calculate the average count per state per condition
total_rounds <- filtered_prepost  %>%
  group_by(condition.f, gameNum.f) %>%
  summarise(total_rounds = n()) 

state_summary  <- counts %>%
  left_join(total_rounds, by = c("condition.f", "gameNum.f")) %>% 
  mutate(state_percentage = count/total_rounds)

ggplot(state_summary , aes(x = gameNum.f, y = state_percentage, fill = investorState.f)) +
  geom_bar(stat = "identity") +
  facet_wrap(~condition.f) +
  labs(x = "Condition", y = "Proportion", fill = "Investor State") +
  theme_bw() +
  theme(legend.position = "bottom")

state_colors <- c("happy" = "Blue", "neutral" = "#77DD77", "unhappy" = "#FF6961")

# Create the histogram with stacked bars and specified colors
ggplot(state_summary , aes(x = gameNum.f, y = state_percentage, fill = investorState.f)) +
  geom_bar(aes(group = investorState.f), position = position_stack(reverse = FALSE), stat = "identity") +
  scale_fill_manual(values = state_colors) +
  facet_wrap(~condition.f*gameNum.f, scales = "free_x", labeller = label_both) +
  labs(x = "Round", fill = "Investor State", title = "Histogram of Latent States per Game and Round") +
  theme_bw() +
  theme(legend.position = "bottom")
```








# Discussion

We used a randomized controlled online experiment where participants played a RTG with artificial agents designed to simulate human-like trust-building scenarios. Participants were then exposed to either forgiving or human-like HMM agents before playing another RTG. Contrary to our hypothesis, exposure to forgiving agents did not increase trust or cooperation. Instead, participants reduced their returns overall whilst the returns of those in the Control group did not change between the pre and post phase of the experiment. Neither did participants show more forgiving behavior in the Manipulation condition after the one-off defection by the agent.  Why did participants reduce their returns even though they were repeatedly exposed to more cooperative and more forgiving artificial agents? A look at how the participants rated their co-players might shed some light on what might be driving this reduction in returns for those in the Manipulation condition. 

Those exposed to the forgiving agent rated their opponent in the post-exposure phase lower on all attributes even though they faced the same dynamic human-like HMM as pre-exposure. One possible explanation for this drop in rating is that participants exhibited a negative contrast effect. This occurs when the evaluation of a person, object, or situation is influenced by comparisons with recently encountered contrasting objects or people. If we've recently interacted with someone exceptionally nice, our perception of a normal level of niceness might be skewed, making normal behavior seem less favourable or even negative by comparison [@kobre_negative_1972]. As the most recently faced opponents were more forgiving and cooperative, this negative contrast effect may have trumped any learning transfer from being repeatedly exposed to cooperative and forgiving agents [@zentall_within-trial_2005]. If this contrast effect is indeed replicable, then an avenue for future research would be to use it to our benefit by making the participants play agents with low cooperation perception.

It is worth highlighting that RS was not correlated to overall performance in the task.  Neither did it moderate the change in returns between Conditions or have an effect on participant returns. However, in examining the player ratings by RS group more closely, we observe that individuals with high RS demonstrate a heightened attunement to changes in the behavior of their HMM co-players: They accurately perceived increased cooperativeness in the forgiving agent, showing an ability to adjust their judgments based on interaction patterns. This may indicate that perceived support from cooperative partners can mitigate their rejection concerns. However, their declining ratings of similar co-players over time, despite consistent agent behavior, suggests that occasional pre-programmed defections may have amplified their perceptions of untrustworthiness and reluctance for future interactions. These nuanced perceptions align with the heightened social awareness often associated with high rejection sensitivity [@downey_implications_1996]. Individuals with low RS were less affected by the agent's behavioral variations, showing a less volatile baseline of social perception. They still exhibit behavior consistent with a contrast effect in the Manipulation condition. This stability in perception might reflect a lower propensity to scrutinize social cues or a more robust internal model of social interactions that is less easily perturbed by short-term variations in partner behavior. 

Despite these differences in perception, the actual cooperative behavior – as measured by returns in the trust game – did not significantly differ between RS groups. This suggests a potential dissociation between the cognitive-perceptual processes involved in evaluating social partners and the behavioral output in economic games. There are multiple potential explanations for this: First, the ratings may reflect explicit, conscious evaluations of social partners, while behavior in the trust game might be guided more by implicit, automatic processes that are less differentiated between RS groups. This interpretation aligns with dual-process theories of social cognition [@lieberman_social_2007]. Second, the structured nature of the trust game might provide a context where the behavioral expression of rejection sensitivity is attenuated. In contrast, the more open-ended nature of providing ratings might allow for greater expression of RS-related perceptual biases.


These findings suggest that interventions focused solely on altering behavior might be insufficient, as the underlying perceptual and cognitive processes may remain unchanged. Conversely, therapies targeting these perceptual processes might not necessarily translate into immediate behavioral changes. Future research should investigate whether this dissociation between perception and behavior persists in more naturalistic social interactions or over longer periods. Additionally, exploring specific conditions or thresholds under which perceptual differences begin to manifest in behavioral divergences could provide valuable insights into the dynamics of rejection sensitivity. Simply exposing individuals to highly cooperative or forgiving partners may not suffice to induce lasting changes in behavior. Instead, interventions may need to incorporate more nuanced approaches that gradually shape expectations and behaviors over time. Combining periods of forgiveness with clear communication about mutual expectations for cooperation might be more effective [@balliet_reward_2011]. Future studies should also consider the temporal dynamics of these effects, examining whether longer exposure periods or different patterns of forgiving behavior could lead to more positive outcomes. Moreover, investigating the role of explicit communication and meta-cognitive reflection on the cooperative process could offer insights into leveraging positive interactions to promote enduring cooperative tendencies.

<!-- This study leveraged a novel approach to examining the dynamics of trust and cooperation in social interactions through the utilization of generative models of human behavior to design artificial agents that can interact in economic games. The use of these agents in the RTG led to similar investment and returns to those recorded in human dyadic interactions. Participants were often uncertain whether they interacted with human or artificial investors, highlighting the agents’ realism. This validates the use of these artificial agents to probe the effectiveness of manipulations whilst keeping a high degree of experimental control. -->



# Conclusion

This randomised controlled experiment enabled us to uncover unexpected effects of exposure to forgiving behavior on subsequent cooperation, particularly in relation to rejection sensitivity. These findings challenge existing assumptions about fostering cooperative behavior and suggest the need for more nuanced interventions. Importantly, the use of HMM-based artificial agents in this study represents a significant methodological advancement. By providing a balance between experimental control and realistic, adaptive behavior, these agents allowed for a nuanced exploration of trust dynamics that would be challenging to achieve with human confederates or simplistic computer algorithms. This approach opens up new possibilities for studying complex social interactions in controlled settings, potentially bridging the gap between laboratory experiments and real-world social dynamics.




\pagebreak

# Author contributions statement {.unnumbered}
I. Guennouni, G. Koppe and C. Korn. designed and developed the study concept. Experiment design, testing and data collection were performed by I. Guennouni. I. Guennouni analysed and interpreted the data under the supervision of G. Koppe and C. Korn. All authors jointly wrote and approved the final version of the manuscript for submission.

# Funding {.unnumbered}
This publication was supported through state funds approved by the State Parliament of Baden-Württemberg for the Innovation Campus Health + Life Science alliance Heidelberg Mannheim. I. Guennouni was supported by a research fellowship from the AI Health Innovation Cluster 

# Competing interests statement {.unnumbered}
The author(s) declared that there were no conflicts of interest with respect to the authorship or the publication of this article.

# Additional information  {.unnumbered}

## Correspondence {.unnumbered}

All correspondence and requests for materials should be addressed to I. Guennouni.

## Transparency and data availability {.unnumbered}

Preregistration: The hypotheses and methods were not preregistered.The analysis plan was not preregistered. Materials: All study materials are publicly available (https://github.com/ismailg/exposure-public). Data: All primary data are publicly available (https://github.com/ismailg/exposure-public). Analysis scripts: All analysis scripts are publicly available (https://github.com/ismailg/exposure-public). 

# References
